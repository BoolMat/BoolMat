\documentclass[11pt]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb, latexsym, mathrsfs, pifont,
tabu, enumitem}
\usepackage[cm]{fullpage}
\usepackage{theoremref}
\usepackage[ruled, linesnumbered]{algorithm2e}
\usepackage{makecell}

\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{defi}[thm]{Definition}
\newtheorem{exa}[thm]{Example}
\newtheorem{algo}[thm]{Algorithm}
\newenvironment{de}[1][]{\begin{defi}[#1]\rm}{\end{defi}}
\newenvironment{ex}{\begin{exa}\rm}{\end{exa}}
\newenvironment{alg}{\begin{algo}\rm}{\end{algo}}
\newcommand{\proofref}[1]{\noindent {\emph{Proof of Theorem}~\ref{#1}.\ }}
\newcommand{\defn}[1]{\textbf{\textit{#1}}}
\numberwithin{equation}{section}

% Lists
%\def\labelenumi{\theenumi}
%\def\theenumi{(\roman{enumi})}

% Macros
\newcommand{\id}{\mbox{\rm id}}
\newcommand{\set}[2]{\ensuremath{\{#1 : #2 \}}}
\newcommand{\genset}[1]{\ensuremath{\langle\: #1 \:\rangle}}
\renewcommand{\to}{\longrightarrow}

\DeclareMathOperator{\im}{im}

\newcommand{\num}{\mathbf{num}}
\newcommand{\vect}{\mathbf{vec}}


% For Algorithms
\SetKwProg{Fn}{Function}{}{}
\SetKwFunction{FZeroIfNotSubset}{ZeroIfNotSubset}
\SetKwFunction{FRemoveDuplicateRows}{RemoveDuplicateRows}
\SetKwComment{Comment}{}{}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\DontPrintSemicolon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\B}{\mathbb{B}}
\newcommand{\Bn}{M_n(\B)}
\newcommand{\Bm}[1]{M_{#1}(\B)}
\newcommand{\Bmn}{M_{m,n}(\B)}
\newcommand{\Refn}{M_n^{\text{id}}(\B)}
\newcommand{\Ref}[1]{M_{#1}^{\text{id}}(\B)}
\newcommand{\Halln}{M_n^{\text{S}}(\B)}
\newcommand{\Hall}[1]{M_{#1}^{\text{S}}(\B)}
\newcommand{\MTn}{M_n^{\mathcal{T}}(\B)}
\newcommand{\MT}[1]{M_{#1}^{\text{T}}(\B)}
\newcommand{\UTn}{UT_n(\B)}
\newcommand{\LTn}{LT_n(\B)}
\renewcommand{\L}{\mathscr{L}}
\newcommand{\R}{\mathscr{R}}
\newcommand{\D}{\mathscr{D}}
\newcommand{\J}{\mathscr{J}}
\renewcommand{\H}{\mathscr{H}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\rank}{\operatorname{rank}}

\newcommand{\K}{\mathbb{K}}

\newcommand{\BGSet}{\mathcal{B}_{n,n}}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newcommand{\mat}[4]{\begin{pmatrix}#1&#2\\#3&#4\end{pmatrix}}

\usepackage[backend=biber, bibencoding=utf8]{biblatex}
\bibliography{matrix}

\title{Minimal generating sets for matrix monoids}
\author{F. Hivert, J. D. Mitchell, F. L. Smith, and W. A. Wilson}
\date{\today}
\begin{document}

\maketitle

\begin{abstract}
  We compute the largest known ranks of the boolean matrix monoid and the
  submonoids $\Refn$ of reflexive boolean matrices, $\Halln$ of Hall matrices,
  $\MTn$ of boolean matrices containing a transformation, and $\UTn$ and $\LTn$,
  of triangular boolean matrices. We also determine the relationship between
  minimal generating sets for $\Bn$, $\Halln$, and $\MTn$, and prove that the
  rank of $\UTn$ and $\LTn$ are given by the triangular numbers.
\end{abstract}

\section{Introduction}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%The \defn{boolean semiring} $\B$ is the set $\{0, 1\}$ with addition defined by 
%\begin{align*}
%  0 + 1 = 1 + 0 &= 1 + 1 = 1 \\
%  0 + 0 &= 0
%\end{align*}
%and multiplication defined as usual for the real numbers $0$ and $1$.  The
%addition and multiplication of elements of $\B$ naturally extends to row and
%column vectors of equal length with entries in $\B$.  The main object of study
%in this document is the collection $\Bn$ of $n\times n$ matrices with entries in
%$\B$. Under the usual multiplication of matrices, using addition and
%multiplication in $\B$, the set $\Bn$ forms a monoid; call the \defn{full
%  boolean matrix monoid}. The monoid $\Bn$ is classical in the literature of
%semigroup theory being among the first monoids to be studied; see, for example,
%\cite{Zaretskii1963aa}. The monoids $\Bn$, $n\in \N$, have been extensively
%studied in the literature, by many authors, and a great deal is known about its
%structure and properties. For example, if $G$ is a finite group, then there
%exists an $n\in \N$ such that $G$ occurs as a maximal subgroup of $\Bn$; the
%probability that a random product of matrices in $\Bn$ equals the universal
%matrix:
%\begin{equation*} 
%  \begin{pmatrix}
%  1 & 1 & \cdots & 1\\
%  1 & 1 & \cdots & 1\\ 
%  \vdots & \vdots & \ddots & \vdots\\
%  1 & 1 & \cdots & 1\\ 
%\end{pmatrix} 
%\end{equation*} 
%tends to $1$ as $n\to \infty$; the minimal size of a generating set for $\Bn$
%grows exponentially with $n$ (see~\thref{cor:ExponentialGenSets});
%Devadze~\cite{Devadze1968aa} and Konieczny~\cite{Konieczny2011aa} characterise
%minimum cardinality generating sets for $\Bn$; TODO: more.
%
%Despite its venerable status, many aspects of the monoids $\Bn$ are still
%shrouded in mystery. The purpose of this article is to cast some light on the
%problems of determining the minimum cardinality $\mathbf{d}(\Bn)$ of a
%generating set for $\Bn$ and certain submonoids of $\Bn$ such as the reflexive
%boolean matrix monoid $\Refn$, and other submonoids where the matrices contain
%particular matrices.
%% The time and space complexity of determining any of these value is exponential
%% in $n$. 
%It seems unlikely that an explicit formula for any of these numbers exists.
%In this paper we describe algorithms for computing the numbers listed,
%and the output of our implementation~\cite{} of these algorithms. The latter
%are summarised in Tables~\ref{figure-table-1} and \ref{tab:reflexiverank}.
%

We'll write this once we know what the content of the paper is.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
\label{section-preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Green's relations}
On any semigroup $S$, there are some key equivalence relations. These are known
as Green's relations, and are defined in terms of principal ideals as follows.
Let $S$ be any semigroup and let $s, t \in S$. Then
\begin{align*}
  s \L t &\text{ if and only if } S^1 s = S^1 t \\
  s \R t &\text{ if and only if } s S^1 = t S^1 \\
  s \J t &\text{ if and only if } S^1 s S^1 = S^1 t S^1.
\end{align*}
Finally, we define Green's $\H$-relation as the intersection of $\L$ and $\R$.
We write $X_s$ for the Green's $\mathcal{X}$-class of $s$, where
$\mathcal{X} \in \{\L, \R, \J, \H\}$.
There is a natural partial order on certain Green's classes
\begin{align*}
  R_s \leq R_t &\text{ if and only if } sS^1 \subseteq tS^1 \\
  L_s \leq L_t &\text{ if and only if } S^1s \subseteq S^1t \\
  J_s \leq J_t &\text{ if and only if } S^1 s S^1 \subseteq S^1 t S^1.
\end{align*}
Further background on Green's relations can be found in~\cite{Howie1995aa}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Semirings}
The theory of matrices over fields is familiar and well-studied, but we are
concerned with matrices over more general objects, semirings. For our purposes,
a semiring is a set $\mathbb{S}$ with two operations, $\oplus$ and $\otimes$,
such that $(\mathbb{S}, \oplus)$ forms a commutative monoid with identity $e$,
$(\mathbb{S}, \otimes)$ forms a monoid, $e\otimes x = x\otimes e = e$ for all $x
\in \mathbb{S}$, and multiplication distributes over addition. We call the
additive identity the \defn{zero} of the semiring and the multipicative identity
the \defn{one}. Throughout, semirings will be denoted by blackboard bold
symbols. We are particularly interested in several special types of semiring.

The \defn{boolean semiring} $\B$ is the set $\{0, 1\}$ with addition defined by 
\begin{align*}
  0 \oplus 1 = 1 \oplus 0 &= 1 \oplus 1 = 1 \\
  0 \oplus 0 &= 0
\end{align*}
and multiplication defined as usual for the real numbers $0$ and $1$. This
semiring, and the matrices over it, have been studied since at least Zaretskii's
foundational paper~\cite{Zaretskii1963aa} in 1963. \\

The \defn{min-plus semiring} $\K^{\infty}$ is the set $\N \cup \{\infty\}$, with
$\oplus = \min$ and $\otimes$ extending the usual addition on $\N$ so that
$x\otimes\infty = \infty\otimes x = \infty$ for all $x \in \K^{\infty}$. For our
purposes, $0 \in \N$, and so the one of $\K^{\infty}$ is $0$ and the zero is
$\infty$. \\ 
%The min-plus semiring was first introduced by
%Simon~\cite{Simon1978aa} in the context of automata theory; see also
%Pin~\cite{Pinab}. 
The \defn{max-plus semiring} $\K^{-\infty}$ is the set $\N \cup \{-\infty\}$ with
$\oplus = \max$ and $\otimes$ extending the usual addition on $\N$ so that
$x\otimes-\infty = -\infty\otimes x = -\infty$ for all $x \in \K^{-\infty}$. The
one of $\K^{-\infty}$ is $0$ and the zero is $-\infty$.

We are also interested in certain finite quotients of these semirings. The
\defn{min-plus semiring with threshold $t$}, denoted $\K^{\infty}_t$, is the set
$\{0, 1, \ldots, t, \infty\}$ with operations $\oplus = \min$ and $\otimes$
defined by
\begin{align*}
  a \otimes b = \begin{cases}
    \min(t, a + b) \quad &\text{$a \neq \infty$ and $b \neq \infty$} \\
    \infty \quad &\text{$a = \infty$ or $b = \infty$}.
  \end{cases}
\end{align*}

The \defn{max-plus semiring with threshold $t$}, denoted $\K^{-\infty}_t$, is
constructed analogously; its elements are $\{-\infty, 0, 1, \ldots, t\}$,
addition is $\max$, and multiplication is defined by $a \otimes b = \min(t, a +
b)$ for all $a, b \in \K^{-\infty}_t$.
These finite semirings with threshold $t$ may also be defined as the quotient of
the corresponding infinite semirings by the congruence generated by $(t, t +
1)$.
The min-plus and max-plus semirings are known as \defn{tropical} semirings.
Tropical semirings have attracted significant attention recently.
The final semirings that we are concerned with are the \defn{modular integers}
$\Z_n$; given $n \in \N$, $\Z_n$ consists of the set $\{0, 1, \ldots, n - 1\}$
where $\oplus$ is addition modulo $n$, and $\otimes$ is multiplication modulo
$n$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Matrix semigroups}
\label{sec:matsemigp}
Given a semiring $\mathbb{S}$ and $m, n \in \N$, we may study the set of $m
\times n$ matrices over $\mathbb{S}$; we will denote this by $M_{m,
  n}(\mathbb{S})$. In particular, we are interested in the multiplicative monoid
of square matrices of dimension $n \in
\N$ over $\mathbb{S}$, denoted by $M_n(\mathbb{S})$.
There are a number of common features of such matrix monoids. As usual, we let
$0$ denote the additive identity of $\mathbb{S}$ and $1$ denote the
multiplicative identity.

Let $A \in M_n(\mathbb{S})$. We write $A_{i*}$ to denote the $i$th row of $A$,
$A_{*i}$ to denote the $i$th column, and $A_{ij}$ to denote the $j$th entry of
the $i$th row. A \defn{linear combination} of rows is a sum of scalar multiples
of the rows, where both operations are defined componentwise in the usual way.
The \defn{row space} $R(A)$ of $A$ is the set of all linear combinations of the
rows of $A$.  A set of rows is \defn{linearly independent} if some row can be
written as a linear combination of other rows; this coincides with the usual
definition when $\mathbb{S}$ is a field. \defn{Spanning sets} are defined
exactly as for matrices over fields: a spanning set for a row space is a set of
rows which every element of the row space may be written as a linear combination
of. A \defn{row basis} of $A$ is then a linearly independent spanning set for
the row space of $A$. \defn{Column spaces} and \defn{column bases} are defined
dually. The importance of row and column bases arises from the following
well-known results:

\begin{prop}
  \thlabel{prop:rowsandideals}
  Let $A, B \in M_n(\mathbb{S})$. Then the following hold:
  \begin{enumerate}[label={\rm (\roman*)}]
    \item
      If $R(A) \subseteq R(B)$, then $A \in M_n(\mathbb{S}) B$.  Similarly, if $C(A)
      \subseteq C(B)$, then $A$ belongs to the right ideal $BM_n(\mathbb{S})$.

    \item 
      $R(AB) \subseteq R(B)$ and $C(AB) \subseteq C(B)$.
  \end{enumerate}
\end{prop}
\begin{proof}
  \noindent \textbf{(i).}
  If $R(A) \subseteq R(B)$, then every row of $A$ can be expressed as a linear
  combination of rows of $B$. For $1 \leq i \leq n$ of $A$, let $A_{i*} =
  \sum_{j = 1}^{n}x_{ij}B_{j*}$, and define $X = [x_{ij}]$. Then $A = XB \in
  M_n(\mathbb{S})B$. The other case is dual.
  \bigskip

  \noindent \textbf{(ii).}
  Suppose that $A = [\alpha_{ij}]$ and $B = [\beta_{ij}]$. If 
  $AB = [\gamma_{ij}]$, then 
  \[
  \gamma_{ij} = \alpha_{i1} \beta_{1j} + \alpha_{i2}\beta_{2j} 
                + \cdots + \alpha_{in}\beta_{nj}
              = \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kj}.
  \]
  It follows that the $i$th row of $AB$ is 
  \[
  (\gamma_{i1}, \gamma_{i2}, \ldots, \gamma_{in})
   =  \left (\sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k1},
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k2},
     \ldots, 
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kn}\right) \\
   % & = & (\alpha_{i1}\beta_{11} + \alpha_{i2}\beta{21} + \cdots +
   %  \alpha_{in}\beta{n1},
   %  \alpha_{i1}\beta_{12} + \alpha_{i2}\beta{22} + \cdots +
   %  \alpha_{in}\beta{n2},
   %  \ldots,
   %  \alpha_{i1}\beta_{1n} + \alpha_{i2}\beta{2n} + \cdots +
   %  \alpha_{in}\beta{nn}) \\
   % & = & 
   % (\alpha_{i1}\beta_{11}, \alpha_{i1}\beta_{12}, 
   % \ldots, \alpha_{i1}\beta_{1n})
   % + 
   % (\alpha_{i2}\beta_{21}, \alpha_{i2}\beta_{22}, 
   % \ldots, \alpha_{i2}\beta_{2n})
   % + \cdots +
   % (\alpha_{in}\beta_{n1}, \alpha_{in}\beta_{n2}, 
   % \ldots, \alpha_{in}\beta_{nn}) \\
    =
    \sum_{k = 1} ^ {n} 
    \alpha_{ik}B_{k*}.
  \]
  Thus the $i$th row of $AB$ is a sum of rows of $B$, and so $R(AB) \subseteq
  R(B)$. 
\end{proof}

\begin{prop} 
  \thlabel{lem:GreensRowColumnSpaces}
  Let $A, B \in M_n(\mathbb{S})$. Then $A \L B$ if and only if $R(A) = R(B)$,
  and $A \R B$ if and only if $C(A) = C(B)$. 
\end{prop}
\begin{proof}
  \textbf{(i) $\Rightarrow$ (ii).} 
  If $A \L B$, then there are $X, Y \in M_n(\mathbb{S})$ such that $XA = B$ and
  $YB = A$. Then $R(B) = R(XA) \subseteq R(A)$ and $R(A) = R(YB) \subseteq R(B)$
  by Proposition~\ref{prop:rowsandideals}(ii).
  \bigskip

  \textbf{(ii) $\Rightarrow$ (i).} Follows immediately by
  Proposition~\ref{prop:rowsandideals}(i). 
\end{proof}

The \defn{group of units} of $M_n(\mathbb{S})$ is the group of invertible
matrices (\defn{units}) in $M_n(\mathbb{S})$; the identity matrix is always a
unit. The group of units is always the maximal class in the $\J$-order of
$M_n(\mathbb{S})$.

For any semiring $\mathbb{S}$, the symmetric group embeds into the group of units of
$M_n(\mathbb{S})$ by the map 
\begin{align*}
  \phi:\: &\alpha \to [a_{ij}], \\
  &a_{ij} =
    \begin{cases}
      1 \quad & i\alpha = j \\ 
      0 \quad &\text{otherwise}.
    \end{cases}
\end{align*}
The image of this embedding will often simply be referred to as $S_n$ or the
symmetric group when context prevents ambiguity. Elements of this embedding
$S_n$ are called \defn{permutation matrices}; multiplying by a permutation
matrix on the left permutes rows of a matrix, and multiplying on the right
permutes columns. Similarly, we may define a \defn{transformation matrix} to be
one which contains a single $1$ in every row; these are the images of the
obvious extension of $\phi$ to the full transformation monoid $\mathcal{T}_n$.

Two matrices $A, B\in M_n(\mathbb{S})$ are \defn{similar} if each can be
obtained from the other by permuting the rows and/or columns. Note that similar
matrices are $\J$-related in $M_n(\mathbb{S})$, by multiplying on the left
and/or right by permutation matrices.

A non-unit matrix $A \in M_n(\mathbb{S})$ is \defn{prime} if $A = BC$ implies
$B$ or $C$ is a unit. The prime matrices of $M_n(\mathbb{S})$ are immediately
below the group of units in the $\J$-order. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Minimal generating sets}

Given a semigroup $S$, we may ask what the minimum cardinality is of a
generating set for $S$. This is known as the \defn{rank} of $S$ and is denoted
by $\mathbf{d}(S)$. A generating set $X$ for $S$ is \defn{irredundant} if no
subset of $X$ generates $S$, and we say that any irredundant generating set of
cardinality $\mathbf{d}(S)$ is a \defn{minimal generating set}. If
$\mathbf{D}(S) \in \N$, then every generating set of cardinality $\mathbf{d}(S)$
is irredundant and hence minimal; this does not hold when $\mathbf{d}(S)$ is not
finite.

\begin{de}[\textbf{Decomposable elements}]
  An element $x$ of a monoid $M$ with identity $e$ is \defn{decomposable} if $x$
  may be written as a product of elements not belonging to $\{e, x\}$, and
  \defn{indecomposable} otherwise.
\end{de}

\begin{lemma}
  \thlabel{lem:GenSetDecomposition}
  Let $S$ be a finite semigroup and let $X$ be a subset of $S$, such that for
  every element $x \in X$ with $\J$-class $J_x$, we have $J_x \subseteq
  \genset{X}$. If every element $s \in S$ that is not $\J$-related to an element
  of $X$ can be written as a product of elements of $S$, none of which are
  $\J$-related to $s$ in $S$, then $X$ generates $S$. 
\end{lemma}
\begin{proof}
  Let $x \in S$. Then either $x$ is in a $\J$-class of an element belonging to
  $X$, in which case we are done, or $x$ may be written as a product of elements
  which are not $\J$-related to $x$, and hence lie strictly above $x$ in the
  $\J$-order. This same argument applies to each of those elements. Since $S$
  has finitely many $\J$-classes, this process must eventually terminate.
  However, the process of decomposing elements may only terminate if each
  element to be decomposed lies in the $\J$-class of an element of $X$; hence $s
  \in \genset{X}$.
\end{proof}

\begin{prop}[Wilf, elsewhere]
  \thlabel{prop-wilf}
  Let $S$ be a finite semigroup.  Suppose that $X$ is an irredundant generating
  subset of $S$ that contains at most one element from each $\D$-class of $S$.
  Then $X$ has minimal cardinality, i.e. $\rank(S) = |X|$.
\end{prop}
\begin{proof}
  Wilf claims to have proven this.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Boolean Matrix Monoids}
\label{sec:boolmat}

In this section, we compute minimal generating sets for the full boolean matrix
monoid $\Bn$ and some of its natural submonoids. In order to define these
submonoids, we must introduce the concept of matrix containment: given two
matrices $A, B \in \Bn$, we say that $A$ is \emph{contained} in $B$ if for all
$1 \leq i,j \leq n$, $A_{ij} = 1$ implies that $B_{ij} 1$; that is, $B$ contains
a $1$ in every position in which $A$ does.

We consider the submonoids:
\begin{enumerate}[label={\rm (\roman*)}]
  \item $\Refn$, of matrices containing the identity (reflexive matrices),
  \item $\Halln$, of matrices containing a permutation matrix (Hall matrices),
  \item $\MTn$, of matrices containing a transformation matrix, and
  \item $\UTn$ and $\LTn$, of upper- and lower-triangular boolean matrices.
\end{enumerate}

There is a natural isomorphism $\Theta$ between binary relations on $\{1,
  \ldots, n\}$ and $\Bn$, which maps a binary relation $\mu$ to the matrix $M
\in \Bn$ such that $M_{ij} = 1$ if and only if $(i, j) \in \mu$.
The monoid $\Refn$ arises as the image of the reflexive binary relations under
$\Theta$, and this is the primary reason for studying $\Refn$. However, it may
also be viewed as the monoid of matrices containing a certain pattern of $1$s -
namely the identity matrix. Similarly, $\Halln$ arises as those matrices
describing a family of subsets which satisfy Hall's marriage condition, but also
as those matrices containing a permutation matrix. By increasing the number of
permitted patterns, we obtain the monoid $\MTn$, consisting of those matrices
containing a transformation. 

We compute the largest known ranks of these monoids, which are presented in
Table~\ref{tab:BMatResults} along with whether that rank was previously known or
is practically computable by brute force. The rank of $\UTn$ is given by the
triangular numbers $T_n$ for $n \geq 2$; this may have already been known but we
were unable to find a reference in the literature. Note that since $\UTn$ and
$\LTn$ are anti-isomorphic via the transposition map, $\mathbf{d}(\UTn) =
\mathbf{d}(\LTn)$ for all $n$. None of the other ranks are known beyond $n = 8$. 

\begin{table}
  \centering
  \begin{tabular}{l|r|r|r|r|r}
    $n$ & $\mathbf{d}(\Bn)$ & $\mathbf{d}(\Refn)$ & $\mathbf{d}(\Halln)$ &
    $\mathbf{d}(\MTn)$ & $\mathbf{d}(\UTn)$ \\ 
    \hline
    1 & *2         & *1& *1& *1& *2\\
    2 & *3         & *2& *2& *3& *3\\
    3 & *5         & *8& *4& *5& *6\\
    4 & *7         & *38& *6& *7& *10\\
    5 & *13        & *1\ 415& *12& *13& *15\\
    6 & 68         & 482\ 430& 67& 68& 21\\
    7 & 2\ 143     & 1\ 034\ 972\ 230& 2\ 142& 2\ 143& 28\\
    8 & 495\ 115   & ?& 495\ 114& 495\ 115 & 36\\
    9 & ?   & ?& ?& ? & 45
  \end{tabular}
  \vspace{1cm}

  \caption{The ranks of certain matrix monoids over $\B$; a * denotes that the
    rank was already known or is computable by brute force, and a ? indicates
    that the value is unknown.}
  \label{tab:BMatResults}
\end{table}
There are several obvious relationships between columns in
Table~\ref{tab:BMatResults}; we prove that these relationships hold for all $n
\in \N$.

There are a number of other submonoids of $\Bn$ that may be considered. If we
define the \defn{containment closure} $\bar{S}$ of a subsemigroup $S \leq \Bn$
to be the set of matrices $A \in \Bn$ containing some element of $S$, then for
any choice of subsemigroup $S$, $S \leq \bar{S} \leq \Bn$. In
particular, the submonoids $\Refn$, $\Halln$, and $\MTn$ are of this type. It
remains an open problem to determine minimal generating sets for arbitrary
containment closures. This problem seems difficult; a more tractable problem may
be to restrict $S$ to subgroups of $S_n$ or submonoids of transformation
matrices.

%TODO: namedrop gossip monoid

The rest of this section is organised as follows. In
Section~\ref{sec:BMatPrelim}, we introduce a number of concepts and results
particular to matrices over $\B$. These are used throughout the rest of
Section~\ref{sec:boolmat}. In Section~\ref{sec:FullBoolMat}, we describe how to
compute minimal generating sets for $\Bn$ based on a theorem of
Devadze~\cite{Devadze1968aa}. In Section~\ref{sec:RefBoolMat}, we describe the
unique minimal generating sets for $\Refn$ and how to compute it; in
Sections~\ref{sec:HallBoolMat} and~\ref{sec:TransBoolMat} we describe how all
minimal generating sets for $\Halln$ and $\MTn$ may be obtained from minimal
generating sets for $\Bn$; and in Section~\ref{sec:TriBoolMat} we give a simple
description of the unique minimal generating sets for $\UTn$ and $\LTn$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preliminaries}
\label{sec:BMatPrelim}
The semiring $\B$ is one of the simplest examples of a semiring, and the matrix
monoids $\Bn$ for $n \in \N$ have been widely studied in the literature;
see~\cite{TODO}. In particular, there is a description of a minimal generating
set for $\Bn$, due to Devadze in 1968~\cite{Devadze1968aa} and proven correct by
Konieczny in 2011~\cite{Konieczny2011aa}. However, these generating sets are
difficult to compute and so explicit generating sets, even for $n = 6$, were
unknown. It was known that the size of a minimal generating set for $\Bn$ grows
very quickly with $n$; see~\thref{cor:ExponentialGenSets}.

In contrast, the subsemigroup of $\Bn$ generated by all the regular elements can
be generated by the four matrices

\begin{align}
  \label{eq:RegularGens}
  T = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    1 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  U = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    0 & 0 & 0 & 0 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & 0 & 0 & 0 & \cdots & 0 
  \end{pmatrix},&\\
  E = \begin{pmatrix}
    1 & 0 & 0 & 0 & \cdots & 0 \\
    1 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  F = \begin{pmatrix}
    0 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1
  \end{pmatrix};
\end{align}
see \cite{Roush1977aa} for further details.
We will continue to use these names for these matrices throughout
Section~\ref{sec:boolmat}. Note that together $T$ and $U$ generate $S_n$ for $n
\geq 2$.

We call any matrix similar to $E$ an \defn{elementary} matrix. In particular,
the elementary matrix which consists of the identity matrix with an additional
$1$ in position $j$ of the $i$th row will be denoted by $E^{i,j}$. If $J_E$ is
the $\J$-class of $E$ in $\Bn$, then it is easy to show that $J_E =
\set{E^{i,j}}{1 \leq i, j \leq n}$ and we call $J_E$ the \defn{elementary
  $\J$-class}. 
\begin{thm}[Devadze's Theorem \cite{Konieczny2011aa}]
  \thlabel{thm:DevadzeKon}
  For $n > 2$, the set $\{T, U, E, F\} \cup P$ is a generating set for $\Bn$ of
  minimum cardinality, where $P$ is any set containing one matrix from every
  $\J$-class of $\Bn$ which contains a prime matrix. 
\end{thm}
By Devadze's Theorem, in order to determine the rank of $\Bn$ it is sufficient
to compute a set of representatives of the $\J$-classes of $\Bn$ containing a
prime matrix; see Section~\ref{sec:FullBoolMat} for details of this computation.

As well as the description of a minimal generating set for $\Bn$, there are
certain additional concepts attached to $\Bn$ which do not apply to matrices
over arbitrary semirings. Many of these arise from the observation that we may
view a vector $v \in \B^n$ as the characteristic function of a subset $s(v)$ of
$\{1, \ldots, n\}$, where $i \in s(v)$ if and only if $v_i = 1$.  Then we define
the \defn{union} of two vectors $v, w$ to be $s^{-1}(s(v) \cup s(w))$. Note that
the union and sum of two vectors coincide in $\B^n$. In fact, since there is a
single non-zero element of $\B$, unions, sums, and linear combinations all
coincide. Given $v, w \in \B^n$, we also say that $v$ is \defn{contained} in
$w$, and write that $v \leq w$, if $s(v) \subseteq s(w)$.

It is straightforward to verify that if $A \in \Bn$, then there is a unique row
basis $r(A)$, which is the unique minimal generating set for $R(A)$ under union,
consisting of the non-zero $\leq$-minimal rows. The dual statement for column
spaces also holds. This yields a strengthening of
\thref{lem:GreensRowColumnSpaces}.

\begin{prop} 
  \thlabel{lem:BMatGreensRowColumnBases}
  Let $A, B \in \Bn$. Then $A \L B$ in $\Bn$ if and only if $r(A) = r(B)$,
  and $A \R B$ in $\Bn$ if and only if $c(A) = c(B)$.
\end{prop}
There is a simple algorithm to compute the row and column bases of matrices in
$\Bn$ in time and space cubic in $n$, and hence the previous proposition gives
an efficient method for determining whether two matrices are $\L$- or
$\R$-related in $\Bn$. This, in combination with
\thref{lem:GreensRowColumnSpaces}, allows for the efficient computation of the
$\L$- and $\R$-structure of $\Bn$. However, the number of $\L$- and $\R$-classes
grows extremely rapidly with $n$, as shown in Table~\ref{tab:NumberLRClasses},
so that it quickly becomes infeasible to compute the $\L$- and $\R$-structure of
$\Bn$. Note that transposition gives an anti-automorphism from $\Bn$ to itself
which exchanges $\L$ and $\R$ classes, and hence determining the $\L$- and
$\R$-structure only requires computation of one of the relations.

\begin{table}
  \centering
  \begin{tabular}{r|r|r|r|r|r|r|r}
    $n$ & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
    \hline
     & 2 & 7 & 55 & 1\ 324& 120\ 633& 42\ 299\ 663& ?  
  \end{tabular}
\vspace{1cm}

\caption{The number of $\L$- or $\R$-classes in $\Bn$.} 
  \label{tab:NumberLRClasses}
\end{table}

Even determining the possible cardinalities of row spaces of matrices in $\Bn$
is a hard problem: see \cite{Breen2001aa, Konieczny1992aa, Li1995aa,
  Shaofang1998aa, Zivkovic2006aa}. This is in stark contrast to the row-spaces
of matrices over fields, which have dimension a power of the cardinality of the
field. For example, the matrix \[\mat{0}{1}{1}{1} \in \Bn\] has row space
cardinality $3$.

It is significantly more difficult to determine the $\J$-relation in $\Bn$ than
the $\L$- or $\R$-relation. Indeed, the problem of determining whether two
matrices are $\J$-related in $\Bn$ is NP-hard~\cite[Theorem 2.7]{Fenner2018aa}.
The $\J$-relation on $\Bn$ is characterised by row space embeddings in the
following theorem; a function $f: R(A) \to R(B)$ is a \defn{row space embedding}
if it respects containment and non-containment, i.e.\ $f(v) \leq f(w)$ if and
only if $v \leq w$ for all $v, w,
\in R(A)$.
\begin{thm}[Zaretskii's Theorem~\cite{Zaretskii1963aa}]
  \thlabel{thm:Zaretskii}
  Let $A, B \in \Bn$. Then $A \leq_{\J} B$ if and only if there exists a row
  space embedding $f: R(A) \to R(B)$.
\end{thm}
Zaretskii's Theorem reduces the problem of determining the $\J$-order $\Bn$ to
problem of digraph embedding, but it should be noted that the size of $R(A)$ is
bounded above by $2^n$, and equality is possible. Computing the $\J$-structure of
$\Bn$ is challenging; see \cite{Breen1997aa}. The largest $n$ for which the
number of $\J$-classes of $\Bn$ is known is $8$; see \cite{Breen2001aa}.


Considering rows as subsets of $\{1, \ldots, n\}$, it is natural to consider
when rows of a matrix $A \in \Bn$ are contained in other rows of $A$. We will
call $A$ \defn{row-trim} if no non-zero row of $A$ is contained in another row.
\defn{Column-trim} is defined dually. We say that $A$ is \defn{trim} if it is
both row-trim and column-trim.

Our interest in trim matrices is due to the following result.

\begin{lemma}[{\cite[Lemma 3.1]{Konieczny2011aa}}]
  \thlabel{lem:PrimeMatricesAreTrim}
  Every prime matrix in $\Bn$ is trim.
\end{lemma}
\begin{proof}
  Let $A \in \Bn$ be prime. Suppose some non-zero row indexed $k$ of $A$ is
  contained in a row indexed $l$ of $A$. Define $X \in \Bn$ to be the matrix
  such that $X_{ij} = 1$ precisely if $A_{j*} \leq A_{i*}$. Then $XA = A$, and
  since $|X_{l*}| \geq 2$, $X \not\in S_n$, a contradiction. A dual argument
  shows that no non-zero column of $A$ is contained in another column.
\end{proof}

It is difficult to enumerate prime matrices directly, but comparatively simple
to enumerate trim matrices. This is key to our strategy for computing a minimal
generating set for $\Bn$.

The technique used to define the matrix $X$ in the proof of
\thref{lem:PrimeMatricesAreTrim} will be useful throughout. Given two matrices
$A, B \in \Bn$, we say that the \defn{greedy left multiplier} of $(A, B)$ is the
matrix $C$ containing a $1$ in position $j$ of row $i$ if and only if $A_{j*}
\leq B_{i*}$. The \defn{greedy right multiplier} of $(A, B)$ is the matrix $D$
containing a $1$ in position $j$ of row $i$ if and only if $A_{*i} \leq B_{*j}$.
Observe that if $r(A)$ is contained in $R(B)$, then every row $v$ of $A$ may be
written as the linear combination of those rows of $B$ which are contained in
$v$; hence $A = CB$ where $C$ is the greedy left multiplier of $(A, B$).
Combining this observation with \thref{lem:GreensRowColumnSpaces} yields the
following lemma:
\begin{lemma}
  \thlabel{lem:GreedyMultipliers}
  For any $A, B \in \Bn$ and $C$ the greedy multiplier of $(A, B)$, the
  following are equivalent:
  \begin{enumerate}[label={\rm (\roman*)}]
    \item $A = CB$
    \item $A \leq_\L B$
    \item $R(A) \subseteq R(B)$.
  \end{enumerate}
  The dual statement holds for greedy right multipliers, Greens $\R$-order, and
  column spaces.
\end{lemma}

A similar property to being trim is being \defn{reduced}. A matrix $A \in \Bmn$
is \defn{row-reduced} if no row of $A$ can be written as a union of other rows
of $A$. \defn{Column-reduced} is defined dually. We say that $A$ is
\defn{reduced} if it is both row-reduced and column-reduced. Since no row of a
trim matrix is contained in another row, it follows that no row can be expressed
as a union of other rows. A dual argument applies to columns, and hence we have
the following lemma.

\begin{lemma}
  \thlabel{lem:TrimMatricesAreReduced}
  Every trim matrix is reduced.
\end{lemma}

The following lemma describes the $\J$-relation on reduced matrices in $\Bn$.

\begin{lemma}[{\cite[Theorem 1.8]{Plemmons1970aa}}]
  \thlabel{lem:PermutingReducedMatrices}
  Let $A, B \in \Bn$ be reduced. Then $A \J B$ if and only if $A$ and $B$ are
  similar.
\end{lemma}

Due to the previous lemma, reduced matrices are particularly convenient to
compute with. A linear reduction to graph isomorphism, described in
Section~\ref{sec:FullBoolMat}, shows that the problem of determining whether two
reduced matrices are $\J$-related has the same complexity as graph isomorphism.
A recent paper of Babai claims that this complexity is at most quasi-polynomial;
see~\cite{Babai2016aa}.
The previous lemma also implies that the $\J$-class of any prime matrix $P$
consists of prime matrices similar to $P$, and we refer to such a $\J$-class as
a \defn{prime $\J$-class}. Note that a prime $\J$-class therefore contains at
most $(n!)^2$ elements. This observation, combined with Devadze's Theorem, has
the following corollary.

\begin{cor}
  \thlabel{cor:ExponentialGenSets}
  The size $\mathbf{d}(\Bn)$ of a minimal generating set for $\Bn$ grows
  super-exponentially with $n$.
\end{cor}
\begin{proof}
  This follows from the fact that there at least $2^{\frac{n^2}{4} - O(n)}$
  prime boolean matrices in $\Bn$ (see~\cite[Theorem 2.4.1]{Kim1982aa}) and each
  prime $\J$-class contains at most $(n!)^2$ elements; hence there are
  super-exponentially many prime $\J$-classes.
\end{proof}
%TODO: add lower bounds here - can only do once can access book

The prime matrices of $M_n(\mathbb{S})$ sit directly below the group of units in
the $\J$-order on $M_n(\mathbb{S})$ for any semiring $\mathbb{S}$. In the case of
$\Bn$, there is an additional $\J$-class immediately below $S_n$: the $\J$-class
$J_E$ of the elementary matrix $E$ from \eqref{eq:RegularGens}. The next result shows that in
fact these are all of the $\J$-classes immediately below $S_n$.

Let $\beta_n$ denote the set $\set{R(A)}{A\in \Bn\setminus S_n}$ of all
possible proper row subspaces of elements of $\Bn$, and let $\B^n$ denote
the space of all boolean vectors of length $n$. Note that $A \in \Bn$ has row
space equal to $\B^n$ if and only if permutation matrices.

\begin{thm}[cf. Theorem 5.1 in~\cite{Caen1981ab}]
  \thlabel{thm:MaximalRowSpaces}
  Let $A \in \Bn\setminus S_n$. Then $R(A)$ is maximal with respect to
  containment in $\beta_n$ if and only if $A$ is prime or elementary.  
\end{thm}

We may now prove a slightly stronger form of Devadze's Theorem.

\begin{thm}[Devadze's Theorem \cite{Konieczny2011aa}]
  \thlabel{thm:Devadzefull}
  For $n > 2$, any minimal generating set for $\Bn$ is given by $\{T', U', E',
    F'\} \cup P$, where $T'$ and $U'$ generate $S_n$, $E'$ is elementary, $F'$
  is a matrix similar to $F$, and $P$ is a set of representatives of the prime
  $\J$-classes of $\Bn$. Conversely, any such set generates $\Bn$.
\end{thm}
\begin{proof}
  The converse follows immediately from \thref{thm:DevadzeKon}, noting that $A
  \in \genset{\{A', T', U'\}}$ for any similar matrices $A, A' \in \Bn$.

  Let $X$ be a minimal generating set for $\Bn$. Since $\mathbf{d}(S_n) = 2$,
  and $X$ must contain generators of the group of units $S_n$, it follows that
  $X$ contains two elements which together generate $S_n$, which we denote by
  $T'$ and $U'$. By \cite[Lemma 4.2]{Konieczny2011aa}, $X$ also contains a set
  $P$ of representatives of the prime $\J$-classes of $\Bn$. By \cite[Lemma
  4.5]{Konieczny2011aa}, and the fact that the elementary $\J$-class lies
  immediately below the group of units, $X$ must also contain an elementary
  matrix, say $E'$. It only remains to show that $X$ must contain a matrix
  similar to $F$. Since none of the elements of $P$, nor $E'$, contain a
  zero row, $P \cup \{E'\}$ does not generate $F$, and $X$ must contain a matrix
  with at least one zero row. Since matrices similar to $F$ have the maximal row
  spaces amongst matrices containing zero rows, $X$ must contain a matrix
  similar to $F$.
\end{proof} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Full Boolean Matrix Monoid}
\label{sec:FullBoolMat}
As mentioned above, in order to compute minimal generating sets for $\Bn$ it is
sufficient to compute sets of representatives of the prime $\J$-classes of
$\Bn$. In this section we describe how such a computation may be performed.

The \defn{kernel} of a function $f: X \to Y$ is the equivalence relation
containing a pair $(a, b)$ if and only if $f(a) = f(b)$.
We call a function $\phi: \Bn \to \Bn$ a \defn{canonical form} if
$\ker\phi = \J$. Given a canonical form $\phi$, the image $\im\phi$ is a
set of representatives of the $\J$-classes of $\Bn$, and the image
$P_\phi = \phi(\set{A \in \Bn}{\text{$A$ prime}})$ is a set of
representatives of the prime $\J$-classes of $\Bn$. 

We wish to enumerate $P_\phi$ for some canonical form $\phi$. Roughly speaking,
our strategy is to enumerate efficiently as small a superset $Q_\phi \subsetneq
\im\phi$ of $P_\phi$ as is practical, and then to filter $Q_\phi$ to remove the
non-prime matrices.
The full image $\im\phi$ is a set of representatives for the $\J$-classes of
$\Bn$; Table~\ref{tab:BreenFormMatrices} demonstrates the growth of $\im\phi$ for
$n = 1, \ldots, 8$. The number of trim matrices in Breen form in $\Bn$ is
comparable to the number of $\J$-classes for $n \leq 8$.
Since is infeasible to compute the image of each of the $2^{n^2}$ elements of
$\Bn$ for $n \geq 7$; we instead compute the images of a smaller set of matrices
of a particular form, which contains at least one matrix of every $\J$-class of
$\Bn$.

\begin{de}[{{\cite[Proposition 3.6]{Breen1997aa}}}]
  \thlabel{de:BreenForm}
  We say that a matrix $A \in \Bmn$ is in \emph{Breen form} if it has all of
  the following properties:
  \begin{enumerate}[label={\rm (\roman*)}]
  \item{$A$ is reduced,}
  \item{all non-zero rows of $A$ are at the bottom,}
  \item{all non-zero columns of $A$ are at the right,}
  \item{the non-zero rows of $A$ as binary numbers are a strictly increasing
      sequence, as are the columns}
  \item{all ones in the first non-zero row of $A$ are on the right,}
  \item{all ones in the first non-zero column of $A$ are at the bottom,}
  \item{every non-zero row has at least as many ones as the first non-zero row.}
  \end{enumerate}
\end{de}

This definition appears as a proposition in \cite{Breen1997aa}; Breen defines a
matrix in $\Bn$ to be in \emph{standard form} if the matrix has minimal value as
a binary number in its $\J$-class, and proves that such a matrix has the
properties of \thref{de:BreenForm}~\cite[Proposition 3.6]{Breen1997aa}. This leads
directly to the following proposition:

\begin{prop}
  \thlabel{prop:BreenFormsExist}
  In every $\J$-class $\Bn$, there exists a matrix in Breen form. 
\end{prop}

In contrast, being in Breen form is not enough to guarantee that a matrix is
minimal. Consequently there is not a unique matrix in each $\J$-class of $\Bn$
in Breen form, as the following example demonstrates. 
\begin{ex}
  \thlabel{ex:SimilarBreenMatrices}
Let $A, B \in \Bn$ be the matrices defined by
\begin{align*}
  \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\quad \quad
  \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}&\\
\end{align*}
respectively. Then $A$ and $B$ are in the Breen form of
\thref{de:BreenForm}. Swapping rows $1$ and $2$ and columns $3$
and $4$ shows that $A$ and $B$ are similar, and hence are $\J$-related in $\Bn$.
\end{ex}

There are significantly fewer than $2^{n^2}$ matrices in Breen form in $\Bn$,
as shown in Table~\ref{tab:BreenFormMatrices}, and so it is feasible to
enumerate the matrices in Breen form for several values of $n$ for which it
is not feasible to enumerate the matrices in $\Bn$.
Given the set $S$ of matrices in Breen form in $\Bn$, and a canonical form
$\phi$, the image $Q_\phi = \phi(S)$ contains $P_\phi$. Later in this section,
we will discuss several methods of filtering $Q_\phi$ to obtain the prime
matrices. 

\begin{table}
  \centering
  \begin{tabular}{l|r|r|r|r|r}
    $n$ & $|\Bn|$ & $|\mathcal{B}_n|$ & $|\mathcal{TB}_n|$ & $\phi(\mathcal{TB}_n)$ &
    $|J(\Bn)|$~\cite{Breen2001aa, Breen1997aa} \\
      \hline
    $1$ & 2 & 2 & 2 & 2 & 2\\
    $2$ & 16 & 4 & 3 & 3 & 3\\
    $3$ & 512 & 13 & 5 & 5 & 11\\
    $4$ & 65\ 536 & 146 & 12 & 10 & 60\\
    $5$ & 33 554 432& 7\ 549 & 141& 32 & 877\\
    $6$ & 68\ 719\ 476\ 736& 1\ 660\ 301& 15\ 020 & 394 & 42\ 944\\
    $7$ & $5.6 \times 10^{14}$ & 1\ 396\ 234\ 450 & 7\ 876\ 125 & 34\ 014 & 7\ 339\ 704 \\
    $8$ & $1.8 \times 10^{19}$ & ? & 18\ 409\ 121\ 852 & 17\ 120\ 845 & 4\ 256\ 203\ 214
  
  \end{tabular}
  \vspace{1cm}

  \caption{The sizes of: the monoid $\Bn$, the set $\mathcal{B}_n$ of matrices
    in $\Bn$ in Breen Form; the set $\mathcal{TB}_n$ of trim matrices in Breen
    form in $\Bn$; the image $\phi(\mathcal{TB}_n)$ of the trim Breen-form
    matrices under any canonical form $\phi$; and the set $J(\Bn)$ of
    $\J$-classes of $\Bn$.}
  \label{tab:BreenFormMatrices}
\end{table}

While theoretically any canonical form $\phi$ is sufficient, the complexity of
computing $\phi$ is important. We now describe how to obtain canonical forms
$\Phi_n$ that are practical to compute with, using a reduction to bipartite
graphs.

Given a matrix $A \in \Bn$, we may form the vertex-coloured bipartite graph
$\Gamma(A)$ with vertices $\{1, \ldots, 2n\}$, colours 
\[\mathbf{col}(v) = \begin{cases}
    0 \qquad &1 \leq v \leq n, \\
    1 \qquad &n < v \leq 2n,
  \end{cases}
\]
and an edge from $i$ to $j+n$ if and only if $A_{ij} = 1$. The numbers $\{1,
  \ldots, n\}$ represent indices of rows and the numbers $\{n + 1, \ldots, 2n\}$
represents indices of columns in the matrix $A$.

It is easy to see that $\Gamma$ is a bijection from $\Bn$ to the set $\BGSet$ of
bipartite graphs with two parts of size $n$, where one part is coloured $0$ and
the other coloured $1$. We call a function $\psi: \BGSet \to \BGSet$ a
\defn{canonical form} for $\BGSet$ if the equivalence classes of $\ker\psi$ are
the graph-theoretical colour-preserving isomorphism classes of $\BGSet$.
Computing canonical forms for graphs is a well-studied problem; for a recent
article see~\cite{McKay2013aa} and the references within. 
and we use the software bliss\footnote{In fact, a slightly-modified version of
  bliss which avoids repeated memory allocation was used; this is available at
  \cite{https://github.com/james-d-mitchell/bliss}}~\cite{Junttila2007aa, Bliss} to obtain such functions $\psi_n$. 
\begin{lemma}
  \thlabel{lem:GraphCanonicalForms}
  The functions $\Phi_n = \Gamma^{-1}\psi_n\Gamma$ are canonical forms when
  restricted to reduced matrices. 
\end{lemma}
\begin{proof}
  We must show that $\ker\Phi_n = \J$, in other words $\Phi_n(A) = \Phi_n(B)$ if and
  only if $A\J B$. This is equivalent to showing $\Gamma(A)$ is isomorphic to
  $\Gamma(B)$ if and only if $A \J B$. Denote the vertices of $\Gamma(A)$ by
  $\{1, \ldots, 2 n\}$ and the vertices of $\Gamma(B)$ by $\{1', \ldots, 2n'\}$,
  as above.
  Suppose that there is a colour-preserving isomomorphism $\Psi: \Gamma(A) \to
  \Gamma(B)$. Since $\Psi$ preserves colours, $\Psi$ maps $\{1, \ldots, n\} \to
  \{1', \ldots, n'\}$ and $\{n + 1, \ldots, 2n\} \to \{(n + 1)', \ldots, 2n'\}$.
  Define permutations $\alpha, \beta$ on $\{1,\ldots, n\}$ by 
  \begin{align*}
    \alpha(i) &= j \text{ if } \Psi(i) = j',\\
    \beta(i)  &= j \text{ if } \Psi(n + i) = (n + j)'.
  \end{align*}
  Then by permuting the rows and columns of $A$ by $\alpha$ and $\beta$
  respectively, $A$ is similar to $B$ and hence $A \J B$ in $\Bn$.

  Conversely, suppose that $A \J B$ in $\Bn$. Then by
  \thref{lem:PermutingReducedMatrices}, there exist $\alpha$ and $\beta$ such
  that by permuting the rows and columns of $A$ by $\alpha$ and $\beta$
  respectively $B$ is obtained. The map $\Psi$ defined by
  \[\Psi(i) = \begin{cases}
      j' \quad &\text{if } 1 \leq i \leq n \text{ and }\alpha(i) = j, \\
      (n + j)' \quad &\text{if } n < i \leq 2n \text{ and }\beta(i) = j
    \end{cases}
  \]
  is a colour-preserving isomorphism between $\Gamma(A)$ and $\Gamma(B)$.
\end{proof}

Given $v \in \B^n$, it will convenient to denote the number represented by $v$
in binary as $\num(v)$. We will also write $\vect$ for $\mathbf{num}^{-1}$.

We now describe how to backtrack through matrices in Breen form to find a
superset of prime matrices $Q_{\Phi_n}$. This may be seen as a depth-first
traversal of a (non-rooted) tree, with nodes $m\times n$ matrices ($m \leq
n$) and leaves $n \times n$ matrices.

\begin{alg}
  \thlabel{alg:canonicalbacktrack}Backtracking for canonical forms.\\
  \textbf{Input}: A natural number $n$. \\
  \textbf{Output}: A set $Q_{\Phi_n}$, with $P_{\Phi_n} \subseteq Q_{\Phi_n}
  \subseteq \im\Phi_n$.
  \begin{enumerate}
    \item We assume that we are at a node $A$ of dimension $m \times n$, and the
      index of the first non-zero row of $A$ is $f \leq m$. 
    \item If $m = n$, the non-zero columns of $A$ form a strictly increasing
      sequence under $\num$, and $A$ is column-reduced, then add $\Phi_n(A)$ to
      $X$, the set of matrices to return.
    \item If $m < n$, then for each $x \in \{\bar{A_{m*}} + 1,
        \ldots, 2^n - 1\}$, if:
      \begin{enumerate}[label={(\roman*)}]
        \item $\vect(x)$ does not contain $A_{l*}$ for any $1 \leq l \leq m$,
          and
        \item $\vect(x)$ has at least as many ones as $A_{f*}$,
        \item for all column indices $1 \leq i < j \leq m$ such that $A_{*i} =
          A_{*j}$, if $\vect(x)_i = 1$ then $\vect(x)_j = 1$.
      \end{enumerate}
      set the current node to be the matrix obtained from $A$ by adjoining
      $x^\dagger$ as the last row, and return to step 1.
    \item after every $x$ has been processed, return to the previous node (if
      any) and carry out step $3$ for the next $x$ at that node (if any).
  \end{enumerate}
  Having initialised step $1$ with each $m \times n$ matrix ($m \geq 1$)
  consisting of $m - 1$ zero rows followed by a row containing some non-zero
  number of $1$s on the right, return $X$.
\end{alg}

\begin{lemma}
  \thlabel{lem:backtrackworks}
  The output of \thref{alg:canonicalbacktrack}, with input $n$, is a subset of
  $\im\Phi_n$ containing $P_{\Phi_n}$. Moreover, \thref{alg:canonicalbacktrack}
  does not compute $\Phi_n(A)$ of any matrix $A$ not in Breen form.
\end{lemma} 
\begin{proof}
  We will prove that the $A$s of step $4$ for which $\Phi_n(A)$ are calculated
  are precisely the set of trim matrices in Breen form; since every prime
  matrix is trim (\thref{lem:PrimeMatricesAreTrim}) and every $\J$-class
  contains a matrix in Breen form, this implies that the output contains
  $P_{\Phi_n}$. We will first prove that each such $A$ is in Breen form.

  Define a matrix to be in \emph{quasi-Breen form} if it satisfies each
  property of \thref{de:BreenForm} other than being column reduced and the
  non-zero columns forming a strictly-increasing sequence.
  We will prove that each node $A$ visited in the algorithm is trim and in
  quasi-Breen form. Note that the matrices that the algorithm is initialised
  with are all trim and in quasi-Breen form, so we must simply prove that
  passing from a node $A$ which is trim and in quasi-Breen form to a node
  $A'$ by adding a row $x^{\dagger}$ in step $3$ preserves these properties.

  Trimness is preserved due to condition (i) of step $3$. Since all trim
  matrices are reduced, $A'$ is also reduced. The conditions on non-zero rows
  being at the bottom and forming a strictly increasing sequence of binary
  numbers are satisfied by choosing $x$ from the range $\{\bar{A_{m*}} + 1,
    \ldots, 2^n - 1\}$.  The conditions on non-zero columns being on the right
  follows from requirement (iii) of step $3$; note that this requirement also
  forces the columns to appear in (not-necessarily-strictly) increasing order.
  The first non-zero column contains the most significant digit of the rows as
  binary numbers, and since the rows of $A'$ are increasing the set of rows with
  that digit equal to $1$ must be contiguous and at the end of $A'$. Hence all
  of the ones in the first non-zero column of $A'$ are at the bottom.

  Since each leaf $A$ visited is trim and in quasi-Breen form, the two
  conditions of step 2, that the non-zero columns form a strictly increasing
  sequence and that $A$ is column-reduced, guarantee that $A$ is in standard
  form. Hence, we only calculate the canonical form $\Phi_n(A)$ if $A$ is trim
  and in Breen form.

  It remains to prove that every trim matrix $A \in \Bn$ in Breen form is
  visited as a node in the enumeration. First, note that the first $m$ rows of
  any trim, standard-form matrix $A \in \Bn$ form an $m \times n$ trim matrix in
  quasi-Breen form. Also, the zero-rows of $A$ together with the first
  non-zero row form one of the matrices with which step $1$ is initialised. It
  simply remains to show that from each $m \times n$ node $X$ consisting of the
  first $m$ rows of $A$, we visit the $(m + 1)\times n$ node $X'$ consisting of
  the first $m + 1$ rows of $A$. It is easy to verify that each of the three
  conditions in step $3$ is satisfied by row $m + 1$ of $A$, and hence $X'$ is
  visited.
\end{proof}

Given $\Phi_n$ and $Q_{\Phi_n}$, the final step is to detect when an element of
$Q_{\Phi_n}$ is prime. We present two algorithms for doing so, in
\thref{alg:filter1} and \thref{alg:filter2}.

\begin{alg}
  \thlabel{alg:filter1}Filtering canonical forms by row spaces.\\
  \textbf{Input}: A set $Q_{\Phi_n}$, containing the images $P_{\Phi_n}$ of the
  prime matrices of $\Bn$ under $\Phi_n$, and not containing any permutation
  matrices. \\
  \textbf{Output}: The set $P_{\Phi_n}$.
  \begin{enumerate}
  \item 
    Compute $X = \set{R(A\alpha)}{A \in Q_{\Phi_n} \cup \{E\}, \alpha \in S_n}$
  \item
    For every $A \in Q_{\Phi_n}$, and for every $R(B\beta) \in X$, if $A \neq B$ and
    $R(A) \subsetneq R(B\beta)$ then discard $R(A\alpha)$ from $X$ for all
    $\alpha \in S_n$.
  \item
    Output $T\subset Q_{\Phi_n}$, the set of non-elementary elements $A$ such that $R(A)$
    remains in $X$ after the previous step.
  \end{enumerate}
\end{alg}

\begin{lemma}
  The output of \thref{alg:filter1} is a set of representatives of prime
  $\J$-classes.
\end{lemma}
\begin{proof}
  Since the $\J$-class of a prime matrix consists only of similar matrices, the
  set $\set{R(A\alpha)}{A \in P_{\Phi_n}} \subset X$ contains all row spaces of
  prime matrices in $\Bn$, and hence so does $X$. Similarly, $X$ contains the
  row space of every elementary matrix. Hence, the elements that are maximal in
  $X$ are precisely the maximal elements of $\beta_n$ and thus by
  \thref{thm:MaximalRowSpaces} correspond to primes and elementary matrices.
  Since $R(A)$ remains in $X$ after step 2 precisely when $R(A)$ (and
  $R(A\alpha)$, for all $\alpha \in S_n$) is maximal in $X$, the output is
  $P_{\Phi_n}$.
\end{proof} 

Note that step 2 of \thref{alg:filter1} requires $O(|Q_{\Phi_n}||X|)$ comparisons.  The
size of $X$ grows extremely rapidly with $n$ as shown in
Table~\ref{tab:filter1numbers}, and so this algorithm is only suitable for small $n$.
\begin{table}
  \centering
  \begin{tabular}{l|r|r}
    $n$ & $|Q_{\Phi_n}|$ & $|X|$ \\
    \hline
    3 & 6 & 91 \\ 
    4 & 11 & 588 \\
    5 & 33 & 8194 \\
    6 & 395 & 570\ 636 \\ 
    7 & 34\ 015 & 342\ 915\ 296 \\
    8 & 17\ 120\ 845 & ? 
  \end{tabular}
\vspace{1cm}

\caption{The number of row spaces generated during \thref{alg:filter1} when
  given input $Q_{\Phi_n}$, the output of \thref{alg:canonicalbacktrack}}. 
  \label{tab:filter1numbers}
\end{table}

Using \thref{alg:canonicalbacktrack} and \thref{alg:filter1}, minimal
generating sets for $n \leq 7$ may be obtained.

For $n=8$ this algorithm is no longer sufficient, and it is necessary to use
heuristics to reduce the size of $Q$. The simplest way to do this is to select a
small subset $X \subset Q$ of matrices with large row spaces, generate the row
spaces $Y = \{R(A\alpha) :\: A \in X\} \subset R$, and check whether $R(B)$ is
contained in any element of $Y$ for each element $B \in Q$.  It is also
worthwhile to filter $R$ by checking containment in the row spaces of all the
column permutations of a known set of prime matrices, such as those described in
the following lemma.

\begin{lemma}
  \thlabel{lem:ExtendingPrimeMatrices}
  Let $A$ be a prime matrix in $M_{n-1}(\B)$. Extend $A$ to a matrix $B \in \Bn$
  by adding a row of zeros at the bottom and a column of zeros on the right,
  then setting $B_{n,n} = 1$. Then $B$ is prime in $\Bn$.
\end{lemma}
\begin{proof}
  Let $C$ be a matrix with row space maximal in $\beta_n$, such that $R(B)
  \subseteq R(B)$.  The last row of $B$ must also be in $C$ since it is a
  minimal in $\B^{n}$. Now $R(A)$ has a unique basis of $n-1$ rows which must be
  contained in both $B$ and $C$, so we have $r(B) = r(C)$; hence $R(B)$ is
  maximal in $\beta_n$. Since $B$ is not elementary, it is prime.
\end{proof}

For $n=8$ prefiltering by some of the large row spaces and extended prime
matrices is enough to obtain a minimal generating set, though the computation is
lengthy; see Table~\ref{tab:runtimestats} for some details. A significant
improvement can be obtained by using Zaretskii's Theorem.

\begin{table}
  \centering
  \begin{tabular}{l|r|r|r|r|r|r}
    $n$ & \thref{alg:canonicalbacktrack} & \thref{alg:filter1} &
    \thref{alg:filter2} & prefiltering & \thead{\thref{alg:filter1} with \\
      prefiltering}  & \thead{\thref{alg:filter2} with \\ prefiltering} \\
    \hline
    1 & ? & ? & ? & ? & ? \\
    2 & ? & ? & ? & ? & ? \\
    3 & ? & ? & ? & ? & ? \\
    4 & ? & ? & ? & ? & ? \\
    5 & ? & ? & ? & ? & ? \\
    6 & ? & ? & ? & ? & ? \\
    7 & ? & ? & ? & ? & ? \\
    8 & ? & ? & ? & ? & ?
  \end{tabular}
\vspace{1cm}

% include prefiltering stats (choose x% of the largest row spaces?)
\caption{Runtime of different filtering approaches; executed on TODO}
  \label{tab:runtimestats}
\end{table}


Let $A \in \Bn$. The \defn{graph} of $R(A)$ is the directed graph with vertices
$R(A)$ and an edge from $v$ to $w$ if $v \leq w$. The graph of $C(A)$ is defined
analogously.

It is an immediate corollary of Zaretskii's Theorem that $A \leq_{\J} B$ if and
only if there exists a homomorphic embedding of the graph of $R(A)$ into the
graph of $R(B)$ which respect non-edges. An efficient and optimised search for
such embeddings is implemented in~\cite{Digraphs2020aa}.

For practical computational purposes, it is useful to add extra structure to the
row space graphs to guide searches for embeddings. The \emph{augmented graph of
  $R(A)$} is the disjoint union of the graph of $R(A)$ with the empty graph on
the vertices $C = \{c_i \: : \: 1 \leq i \leq n\}$, with an edge from $v \in R(A)$
to $c_i$ if $v_i = 1$.

\begin{lemma}
  \thlabel{lem:EmbeddingGraphs}
  Let $Q$ be a superset of a canonical set of prime matrices $P$ which does not
  contain a permutation matrix, and let $A \in
  Q$. Then $A$ is not prime or elementary if and only if for some $B \in
  (Q\cup\{E\})\setminus\{A\}$ there exists a digraph embedding
  $\phi$ from the augmented graph of $R(A)$ into the augmented graph of $R(B)$
  which permutes $\{ c_i : 1 \leq i \leq n \}$ and respects non-adjacency.
\end{lemma}
\begin{proof}
  Let $A$ not be prime or elementary; then $R(A)$ is contained in the row space
  of some column permutation $\alpha$ of a $B \in Q \setminus \{A\}$.
  Then the embedding that extends the map $c_i \to c_{\alpha^{-1}i}$ has the
  properties required. Conversely, if such a map $\phi$ exists, the permutation
  $\alpha$ induced by the restriction to $C$ has the property that
  $R(B\alpha^{-1})$ contains $R(A)$, and hence by \thref{thm:MaximalRowSpaces}
  $A$ is not prime or elementary. 
\end{proof}

Note that such an embedding $\phi$ must also map a vector containing $i$ ones to
another containing $i$ ones to preserve adjacency and non-adjacency with the set
$C$.

We can therefore use the following improved algorithm to filter canonical
supersets of prime matrices.

\begin{alg}
  \thlabel{alg:filter2} Filtering canonical forms by digraph embeddings.\\
  \textbf{Input}: A set $Q_{\Phi_n}$, containing the images $P_{\Phi_n}$ of the
  prime matrices of $\Bn$ under $\Phi_n$, and not containing any permutation
  matrices. \\
  \textbf{Output}: The set $P_{\Phi_n}$.
  \begin{enumerate}
  \item
    Generate the set $G$ of augmented graphs of row spaces of matrices in $Q$.
  \item 
    For every $K, L \in G$, if there exists an embedding of $K$ into $L$ as in
    \thref{lem:EmbeddingGraphs}, then discard $K$ from $G$.
  \item
    Output $X\subset Q$, the set of non-elementary elements $A$ with
    corresponding graphs remaining in $G$ after the previous step.
\end{enumerate}
\end{alg}

Note that this is in effect the same computation as in \thref{alg:filter1}; it
replaces a brute-force search through all permutations of columns with a guided
search for an appropriate permutation. It is also superior in that no more data
has to be computed, unlike \thref{alg:filter1} where new row spaces must be
produced for each column permutation. Additionally, information about the graphs
can be reused (in particular their automorphism group). However, this is not as
useful as it might seem, since the automorphism group of prime row spaces
appears to be almost always be trivial.

Using this method of filtration, a minimal generating sets for $\Bn$, $6 \leq n
\leq 8$ have been computed; the size of such generating sets is contained in
Table~\ref{tab:BMatResults}. It seems unlikely that these methods can produce
minimal generating sets for $n > 8$. The generating sets obtained from this
algorithm are obtainable at TODO, along with code to produce them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reflexive Boolean Matrices}
\label{sec:RefBoolMat}
An interesting submonoid of $\Bn$ is the monoid $\Refn$ of reflexive boolean
matrices, i.e. boolean matrices with $1$s on the main diagonal. Minimal
generating sets for $\Refn$ are significantly larger than those of $\Bn$.
\begin{thm}
  \thlabel{thm:ReflexiveGenSet}
  The unique minimal monoid generating set for $\Refn$ consists of the set of
  elementary matrices in $\Refn$ together with the set of indecomposable trim
  matrices in $\Refn$.
\end{thm}

In order to prove this theorem, we must understand the  $\J$-relation on
$\Refn$. Let $A, B$ be two matrices belonging to $\Refn$. Observe that since $A,
B$ both contain the identity matrix, the product $AB$ must contain both every
row of $A$ and every column of $B$; hence $A \leq AB$ and $B \leq AB$. This
leads to the following well-known fact:

\begin{lemma}
  \thlabel{lem:ReflexiveJRelation}
  $\Refn$ is $\J$-trivial. 
\end{lemma}
\begin{proof}
  If $A \J B$, then $A \leq B$ and $B \leq A$ with respect to containment. Hence
  $A = B$.    
\end{proof}
Note that it also follows that $AB$ has at least as many $1$s as the maximum
number of $1$s in $A$ or $B$. It also follows from the lemma that any
decomposable element $A$ is decomposable into a product of elements not
$\J$-related to $A$.

We now prove several results relating to decomposability of elements in $\Refn$.

\begin{lemma}
  \thlabel{lem:ReflexiveNonTrimDecomposable}
  Every matrix in $\Refn$ that is neither trim nor elementary is decomposable in
  $\Refn$.
\end{lemma}
\begin{proof}
  Let $A \in \Refn$ be neither trim nor elementary.
  Since $A$ is not trim, it is either not row-trim or not column-trim (or both).
  Suppose that $A$ is not row-trim; then there exist some $1 \leq i, j
  \leq n$ such that the $i$th row $A_{i*}$ is contained in the $j$th row
  $A_{j*}$.
  Let $B$ be the matrix obtained by setting entry $i$ of row $j$ of $A$ to be
  equal to $0$, that is
  \[B_{kl} = \begin{cases} 
                0 \quad& k = i \text{ and } l = j \\ 
                A_{kl} \quad& \text{otherwise.} 
              \end{cases} \]
  Since $i \neq j$ and $A$ is reflexive, so too is $B$. Now $B_{j*} \cup A_{i*}
  = A_{j*}$, and so $A = E^{j,i}B$. By \thref{lem:ReflexiveJRelation} neither
  $E^{j,i}$ nor $B$ is $\J$-related to $A$.
  
  If, instead, $A$ is column trim, then the same argument applied to the
  transpose $A^T$ demonstrates that $A^T$ may decomposed in such a way, and thus
  $A$ may also.
\end{proof}

\begin{lemma}
  \thlabel{lem:reflexiveelementaryindecomposable}
  Elementary matrices are indecomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Elementary matrices are precisely those matrices in $\Refn$ containing $n + 1$
  ones. By the observation that the product of two matrices in $\Refn$ contain
  at least as many $1$s as the maximum number of ones in a factor, it follows
  that if an elementary matrix is decomposable it is decomposable into other
  elementary matrices. However, it is easy to show that the only way of writing
  a reflexive elementary matrix $E$ as a product of elementary matrices is $E =
  E^{k}$; hence elementary matrices are indecomposable.
\end{proof}

\begin{cor}
  \thlabel{cor:reflexiveindecomposable}
  An indecomposable element of $\Refn$ is either trim or elementary.
\end{cor}

\begin{proof}[Proof of \thref{thm:ReflexiveGenSet}]
  Let $T$ denote the set of indecomposable trim matrices, and $\mathcal{E}$
  denote the set of reflexive elementary matrices. By
  \thref{ReflexiveJRelation} and \thref{cor:reflexiveindecomposable}, it follows
  from \thref{lem:GenSetDecomposition} that $\genset{T \cup \mathcal{E}} =
  \Refn$. Since each element of $T \cup \mathcal{E}$ is decomposble, $T \cup
  \mathcal{E}$ must be contained in any generating set for $\Refn$, and hence is
  minimal.
\end{proof}

We now discuss how such minimal generating sets may be computed. Since it is
easy to enumerate the reflexive elementary matrices, the problem is determining
the set of indecomposable trim matrices in $\Refn$.
The following lemmas give a method for testing indecomposability.

\begin{lemma}
  \thlabel{lem:decomposeintersection}
  A trim matrix $A \in \Refn$ can be decomposed as $A = BC$, $B, C \in
  \Refn\setminus\{I, A\}$, if and only if $A = B'C'$ where $C'$ is the matrix
  whose $i$th row $C_i$ is the intersection 
  \[ C_i = \cap_{K_i} A_i \]
  where $K_i$ is the positions of the $1$s in the $i$th column of $B$, $B'$ is
  the greedy left multiplier of $(C', A)$, and $B', C' \in \Refn
  \setminus\{A\}$.
\end{lemma}
\begin{proof}
  ($\Rightarrow$)
  Suppose that $A = BC$ for $B, C \in \Refn \setminus\{I, A\}$, and let $B', C',
  K_i$ be defined as above. Fix $i$, and consider the $i^{\text{th}}$ row $C_i'$
  of $C'$. By the definition of $K_i$, for each $j \in K_i$, we have $C_i \leq
  A_j$; hence $C_i \leq C'_i = \cap_{K_i} A_j \leq A_j$. This implies that $A =
  BC'$, since $A = BC \leq BC' \leq A$. By \thref{lem:GreedyMultipliers}, $A =
  B'C'$. Observe that since $A = BC'$, by the definition of the greedy left
  multiplier we must have $B \leq B'$. Hence $B' \in \Refn$. Since $C_i \leq
  C'_i$ for all $i$, $C'$ is also in $\Refn$. It remains to show that neither
  $B'$ nor $C'$ belongs to $\{I, A\}$. Note that since $B \leq B'$ and $C \leq
  C'$, $B', C'$ are not the identity matrix. Since $A$ is trim, if $B'$ or $C'$
  were equal to $A$ the product $B'C'$ would have more ones than $A$ does, but
  $A = B'C'$.
  \\ ($\Leftarrow$) Immediate.
\end{proof}
Hence, in order to determine whether a trim matrix $A$ is decomposable it
suffices to:
\begin{enumerate}
  \item generate all matrices $C$ with rows intersections of rows of $A$, and
    for each $C$
  \item test whether the product $BC$ of $C$ with the greedy left multiplier
    $C$ of $(A, B)$ is equal to $A$, and $B, C \not\in \{I, A\}$.
\end{enumerate}
If no such matrices $B, C$ are found, then $A$ is indecomposable. This method is
clearly superior to checking all products of matrices in $\Refn$, but still
quickly becomes infeasible to use for all trim matrices in $\Refn$.\\

In order to reduce the time spent checking matrices using
\thref{lem:decomposeintersection}, we would like to only check the smallest
necessary set of representatives of some equivalence relation. The most obvious
choice is to take canonical representatives in $\Bn$. However, the following
example illustrates that two reduced reflexive matrices can belong to the same
$\J$-class of $\Bn$ while only one of them is decomposable in $\Refn$; hence we
can not use the same canonical forms $\Phi_n$ as were used in
\thref{alg:canonicalbacktrack}, \thref{alg:filter1}, and \thref{alg:filter2}. 
\begin{ex}
  Let
\begin{align*}
  A = \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\text{, }&
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
Then $A, B \in \Ref{5}$, and $B$ may be obtained by exchanging columns $3$ and
$5$ of $A$. However, $A$ is indecomposable whilst
\begin{align*}
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 \\
    1 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1 
  \end{pmatrix}
  \begin{pmatrix}
    1 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
\end{ex} 

However, the following lemma shows that we should consider more restricted
permutations.

\begin{lemma}
  \thlabel{lem:reflexivecanonical}
  Let $A, B \in \Refn$ be such that $A = P^{-1} B P$ for some permutation matrix
  $P \in S_n$ (i.e. $A$ is obtained by permuting the rows and columns of $B$ by
  the same permutation). Then $A$ is decomposable in $\Refn$ if and only if $B$
  is decomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Suppose that $B = XY$ for $X, Y \in \Refn\setminus \{I, A\}$. Then $P^{-1}XP,
  P^{-1}YP \in \Refn\setminus\{I, A\}$ and $P^{-1}XPP^{-1}YP = A$. The proof of
  the other direction is dual, since $PAP^{-1} = B$.
\end{proof}

Hence it is sufficient to consider representatives of the equivalence relation
which relates any two matrices which are similar under the same row and column
permutation. In order to compute these representatives, we modify the
construction of the bipartite graphs $\Gamma$ of Section~\ref{sec:FullBoolMat}.

Given a matrix $A \in \Refn$, we form the vertex-coloured tripartite graph
$\Gamma_\text{id}(A)$ with vertices $\{1, \ldots, 3n\}$, colours 
\[\mathbf{col}(v) = \begin{cases}
    0 \qquad &1 \leq v \leq n, \\
    1 \qquad &n < v \leq 2n, \\
    2 \qquad &2n < v \leq 3n,
  \end{cases}
\]
, an edge from $i$ to $j+n$ if and only if $A_{ij} = 1$ for $1 \leq i \leq n$,
and an edge from $i + 2n$ to $i$ and $i + n$ for $1 \leq i \leq n$. The numbers $\{1,
  \ldots, n\}$ represent indices of rows, and the numbers $\{n + 1, \ldots, 2n\}$
represents indices of columns in the matrix $A$. The additional vertices $\{2n +
  1, \ldots, 3n\}$, adjacent to both the corresponding row and column nodes,
force an isomorphism of $\Gamma_\text{id}(A)$ to induce the same permutation on rows and
columns of $A$ in the same way that a permutation was induced in
\thref{lem:GraphCanonicalForms}. As before, we may obtain canonical forms
$\Psi_n$ for the graphs $\Gamma_{\text{id}}(A)$ via bliss. Since
$\Gamma_\text{id}$ is clearly injective, we may compute the functions
$\Xi_n = \Gamma_\text{id}\Psi_n\Gamma_\text{id}^{-1}$. It is easy to show that
the equivalence classes $\ker\Xi$ are precisely the classes of matrices which
are similar under permuting rows and columns by the same permutation.

As in Section~\ref{sec:FullBoolMat}, we wish to only enumerate matrices of a
certain form. A similar argument to \cite[Proposition 3.6]{Breen1997aa} shows
that by permuting the rows and columns of matrices by the same permutation,
matrices in $\Refn$ can be put in the following \defn{reflexive Breen form}:

\begin{enumerate}[label={\rm (\roman*)}]
  \item{all $1$s in the first row of $A$ are on the left,}
  \item{no row has fewer ones than the first row,}
  \item{if a $1$ appears in row $i$ in column $j$, then for each $k < j$ there
      is some row $l < i$ with a $1$ in position $k$.}
\end{enumerate}

As in \thref{ex:SimilarBreenMatrices}, it is possible for two distinct matrices
in this form to have the same value under $\Xi_n$.

Now, given $\Xi_n$, a similar backtrack search to \thref{alg:canonicalbacktrack}
allows appropriate represenatives of matrices to be enumerated.

We then have the following algorithm for finding a minimal generating set for
$\Refn$:
\begin{alg}
  \thlabel{alg:ReflexiveGenSet}
  Computing the minimal generating set for $\Refn$ \\
  \textbf{Input}: A natural number $n$.\\
  \textbf{Output}: A minimal generating set for $\Refn$.
\begin{enumerate}
  \item
    Enumerate the trim reflexive boolean matrices in reflexive Breen form using
    the analogue of \thref{alg:canonicalbacktrack}, storing canonical
    representatives under a row and column permutation in a set $S$
  \item 
    Filter out the properly decomposable matrices in $S$ using
    \thref{lem:decomposeintersection}, leaving a set $T$ of trim matrices that
    are not properly decomposable
  \item
    Return $T$ together with the reflexive elementary matrices.
\end{enumerate}
\end{alg}
Using this algorithm, we can calculate the sizes of minimal generating sets up
to $n = 6$; these are contained in Table~\ref{tab:BMatResults}.

There are a small number of matrices in $\Ref{7}$ for which the approach based on
\thref{lem:decomposeintersection} is too inefficient; we chose to use a
different method to test $12$ matrices in total. Observe that a matrix $A$ is
decomposable into a product of generators $X_1 X_2 \ldots X_k$ from some minimal
generating set if and only if $\alpha A \alpha^{-1} = \alpha (X_1 X_2 \ldots
X_{k-1})\alpha^{-1}\alpha X_k \alpha^{-1}$ for all permutations $\alpha$. Since
the set $S$ of Algorithm \thref{alg:ReflexiveGenSet} contains $\alpha X_k
\alpha^{-1}$ for some $\alpha \in S_n$, we can detect if $A$ is properly
decomposable by testing whether $\alpha A \alpha^{-1} = CB$ for any $\alpha \in
S_n$, $B \in S$ and with $C$ the greedy multiplier of $(\alpha A \alpha^{-1},
B)$. A brute force approach based on this observation is sufficient to filter
the $12$ difficult matrices for $n = 7$.

% The single matrix that is kept is:
%1000010
%0100101
%1010101
%1001101
%0110110
%0111010
%0111001

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hall Matrices}
\label{sec:HallBoolMat}

%TODO: get rid of "indexed by" everywhere

There is a particularly interesting submonoid of $\Bn$ consisting of those
boolean matrices containing a permutation matrix is particularly interesting. It
is often called the \emph{Hall monoid} since matrices containing a permutation
matrix correspond to instances of the Hall marriage problem that have a
solution, and are thus referred to as \emph{Hall matrices}. We will denote the
Hall monoid by $\Halln$. For convenience, we shall often simply say that a Hall
matrix contains a permutation when it contains the corresponding permutation
matrix.

The main result of this section is the following theorem. Unlike the monoid of
reflexive boolean matrices $\Refn$, the Hall monoid $\Halln$ has minimal
generating sets that are strongly related to the minimal generating sets for
$\Bn$.
\begin{thm}
  \thlabel{thm:HallGenSet}
  Every minimal generating set for $\Halln$ is obtained by removing a rank $n-1$
  matrix from a minimal generating set for $\Bn$. That is, every minimal
  generating set for $\Halln$ consists of a set of representatives $P$ of the
  prime $\J$-classes of $\Bn$ together with two generators for the group of units
  and an elementary matrix.
\end{thm}

In order to prove this theorem, we will need the following classical result,
restated in our context.

\begin{thm}[Hall's Marriage Theorem~{\cite[Theorem 1]{Hall1935aa}}]
  \thlabel{thm:HallMarriage}
  Let $A \in \Bn$. Then $A$ is a Hall matrix if and only if every union of $k$
  rows contains at least $k$ ones, for $1 \leq k \leq n$.
\end{thm}
We shall say that a subset $X$ of the rows of a matrix \emph{satisfies the Hall
  condition} if the union of the rows in $X$ contains at least $|X|$ ones, and
that a matrix satifies the Hall condition if every subset of the rows satisfies
the Hall condition.

Similarly to the case for reflexive matrices, the fact that Hall matrices contain
permutations gives useful information on products of matrices. Given two
matrices $A, B \in \Halln$, both $A$ and $B$ contain a permutation matrix; hence
$AB$ contains a row-permuted copy of $B$ and a column-permuted copy of $A$. It
follows that $AB$ contains at least as many $1$s as the maximum number of $1$s
in $A$ or $B$.

The $\J$-relation for $\Halln$ is also easily described through the following
lemmas
\begin{lemma}
  \thlabel{lem:HallJRelation}
  Two matrices $A, B \in \Halln$ are $\J$-related in $\Halln$ if and only if
  they are similar.
\end{lemma}
\begin{proof}
  The reverse direction is clear. For the forward direction, suppose that $A =
  SBT$ and $B = UAV$ for matrices $S, T, U, V \in \Halln$. Then $BT$ contains a
  column-permuted copy of $B$, and hence $A$ contains a row- and column-permuted
  copy of $B$. Since, similarly, $B$ contains a row- and column-permuted copy of
  $A$, it follows that $A$ is a row- and column-permutation of $B$.
\end{proof}

We will prove \thref{thm:HallGenSet} through a series of lemmas. The
first thing to prove is that every element specificed actually belongs to
$\Halln$; this is clear for elements of the group of units and elementary
matrices but less clear for prime matrices.

\begin{lemma}
  \thlabel{lem:PrimeAreHall}
Every prime matrix is Hall.
\end{lemma}
\begin{proof}
  Let $A \in \Bn$ be prime. By \thref{thm:HallMarriage}, it suffices to show
  that there is no subset of rows of $A$ of size $k$ such that the union of
  these rows contains fewer than $k$ ones. This is equivalent to not containing
  any $k \times (n - k + 1)$ submatrix containing only $0$. As a consequence of
  the discussion after \cite[Definition 2.4]{Caen1981aa}, the set of rows of $A$
  containing more than a single $1$ do not contain any $k \times (n - k)$
  submatrix containing only $0$; hence $A$ does not contain a $k \times (n - k +
  1)$ such submatrix, and $A \in \Halln$.
\end{proof}

In order to apply \thref{lem:GenSetDecomposition}, we must be able to decompose
certain elements of $\Halln$ into products of elements that lie above the given
element in the $\J$-order. The following two lemmas are the first steps in
finding such a decomposition.

\begin{lemma}
  \thlabel{lem:NonTrimDecomposable}
  Let $A$ be a non-trim matrix belonging to $\Halln$. Then there exist $B, C \in
  \Halln$ such that $A = CB$, and neither $B$ nor $C$ is $\J$-related to $A$.
\end{lemma}
\begin{proof}
  We may assume that $A$ contains the identity permutation, since $A$ is
  decomposable into such matrices $B$ and $C$ if and only if every matrix
  similar to $A$ is decomposable into matrices similar to $B$ and $C$. The lemma
  now follows using the same proof as in
  \thref{lem:ReflexiveNonTrimDecomposable}.
\end{proof}

It will be convenient in the following proofs to define $e_i$ to be the boolean
vector of length $n$ with a single $1$ in position $i$, for $1 \leq i \leq n$.

\begin{lemma}
  \thlabel{lem:HallAssumptions}
  Let $A$ be a trim matrix belonging to $\Halln$ which is not prime, elementary, or a
  permutation matrix. Then there exist $B \in \Halln$ and $C \in \Bn$ such that
  $A = CB$, neither $B$ nor $C$ is $\J$-related to $A$ in $\Halln$, and $C$
  contains a $1$ in every column.
\end{lemma}
\begin{proof}
  As in \thref{lem:NonTrimDecomposable}, we may assume that $A$ contains the
  identity permutation. Since $A$ is not prime, elementary, or a permutation
  matrix, it has non-maximal row space in $\beta_n$. Let $B$ be a maximal
  non-permutation matrix in $\Bn$ whose row space contains the row space of $A$.

  Letting $C \in \Bn$ be the greedy left multiplier of $(A, B)$, we have $A = CB$ by
  \thref{lem:GreedyMultipliers}. Suppose that $C$ is $\J$-related to $A$; then
  by \thref{lem:HallJRelation} $C$ is similar to $A$. Then since $A$ is trim, so
  too is $C$. Since $B$ was chosen to be a non-permutation matrix, the product
  $CB$ contains more $1$s than $C$. But $A = CB$, and $C$ is similar to $A$, a
  contradiction. Hence $C$ is not $\J$-related to $A$. Since $R(A) \subsetneq
  R(B)$, $B$ is not $\J$-related to $A$ in $\Bn$ and thus is not $\J$-related to
  $A$ in $\Halln$.

  If $C$ contains a $1$ in every column, we are done. However, there is no
  reason that this must be the case.

  Suppose that the columns of $C$ indexed by $X = \{c_1, c_2, \ldots, c_k\}$ do
  not contain a $1$, and that $B$ contains the permutation $\alpha$. For $1 \leq
  i \leq k$, define $B'_{c_i*} = e_{\alpha(c_i)}$. Define the remaining rows of
  $B'$ to be the corresponding rows of $B$. Then $B'$ contains $\alpha$. Let
  $C'$ be the greedy left multiplier of $(A, B')$; then for all $1 \leq i \leq
  k$, $C'_{\alpha(c_i)c_i} = 1$ since $A_{\alpha(c_i)\alpha(c_i)} = 1$. Note
  that since the columns indexed by $X$ of $C$ did not contain a $1$, $R(A)$ is
  in fact a subset of the subspace of $R(B)$ generated by the rows indexed by
  $\{1, \ldots, n\}\setminus X$; hence $R(A) \subsetneq R(B')$ and thus by
  \thref{lem:GreedyMultipliers}, $A = C'B'$. Hence we have found $B', C' \in \Bn$
  such that $A = C'B'$, $B' \in \Halln$, and every column of $C'$ contains a
  $1$. We must finally prove that $B'$ and $C'$ are not $\J$-related to $A$ in
  $\Halln$. Suppose that $A \J B'$; then $B'$ is similar to $A$, and hence $B'$
  is trim. Since $C$ contains a $1$ in every row, and $C'$ contains all $1$s of
  $C$ together with at least one more, $C'$ is not the identity matrix.
  As above, it follows that $C'B'$ contains more $1$s than $B'$ does; this is a
  contradiction. Hence $A$ is not $\J$-related to $B'$. Now suppose that $A\J
  C'$. Then $C'$ is similar to $A$, and thus trim.
  In order to apply the previous argument to $C'$, we must prove that $B'$ is
  not a permutation matrix. Since $B$ was not a permutation matrix, and $B'$ was
  obtained by replacing some rows of $B$ by rows $e_{\alpha(c_i)}$ containing a
  single $1$, the only way that $B'$ may be a permutation matrix is if the
  non-replaced rows of $B$ - indexed by $\{1, 2, \ldots, n\}\setminus X$ - all
  contained a single $1$.  But since $C$ contains $1$s only in those columns,
  the product $A = CB$ could then only contain $1$s in at most $n - |X|$
  columns, and thus would not be a Hall matrix.  Hence, $B'$ is not a
  permutation matrix and a similar argument to that which showed that $A$ is not
  $\J$-related to $B'$ applies to $A$ and $C'$, to show that $A$ is not
  $\J$-related to $C'$ in $\Halln$.
\end{proof}

While \thref{lem:HallAssumptions} does not provide the decomposition we
require in order to use \thref{lem:GenSetDecomposition}, it provides a
decomposition into two matrices that are close to having the correct properties.
This motivates the following definition. Given a row-trim matrix $A \in \Bn$,
define the \defn{core} $A^\circ$ of $A$ to be the submatrix of $A$ consisting of
those rows containing at least $2$ ones. We say that a subset of rows of $A$
violating the Hall condition is a \defn{maximal violator of $A$} if it has
largest cardinality amongst such subsets, and that a matrix is $k$-deficient if
$k$ is the cardinality of a maximal violator of $A^\circ$. The following lemma
shows that we are justified in considering maximal violators of $A^\circ$ rather
than $A$. 

\begin{lemma}
  \thlabel{MaximalViolatorsCore}
  If $A$ is a row-trim matrix belonging to $\Bn$, then $A$ has a subset of rows
  violating the Hall condition if and only if $A^\circ$ has a subset of rows
  violating the Hall condition.
\end{lemma}
\begin{proof}
  Suppose $A$ has rows $X = \{r_1, r_2, \ldots, r_k\}$ containing a single $1$.
  Since $A$ is row-trim, no other row may contain a $1$ in the columns in which
  the rows $X$ have a $1$; hence we may permute the rows and columns of $A$ so
  that the rows containing a single $1$ form a identity matrix $I_k$ as the $k
  \times k$ bottom-right block. Now $A^\circ$ forms the first $n-k$ rows, and it
  is clear that the union of a maximal violator of $A^\circ$ with the last $k$
  rows forms a maximal violator of $A$, and that restricting a maximal violator
  of $A$ to the first $n-k$ rows induces a maximal violator of $A^\circ$.
\end{proof}

We will demonstrate that we can iteratively reduce the $k$-deficiency of the
matrix $C$ in the statement of \thref{lem:HallAssumptions} until it is
$0$-deficient and therefore belongs to $\Halln$.

\begin{lemma}
  \thlabel{lem:DeficiencyReduction}
  Suppose that $A$ is a trim matrix belonging to $\Halln$ containing the
  identity permutation, and that $A = CB$ where $B$ belongs to $\Halln$, $C
  \in \Bn$ is a $k$-deficient matrix containing a $1$ in every column, and
  neither $B$ nor $C$ are $\J$-related to $A$ in $\Halln$. Then there exist $T
  \in \Halln$ and $S \in \Bn$ such that $A = ST$, $S$ contains a $1$ in
  every column, neither $S$ nor $T$ are $\J$-related to $A$ in $\Halln$, and
  $S$ is at most $(k-1)$-deficient.
\end{lemma}
\begin{proof}
  Since $C$ is $k$-deficient, there is some maximal violator of $C^\circ$,
  indexed in $C$ by $W  = \{w_1, w_2, \ldots, w_k\} \subset \{1, \ldots, n\}$.
  Since $C$ contains a $1$ in every column, $k < n$. We will show how we can
  construct new matrices from $C$ and $B$ so that the rows indexed by $W$
  satisfy the Hall condition. It will be useful in this proof to denote the
  complement of a set $Z \subseteq \{1, 2, \ldots, n\}$ in $\{1, 2, \ldots, n\}$
  by $Z^C$.

  Let $X = \{x_1, \ldots, x_l\} \subset \{1, \ldots, n\}$ denote the indices of
  those columns of $C$ that do not contain any $1$s in the rows indexed by $W$.
  By multiplying $C$ by an appropriate permutation matrix on the right, and $B$
  by the inverse of this permutation matrix on the left, we may assume that $X^C
  \subset W$, and that $X \cap W = \{x_1, \ldots, x_{m - 1}\}$, where $m = k + l
  - n + 1$. That is, the $1$s that occur in rows $W$ occur in a subset of the
  columns $W$, and those columns indexed by $W$ in which a $1$ does not occur in
  rows $W$ are labelled by $\{x_1, \ldots, x_{m - 1}\}$. Consider the remaining
  $n - k$ column indices $\{x_m, \ldots, x_k\}$. 
    
  Let $D$ be the $(n-k) \times (n-k)$ submatrix of $C$ consisting of rows $W^C$
  of $C$ and columns $\{x_m, \ldots, x_k\}$. Suppose that $D$ contains maximal
  violator $V$. The rows in $V$ cannot all be rows of $C$ which contained a
  single $1$: since $A$ is trim, $C$ is row trim and hence each row of $C$
  containing a single $1$ contains a distinct $1$.  It follows that $V$ contains
  at least one row of $C^\circ$. But then the union of $W$ with the rows of
  $C^\circ$ corresponding to rows of $V$ is a maximal violator of $C^\circ$ with
  larger cardinality than $W$, a contradiction. Hence $D$ satisfies the Hall
  condition, and therefore $D$ contains a permutation matrix. This defines a
  bijection $f: W^C \to \{x_m, \ldots, x_k\}$ such that for all $i \in W^C$,
  $f(i)$ is the column containing a $1$ in row $i$ of the permutation matrix.
  For all $i \in W^C$, we define row $i$ of $S$ to be $e_{f(i)}$, and row $f(i)$
  of $T$ to be $A_{i*}$; then $(ST)_{i*} = A_{i*}$. Observe that since
  $C_{i,f(i)} = 1$, row $B_{f(i)*}$ is contained in row $A_{i*}$ and hence also
  contained in row $T_{i*}$.

  For all $j \in X^C$, we define row $j$ of $T$ to
  be $B_{j*}$; then for all $i \in W$, $(CT)_{i*} = A_{i*}$. It remains to
  define rows $W$ of $S$ and rows $\{x_1, \ldots, x_{m - 1}\}$ of $T$. Since
  $B$ is a Hall matrix, it contains a permutation matrix $U$ with corresponding
  permutation $u$. The rows $X^C
  \cup \{x_m, \ldots, x_k\}$ of $T$ contain the corresponding rows of $U$. For
  all $j \in \{x_1 \ldots, x_k\}$, consider the cycle in the permutation $u$
  starting at $j$. If $u(j) \in W$, then define $T_{j*} = e_{u(j)}$. Otherwise,
  $u(j) \not\in W$, and we may construct the tuple $(u^1(j), u^2(j), \ldots,
  u^{q}(j), iu^{q+1}(j))$ where $u^{i}(j) \not\in W^C$ for $1 \leq i \leq q$,
  and $u^{q + 1}(j) \in W$. Then we define $T_{j*} = e_{u^{q + 1}(j)}$. By the
  assumptions on $X$, for $1 \leq i \leq q$ we have $u^{i}(j) \in \{x_m, \ldots,
    x_l\}$, and by the definitions of rows $\{x_m, \ldots, x_l\}$ of $T$, we
  have that $T_{u^{i}(q),u^{i}(q)} = 1$. For each such tuple, we modify $U$ by
  defining $U_{j*} = e_{u^{q + 1}(j)}$, and $U_{u^{i}(q)*} = e_{u^{q + 1}(j)}$
  for $1 \leq i \leq q$. Note that this modification is well-defined since $u$
  is a permutation and thus decomposes into disjoint cycles. After this
  modification, $T$ is fully defined and contains the permutation matrix $U$.

  For each $j \in \{x_1, \ldots, x_{m - 1}\}$, we have $T_{j*} = e_w$ for some
  $w \in W$, and hence there is a $1$ in position $(w, j)$ of the greedy left
  multiplier of $(A, T)$. Define the rows $W$ of $S$ to be the corresponding
  rows of the greedy left multiplier of $(A, T)$. Then the union $y$ of the rows
  $W$ of $S$ contains ones in columns $\{x_1, \ldots, x_{m - 1}$. Note that
    since the rows of $T$ indexed by $X^C$, the set of columns that had a $1$ in
    some row of $W$, are equal to the corresponding rows of $B$, we have $S_{w*}
    \geq C_{w*}$ for all $w \in W$. Hence $y$ contains $(n - l) + m = k$ ones,
    and so the rows $W$ satisfy the Hall condition. Since every other row of $S$
    contains a single $1$, it follows that $S$ is at most $(k - 1)$-deficient.

  As noted above, $(ST)_{i*} = A_{i*}$ for all $i \in W^C$. For $i \in W$, we
  have that $S_{i*} \geq C_{i*}$; since $(CT)_{i*} = A_{i*}$ we must have
  $(ST)_{i*} \geq A_{i*}$. By the definition of the greedy left multiplier,
  $(ST)_{i*} \leq A_{i*}$ for all $i \in W$. Hence $A = ST$.
    
  We wish to now show that $S$ contains a $1$ in every column, and that $A$ is
  not $\J$-related to $S$ or to $T$. That $S$ contains a $1$ in every column
  follows from the union $y$ of the rows $W$ containing $1$s in each of the columns
  indexed by $W$, and the other rows being defined via the bijection $f$. That
  $T$ is not $\J$-related to $A$ follows from the same argument as above; since
  $A$ is trim so would be $B$, but $S$ contains at least one row with more than
  one $1$, a contradiction. In order to prove that $S$ is not $\J$-related to
  $A$, we must as above prove that $T$ is not a permutation matrix. Similarly to
  the argument above, we note that if $T$ is a permutation matrix then each row
  of $T$ indexed by $X^C$ contains a single one, but these are equal to the
  corresponding rows of $B$.  Then the union of rows $W$ of $CB$ would contain
  precisely $n - l < k$ ones, and hence $A$ would not be Hall. Hence $T$ is not
  a permutation matrix, and the argument proceeds as above. 
\end{proof}

\begin{cor}
  \thlabel{cor:HallDecomposition}
  Let $A$ be a matrix belonging to $\Halln$ which is not prime, elementary,
  or a permutation matrix. Then $A$ can be be decomposed as a product $A = CB$
  of matrices $B, C \in \Halln$, such that neither $B$ nor $C$ is $\J$-related
  to $A$ in $\Halln$.
\end{cor}
\begin{proof}
  We may assume that $A$ contains the identity permutation, since If $A$ is not
  trim then this follows directly from \thref{lem:NonTrimDecomposable}.
  Otherwise, $A$ is trim and by \thref{lem:HallAssumptions} there exist $B \in
  \Halln$ and $C \in \Bn$ such that $A = CB$, neither $B$ nor $C$ is
  $\J$-related to $A$ in $\Halln$, and $C$ contains a $1$ in every column. If
  $C$ also belongs to $\Halln$, then we are done; otherwise $C$ is $k$-deficient
  for some $1 \leq k \leq n$. By iteratively replacing $B$ and $C$ with the
  matrices constructed in \thref{lem:DeficiencyReduction}, we must eventually
  construct $B$ and $C$ with the properties above and where $C$ is
  $0$-deficient, and thus Hall by \thref{MaximalViolatorsCore}.
\end{proof}

We may now prove \thref{thm:HallGenSet}.

\begin{proof}[\thref{thm:HallGenSet}]
  Let $G \subset \Halln$ consist of a set of representatives $P$ of the prime
  $\J$-classes of $\Bn$ together with two matrices that generate $S_n$ and an
  elementary matrix. By \thref{lem:HallJRelation}, for any element $x \in G$ with
  $\J$-class $J_x$ in $\Halln$, we have $J_x \subsetneq \genset{G}$. It
  follows from \thref{cor:HallDecomposition} and \thref{lem:GenSetDecomposition}
  that $G$ generates $\Halln$. Since any generating set for $\Bn$ requires a
  matrix from every prime $\J$-class, two generators for $S_n$, and an
  elementary matrix, and each of these lie in $\Halln$, we must require these
  matrices in any generating set for $\Halln$; hence $G$ is minimal. The same
  argument shows that every minimal generating set is obtained in this way.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Transformation Hall Matrices}
\label{sec:TransBoolMat} 
After considering the reflexive and Hall matrices, it
is natural to consider the monoids obtained by relaxing the restrictions on
which patterns must be contained. In this section, we consider the monoid $\MTn$
of matrices which contain a transformation matrix; that is, have a $1$ in every
row. As in the case of the Hall monoid, the minimal generating sets for $\MTn$
are strongly related to minimal generating sets for $\Bn$.

%TODO: this is the next proof to tidy up
\begin{thm}
  All minimal generating sets for $\MTn$ are obtained by replacing the rank $n -
  1$ matrix in a minimal generating set for $\Bn$ by a matrix similar to
  \begin{align*}
    F' = \begin{pmatrix}
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 0 & 1 & 0 & \cdots & 0 \\
      0 & 0 & 0 & 1 & \cdots & 0 \\
        &   &   \dots & \dots & \\
      0 & 0 & 0 & 0 & \cdots & 1
    \end{pmatrix}
  \end{align*}
\end{thm}
\begin{proof}
  Since all prime matrices have full rank, such a set $G$ is contained in
  $\MTn$. To see that it is a generating set, consider a matrix $A$ which is not
  $\J$-related to any matrix in $G$. We wish to write $A$ as a product of
  matrices which lie strictly above $A$ in the $\J$-order. 
  
  Suppose that $A$ is not row-trim, and row $i$ is contained in row $j$. Then
  subtracting row $i$ from row $j$, we obtain a new matrix $A'$. If row $j$ is
  now empty, we then insert any row that is not in the row space of $A$ as row
  $j$. Now $A$ is the product $F''A'$ of $A'$ with some matrix similar to $F'$. By
  replacing $A$ with $A'$, and repeating if necessary, we may assume that $A$ is
  row-trim; a dual procedure allows us to assume that $A$ is column-trim. 
  
  Let $A_0 = A$. Then we write $A_0 = B_0C_0$ where $B_0, C_0 \in \Bn$, $B_0$ has a
  maximal row-space amongst non-permutation matrices, and $C_0$ is the greedy left
  multiplier. Since $B_0$ is Hall, it lies in $\MTn$; it is also $\J$-related to
  some matrix in $G$ and hence lies above $A_0$. Since $A_0$ is trim, $C_0$ must also
  be trim, and similarly since $A_0$ contains no zero row neither does $C_0$.
  However, $B_0$ is not a permutation matrix, and therefore $A_0 = C_0B_0$ contains more
  $1$s than $C_0$ does. Now either $C_0$ also lies strictly above $A_0$, in which case
  we are done, or we can repeat the process with $A_1 = C_0$. Since we
  cannot continue producing matrices with fewer and fewer ones forever,
  eventually we must decompose one of the $A_i$s as desired; then the product $A
  = C_i B_i B_{i - 1} \ldots B_1$ consists of matrices strictly above $A$ in the
  $\J$-order, which all lie in $\MTn$. By \thref{lem:GenSetDecomposition},
  $G$ generates $\MTn$.
  Now, since every generating set for $\Bn$ must contain a representative of
  each prime $\J$-class and an elementary matrix, so too must every generating
  set for $\MTn$. Now $F'$ is not Hall, while all prime and elementary matrices
  are Hall, so $F'$ is not generated by prime and elementary matrices. Hence,
  any such generating set $G$ is minimal.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Triangular Boolean Matrices}
\label{sec:TriBoolMat}
We now turn our attention to the monoids of upper and lower triangular boolean
matrices, denoted by $\UTn$ and $\LTn$ respectively. These matrices have a
particularly simple minimal generating set:

\begin{lemma}
  \thlabel{lem:mingeneratingsetfortriangular}
  The unique minimal monoid generating set $G_U$ for $\UTn$ consists of those
  elementary matrices and matrices similar to $F$ which are upper triangular.
  The dual statement holds for $\LTn$.
\end{lemma}

\begin{proof}
  We will prove the lemma for $\UTn$; the result for $\LTn$ follows via the
  anti-isomorphism given by transposition.
  We will first construct any matrix $A \in \UTn$ as a product of matrices in
  $G_U$. We iteratively define a product $A_i$, $0 \leq i \leq n$ where $A_0$ is
  the identity and $n$ is the number of $1$s in $A$. For the $i$-th $1$
  contained in $A$ (ordered by row then column) with position $(x_i, y_i)$, we
  obtain $A_i$ from $A_{i - 1}$ by left-multiplying by $E^{x_i, y_i}$. Let the
  zero rows of $A$ have indices $\{z_1, \ldots, z_{k}\}$. Note that the matrices
  in $\UTn$ similar to $F$ are precisely those matrices obtained by deleting a
  single $1$ from an identity matrix. We define $A_{n + j}$ to be the matrix
  obtained by left multiplying $A_{n + j - 1}$ by the element of $X$ with a zero
  row in position $z_j$. Then $A_{n + k} = A$.  
  
  Now it is easy to show that for each matrix $A \in G_U$, if $A$ is written as
  a product $A = BC$ in $\UTn$ then one of $B$ or $C$ must be equal to $A$; it
  follows that any generating set for $\UTn$ must contain all matrices in $G_U$.
  Hence $G_U$ is the unique minimal generating set for $\UTn$.
\end{proof}

\begin{cor}
  \thlabel{cor:RankTriBoolMat}
  For $n > 1$, the ranks of $\UTn$ and $\LTn$ are the $n$-th triangular number
  $T_n = \frac{n(n+1)}{2}$.
\end{cor}
\begin{proof}
  Elementary matrices in $\UTn$ are precisely those in the form of an identity
  matrix together with an additional $1$ in some position above the main
  diagonal; hence there are $T_{n - 1}$ elementary matrices in $\UTn$. There are
  $n$ matrices similar to $F$ in $\UTn$, and hence $T_{n - 1} + n =  T_n$
  elements of the minimal monoid generating set.
\end{proof}

\section{Tropical matrices}
%TODO: we would like to include the following results since they seem like a
%natural fit, these are the things which need to be proved and we don't quite
%know what the proofs are:

Another class of semiring which has attracted significant recent attention (see
~\cite{TODO}) is the tropical min-plus semirings which are interesting because
TODO. The monoids of matrices over these semirings have significantly more
complex behaviour than the boolean matrix monoid (see \cite{TODO}).

\subsection{Min-plus matrices}

\begin{thm}[J, J, J]\label{thm-min-plus}
  The monoid $M_{2}(K^{\infty})$ of $2 \times 2$ min-plus matrices is
  generated by the matrices:
  \begin{equation*}
          A_{i} = \mat{i}{0}{0}{\infty},
    \quad B     = \mat{1}{\infty}{\infty}{0},
    \quad \text{and}
    \quad C     =  \mat{\infty}{\infty}{\infty}{0}
  \end{equation*}
  where $i \in \N \cup \{\infty\}$.
\end{thm}

\begin{cor}[J, J, J]\label{cor-finite-min-plus}
  Let $t \in \N$ be arbitrary. Then the finite monoid $M_{2}(K^{\infty}_t)$ of
  $2 \times 2$ min-plus matrices is generated by the $t + 4$ matrices:
  \begin{equation*}
          A_{i} = \mat{i}{0}{0}{\infty},
    \quad B     = \mat{1}{\infty}{\infty}{0},
    \quad \text{and}
    \quad C     =  \mat{\infty}{\infty}{\infty}{0}
  \end{equation*}
  where $i \in \{0, 1, \ldots, t, \infty\}$.
\end{cor}

\subsection{Max-plus matrices}
???? Seems like a natural thing to include.

\section{Matrices over $\mathbb{Z}_n$}

\begin{thm}[Wilf]
  The monoid $M_{k}(\mathbb{Z}_{n})$ is generated by $GL_{k}(\mathbb{Z}_{n})$ and
  any one element from each of the $\D$-classes immediately below the group of
  units. In particular, you could choose
  the diagonal matrices
  $$\begin{pmatrix}
    n/p    & 0      & \cdots & 0  \\
    0      & 1      &        & \vdots \\
    \vdots &        & \ddots & 0 \\
    0      & \cdots & 0      & 1  \\
   \end{pmatrix},$$
   for each prime divisor $p$ of $n$.
\end{thm}
Note that by the same logic as everywhere else this must be minimal.

\printbibliography
\end{document} 
