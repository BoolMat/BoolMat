\documentclass[11pt]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb, latexsym, mathrsfs, pifont,
tabu, enumitem}
\usepackage[cm]{fullpage}
\usepackage{theoremref}
\usepackage[ruled, linesnumbered]{algorithm2e}
\usepackage{makecell}

\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{defi}{Definition}
\newtheorem{exa}[thm]{Example}
\newtheorem{algo}[thm]{Algorithm}
\newenvironment{de}[1][]{\begin{defi}[#1]\rm}{\end{defi}}
\newenvironment{ex}{\begin{exa}\rm}{\end{exa}}
\newenvironment{alg}{\begin{algo}\rm}{\end{algo}}
\newcommand{\proofref}[1]{\noindent {\emph{Proof of Theorem}~\ref{#1}.\ }}
\newcommand{\defn}[1]{\textbf{\textit{#1}}}
\numberwithin{equation}{section}

% Lists
%\def\labelenumi{\theenumi}
%\def\theenumi{(\roman{enumi})}

% Macros
\newcommand{\id}{\mbox{\rm id}}
\newcommand{\set}[2]{\ensuremath{\{#1 : #2 \}}}
\newcommand{\genset}[1]{\ensuremath{\langle\: #1 \:\rangle}}
\renewcommand{\to}{\longrightarrow}

\DeclareMathOperator{\im}{im}

% For Algorithms
\SetKwProg{Fn}{Function}{}{}
\SetKwFunction{FZeroIfNotSubset}{ZeroIfNotSubset}
\SetKwFunction{FRemoveDuplicateRows}{RemoveDuplicateRows}
\SetKwComment{Comment}{}{}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\DontPrintSemicolon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\B}{\mathbb{B}}
\newcommand{\Bn}{M_n(\B)}
\newcommand{\Bm}[1]{M_{#1}(\B)}
\newcommand{\Bmn}{M_{m,n}(\B)}
\newcommand{\Refn}{M_n^{\text{id}}(\B)}
\newcommand{\Ref}[1]{M_{#1}^{\text{id}}(\B)}
\newcommand{\Halln}{M_n^{\text{S}}(\B)}
\newcommand{\Hall}[1]{M_{#1}^{\text{S}}(\B)}
\newcommand{\MTn}{M_n^{\mathcal{T}}(\B)}
\newcommand{\MT}[1]{M_{#1}^{\text{T}}(\B)}
\newcommand{\UTn}{UT_n(\B)}
\newcommand{\LTn}{LT_n(\B)}
\renewcommand{\L}{\mathscr{L}}
\newcommand{\R}{\mathscr{R}}
\newcommand{\D}{\mathscr{D}}
\newcommand{\J}{\mathscr{J}}
\renewcommand{\H}{\mathscr{H}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\rank}{\operatorname{rank}}

\newcommand{\K}{\mathbb{K}}

\newcommand{\BGSet}{\mathcal{B}_{n,n}}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newcommand{\mat}[4]{\begin{pmatrix}#1&#2\\#3&#4\end{pmatrix}}

\usepackage[backend=biber, bibencoding=utf8]{biblatex}
\bibliography{matrix}

\title{Minimal generating sets for matrix monoids}
\author{F. Hivert, J. D. Mitchell, F. L. Smith, and W. A. Wilson}
\date{\today}
\begin{document}

\maketitle

\begin{abstract}
  We compute the largest known ranks of the boolean matrix monoid and the
  submonoids $\Refn$ of reflexive boolean matrices, $\Halln$ of Hall matrices,
  $\MTn$ of boolean matrices containing a transformation, and $\UTn$ and $\LTn$,
  of triangular boolean matrices. We also determine the relationship between
  minimal generating sets for $\Bn$, $\Halln$, and $\MTn$, and prove that the
  rank of $\UTn$ and $\LTn$ are given by the triangular numbers.
\end{abstract}

\section{Introduction}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%The \defn{boolean semiring} $\B$ is the set $\{0, 1\}$ with addition defined by 
%\begin{align*}
%  0 + 1 = 1 + 0 &= 1 + 1 = 1 \\
%  0 + 0 &= 0
%\end{align*}
%and multiplication defined as usual for the real numbers $0$ and $1$.  The
%addition and multiplication of elements of $\B$ naturally extends to row and
%column vectors of equal length with entries in $\B$.  The main object of study
%in this document is the collection $\Bn$ of $n\times n$ matrices with entries in
%$\B$. Under the usual multiplication of matrices, using addition and
%multiplication in $\B$, the set $\Bn$ forms a monoid; call the \defn{full
%  boolean matrix monoid}. The monoid $\Bn$ is classical in the literature of
%semigroup theory being among the first monoids to be studied; see, for example,
%\cite{Zaretskii1963aa}. The monoids $\Bn$, $n\in \N$, have been extensively
%studied in the literature, by many authors, and a great deal is known about its
%structure and properties. For example, if $G$ is a finite group, then there
%exists an $n\in \N$ such that $G$ occurs as a maximal subgroup of $\Bn$; the
%probability that a random product of matrices in $\Bn$ equals the universal
%matrix:
%\begin{equation*} 
%  \begin{pmatrix}
%  1 & 1 & \cdots & 1\\
%  1 & 1 & \cdots & 1\\ 
%  \vdots & \vdots & \ddots & \vdots\\
%  1 & 1 & \cdots & 1\\ 
%\end{pmatrix} 
%\end{equation*} 
%tends to $1$ as $n\to \infty$; the minimal size of a generating set for $\Bn$
%grows exponentially with $n$ (see~\thref{cor:ExponentialGenSets});
%Devadze~\cite{Devadze1968aa} and Konieczny~\cite{Konieczny2011aa} characterise
%minimum cardinality generating sets for $\Bn$; TODO: more.
%
%Despite its venerable status, many aspects of the monoids $\Bn$ are still
%shrouded in mystery. The purpose of this article is to cast some light on the
%problems of determining the minimum cardinality $\mathbf{d}(\Bn)$ of a
%generating set for $\Bn$ and certain submonoids of $\Bn$ such as the reflexive
%boolean matrix monoid $\Refn$, and other submonoids where the matrices contain
%particular matrices.
%% The time and space complexity of determining any of these value is exponential
%% in $n$. 
%It seems unlikely that an explicit formula for any of these numbers exists.
%In this paper we describe algorithms for computing the numbers listed,
%and the output of our implementation~\cite{} of these algorithms. The latter
%are summarised in Tables~\ref{figure-table-1} and \ref{tab:reflexiverank}.
%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
\label{section-preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Green's relations}
On any semigroup $S$, there are some key equivalence relations. These are known
as Green's relations, and are defined in terms of principal ideals as follows.
Let $S$ be any semigroup and let $s, t \in S$. Then
\begin{align*}
  s \L t &\text{ if and only if } S^1 s = S^1 t \\
  s \R t &\text{ if and only if } s S^1 = t S^1 \\
  s \J t &\text{ if and only if } S^1 s S^1 = S^1 t S^1.
\end{align*}
Finally, we define Green's $\H$-relation as the intersection of $\L$ and $\R$.
We write $X_s$ for the Green's $\mathcal{X}$-class of $s$, where
$\mathcal{X} \in \{\L, \R, \J, \H\}$.
There is a natural partial order on certain Green's classes
\begin{align*}
  R_s \leq R_t &\text{ if and only if } sS^1 \subseteq tS^1 \\
  L_s \leq L_t &\text{ if and only if } S^1s \subseteq S^1t \\
  J_s \leq J_t &\text{ if and only if } S^1 s S^1 \subseteq S^1 t S^1.
\end{align*}
Further background on Green's relations can be found in~\cite{Howie1995aa}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Semirings}
The theory of matrices over fields is familiar and well-studied, but we are
concerned with matrices over more general objects, semirings. For our purposes,
a semiring is a set $\mathbb{S}$ with two operations, $\oplus$ and $\otimes$,
such that $(\mathbb{S}, \oplus)$ forms a commutative monoid with identity $e$,
$(\mathbb{S}, \otimes)$ forms a monoid, $e\otimes x = x\otimes e = e$ for all $x
\in \mathbb{S}$, and multiplication distributes over addition. We call the
additive identity the \defn{zero} of the semiring and the multipicative identity
the \defn{one}. Throughout, semirings will be denoted by blackboard bold
symbols. We are particularly interested in several special types of semiring.

The \defn{boolean semiring} $\B$ is the set $\{0, 1\}$ with addition defined by 
\begin{align*}
  0 \oplus 1 = 1 \oplus 0 &= 1 \oplus 1 = 1 \\
  0 \oplus 0 &= 0
\end{align*}
and multiplication defined as usual for the real numbers $0$ and $1$. This
semiring, and the matrices over it, have been studied since at least Zaretskii's
foundational paper~\cite{Zaretskii1963aa} in 1963. \\

The \defn{min-plus semiring} $\K^{\infty}$ is the set $\N \cup \{\infty\}$, with
$\oplus = \min$ and $\otimes$ extending the usual addition on $\N$ so that
$x\otimes\infty = \infty\otimes x = \infty$ for all $x \in \K^{\infty}$. For our
purposes, $0 \in \N$, and so the one of $\K^{\infty}$ is $0$ and the zero is
$\infty$. \\ 
%The min-plus semiring was first introduced by
%Simon~\cite{Simon1978aa} in the context of automata theory; see also
%Pin~\cite{Pinab}. 
The \defn{max-plus semiring} $\K^{-\infty}$ is the set $\N \cup \{-\infty\}$ with
$\oplus = \max$ and $\otimes$ extending the usual addition on $\N$ so that
$x\otimes-\infty = -\infty\otimes x = -\infty$ for all $x \in \K^{-\infty}$. The
one of $\K^{-\infty}$ is $0$ and the zero is $-\infty$.

We are also interested in certain finite quotients of these semirings. The
\defn{min-plus semiring with threshold $t$}, denoted $\K^{\infty}_t$, is the set
$\{0, 1, \ldots, t, \infty\}$ with operations $\oplus = \min$ and $\otimes$
defined by
\begin{align*}
  a \otimes b = \begin{cases}
    \min(t, a + b) \quad &\text{$a \neq \infty$ and $b \neq \infty$} \\
    \infty \quad &\text{$a = \infty$ or $b = \infty$}.
  \end{cases}
\end{align*}

The \defn{max-plus semiring with threshold $t$}, denoted $\K^{-\infty}_t$, is
constructed analogously; its elements are $\{-\infty, 0, 1, \ldots, t\}$,
addition is $\max$, and multiplication is defined by $a \otimes b = \min(t, a +
b)$ for all $a, b \in \K^{-\infty}_t$.

These finite semirings with threshold $t$ may also be defined as the quotient of
the corresponding infinite semirings by the congruence generated by $(t, t +
1)$.

The min-plus and max-plus semirings are known as \defn{tropical} semirings.
Tropical semirings have attracted significant attention recently due to ???
TODO, see TODO.

The final semirings that we are concerned with are the \defn{modular integers}
$\Z_n$; given $n \in \N$, $\Z_n$ consists of the set $\{0, 1, \ldots, n - 1\}$
where $\oplus$ is addition modulo $n$, and $\otimes$ is multiplication modulo
$n$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Matrix semigroups}
\label{sec:matsemigp}
Given a semiring $\mathbb{S}$ and $m, n \in \N$, we may study the set of $m
\times n$ matrices over $\mathbb{S}$; we will denote this by $M_{m,
  n}(\mathbb{S})$. In particular, we are interested in the multiplicative monoid
of square matrices of dimension $n \in
\N$ over $\mathbb{S}$, denoted by $M_n(\mathbb{S})$.
There are a number of common features of such matrix monoids. As usual, we let
$0$ denote the additive identity of $\mathbb{S}$ and $1$ denote the
multiplicative identity.

Let $A \in M_n(\mathbb{S})$. We write $A_{i*}$ to denote the $i$th row of $A$,
$A_{*i}$ to denote the $i$th column, and $A_{ij}$ to denote the $j$th entry of
the $i$th row. A \defn{linear combination} of rows is a sum of scalar multiples
of the rows, where both operations are defined componentwise in the usual way.
The \defn{row space} $R(A)$ of $A$ is the set of all linear combinations of the
rows of $A$.  A set of rows is \defn{linearly independent} if some row can be
written as a linear combination of other rows; this coincides with the usual
definition when $\mathbb{S}$ is a field. \defn{Spanning sets} are defined
exactly as for matrices over fields: a spanning set for a row space is a set of
rows which every element of the row space may be written as a linear combination
of. A \defn{row basis} of $A$ is then a linearly independent spanning set for
the row space of $A$. \defn{Column spaces} and \defn{column bases} are defined
dually. The importance of row and column bases arises from the following
well-known results:

\begin{prop}
  \thlabel{prop:rowsandideals}
  Let $A, B \in M_n(\mathbb{S})$. Then the following hold:
  \begin{enumerate}[label={(\roman*)}]
    \item
      If $R(A) \subseteq R(B)$, then $A \in M_n(\mathbb{S}) B$.  Similarly, if $C(A)
      \subseteq C(B)$, then $A \in B M_n(\mathbb{S})$.

    \item 
      $R(AB) \subseteq R(B)$ and $C(AB) \subseteq C(B)$.
  \end{enumerate}
\end{prop}
\begin{proof}
  \noindent \textbf{(i).}
  If $R(A) \subseteq R(B)$, then every row of $A$ can be expressed as a linear
  combination of rows of $B$. For $1 \leq i \leq n$ of $A$, let $A_{i*} =
  \sum_{j = 1}^{n}x_{ij}B_{j*}$, and define $X = [x_{ij}]$. Then $A = XB \in
  M_n(\mathbb{S})B$. The other case is dual.
  \bigskip

  \noindent \textbf{(ii).}
  Suppose that $A = [\alpha_{ij}]$ and $B = [\beta_{ij}]$. If 
  $AB = [\gamma_{ij}]$, then 
  \[
  \gamma_{ij} = \alpha_{i1} \beta_{1j} + \alpha_{i2}\beta_{2j} 
                + \cdots + \alpha_{in}\beta_{nj}
              = \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kj}.
  \]
  It follows that the $i$th row of $AB$ is 
  \[
  (\gamma_{i1}, \gamma_{i2}, \ldots, \gamma_{in})
   =  \left (\sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k1},
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k2},
     \ldots, 
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kn}\right) \\
   % & = & (\alpha_{i1}\beta_{11} + \alpha_{i2}\beta{21} + \cdots +
   %  \alpha_{in}\beta{n1},
   %  \alpha_{i1}\beta_{12} + \alpha_{i2}\beta{22} + \cdots +
   %  \alpha_{in}\beta{n2},
   %  \ldots,
   %  \alpha_{i1}\beta_{1n} + \alpha_{i2}\beta{2n} + \cdots +
   %  \alpha_{in}\beta{nn}) \\
   % & = & 
   % (\alpha_{i1}\beta_{11}, \alpha_{i1}\beta_{12}, 
   % \ldots, \alpha_{i1}\beta_{1n})
   % + 
   % (\alpha_{i2}\beta_{21}, \alpha_{i2}\beta_{22}, 
   % \ldots, \alpha_{i2}\beta_{2n})
   % + \cdots +
   % (\alpha_{in}\beta_{n1}, \alpha_{in}\beta_{n2}, 
   % \ldots, \alpha_{in}\beta_{nn}) \\
    =
    \sum_{k = 1} ^ {n} 
    \alpha_{ik}B_{k*}.
  \]
  Thus the $i$th row of $AB$ is a sum of rows of $B$, and so $R(AB) \subseteq
  R(B)$. 
\end{proof}

\begin{prop} 
  \thlabel{lem:GreensRowColumnSpaces}
  Let $A, B \in M_n(\mathbb{S})$. Then $A \L B$ if and only if $R(A) = R(B)$,
  and $A \R B$ if and only if $C(A) = C(B)$. 
\end{prop}
\begin{proof}
  \textbf{(i) $\Rightarrow$ (ii).} 
  If $A \L B$, then there are $X, Y \in M_n(\mathbb{S})$ such that $XA = B$ and
  $YB = A$. Then $R(B) = R(XA) \subseteq R(A)$ and $R(A) = R(YB) \subseteq R(B)$
  by Proposition~\ref{prop:rowsandideals}(ii).
  \bigskip

  \textbf{(ii) $\Rightarrow$ (i).} Follows immediately by
  Proposition~\ref{prop:rowsandideals}(i). 
\end{proof}

The \defn{group of units} of $M_n(\mathbb{S})$ is the group of invertible
matrices (\defn{units}) in $M_n(\mathbb{S})$; the identity matrix is always a
unit. The group of units is always the maximal class in the $\J$-order of
$M_n(\mathbb{S})$.

For any semiring $\mathbb{S}$, the symmetric group embeds into the group of units of
$M_n(\mathbb{S})$ by the map 
\begin{align*}
  \phi:\: &\alpha \to [a_{ij}], \\
  &a_{ij} =
    \begin{cases}
      1 \quad & i\alpha = j \\ 
      0 \quad &\text{otherwise}.
    \end{cases}
\end{align*}
The image of this embedding will often simply be referred to as $S_n$ or the
symmetric group when context prevents ambiguity. Elements of this embedding
$S_n$ are called \defn{permutation matrices}; multiplying by a permutation
matrix on the left permutes rows of a matrix, and multiplying on the right
permutes columns. Similarly, we may define a \defn{transformation matrix} to be
one which contains a single $1$ in every row; these are the images of the
obvious extension of $\phi$ to the full transformation monoid $\mathcal{T}_n$.

Two matrices $A, B\in M_n(\mathbb{S})$ are \defn{similar} if each can be
obtained from the other by permuting the rows and/or columns. Note that similar
matrices are $\J$-related in $M_n(\mathbb{S})$, by multiplying on the left
and/or right by permutation matrices.

A non-unit matrix $A \in M_n(\mathbb{S})$ is \defn{prime} if $A = BC$ implies
$B$ or $C$ is a unit. The prime matrices of $M_n(\mathbb{S})$ are immediately
below the group of units in the $\J$-order. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Minimal generating sets}

Given a semigroup $S$, we may ask what the minimum cardinality is of a
generating set for $S$. This is known as the \defn{rank} of $S$ and is denoted
by $\mathbf{d}(S)$. A generating set $X$ for $S$ is \defn{irredundant} if no
subset of $X$ generates $S$, and we say that any irredundant generating set of
cardinality $\mathbf{d}(S)$ is a \defn{minimal generating set}. If
$\mathbf{D}(S) \in \N$, then every generating set of cardinality $\mathbf{d}(S)$
is irredundant and hence minimal; this does not hold when $\mathbf{d}(S)$ is not
finite.

\begin{de}[\textbf{Decomposable elements}]
  An element $x$ of a monoid $M$ with identity $e$ is \defn{decomposable} if
  there exist $y, z \in M$ with $x = yz$, and \defn{properly decomposable} if
  there exist $y, z \in M\setminus\{e, x\}$ such that $x = yz$.
\end{de}

\begin{lemma}
  \thlabel{lem:GenSetDecomposition}
  Let $S$ be a finite semigroup and let $X \subseteq$ be a set of elements which
  generate all elements of the maximal $\J$-classes of $S$. Suppose that for all
  $s$ not in the maximal $\J$-classes of $S$, $s$ can be written as a product of
  elements which lie strictly above $s$ in the $\J$-order. Then $X$ generates
  $S$. 
\end{lemma}
\begin{proof}
  Let $x \in S$. Then either $x$ is in a maximal $\J$-class, in which case we
  are done, or $x$ may be written as a product of elements which lie strictly
  above $x$ in the $\J$-order. This argument may be repeated for each of those
  elements. Since $S$ is finite, we must eventually reach a decomposition of $x$
  into elements in maximal $\J$-classes, and hence $x \in \genset{x}$.
\end{proof}

\begin{prop}[Wilf, elsewhere]
  \thlabel{prop-wilf}
  Let $S$ be a finite semigroup.  Suppose that $X$ is an irredundant generating
  subset of $S$ that contains at most one element from each $\D$-class of $S$.
  Then $X$ has minimal cardinality, i.e. $\rank(S) = |X|$.
\end{prop}
\begin{proof}
  Wilf claims to have proven this.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Boolean Matrix Monoids}
\label{sec:boolmat}

In this section, we compute minimal generating sets for the full boolean matrix
monoid $\Bn$ and some of its natural submonoids. In order to define these
submonoids, we must introduce the concept of matrix containment: given two
matrices $A, B \in \Bn$, we say that $A$ is \emph{contained} in $B$ if for all
$1 \leq i,j \leq n$, $A_{ij} = 1$ implies that $B_{ij} 1$; that is, $B$ contains
a $1$ in every position in which $A$ does.

We consider the submonoids:
\begin{enumerate}
  \item $\Refn$, of matrices containing the identity (reflexive matrices),
  \item $\Halln$, of matrices containing a permutation matrix (Hall matrices),
  \item $\MTn$, of matrices containing a transformation matrix, and
  \item $\UTn$ and $\LTn$, of upper- and lower-triangular boolean matrices.
\end{enumerate}

There is a natural isomorphism $\Theta$ between binary relations on $\{1,
  \ldots, n\}$ and $\Bn$, which maps a binary relation $\mu$ to the matrix $M
\in \Bn$ such that $M_{ij} = 1$ if and only if $(i, j) \in \mu$.
The monoid $\Refn$ arises as the image of the reflexive binary relations under
$\Theta$, and this is the primary reason for studying $\Refn$. However, it may
also be viewed as the monoid of matrices containing a certain pattern of $1$s -
namely the identity matrix. Similarly, $\Halln$ arises as those matrices
describing a family of subsets which satisfy Hall's marriage condition, but also
as those matrices containing a permutation matrix. By increasing the number of
permitted patterns, we obtain the monoid $\MTn$, consisting of those matrices
containing a transformation. 

We compute the largest known ranks of these monoids, which are presented in
Table~\ref{tab:BMatResults} along with whether that rank was previously known or
is practically computable by brute force. The rank of $\UTn$ is given by the
triangular numbers $T_n$ for $n \geq 2$; this may have already been known but we
were unable to find a reference in the literature. Note that since $\UTn$ and
$\LTn$ are anti-isomorphic via the transposition map, $\mathbf{d}(\UTn) =
\mathbf{d}(\LTn)$ for all $n$. None of the other ranks are known beyond $n = 8$. 

\begin{table}
  \centering
  \begin{tabular}{l|r|r|r|r|r}
    $n$ & $\mathbf{d}(\Bn)$ & $\mathbf{d}(\Refn)$ & $\mathbf{d}(\Halln)$ &
    $\mathbf{d}(\MTn)$ & $\mathbf{d}(\UTn)$ \\ 
    \hline
    1 & *2         & *1& *1& *1& *2\\
    2 & *3         & *2& *2& *3& *3\\
    3 & *5         & *8& *4& *5& *6\\
    4 & *7         & *38& *6& *7& *10\\
    5 & *13        & *1\ 415& *12& *13& *15\\
    6 & 68         & 482\ 430& 67& 68& 21\\
    7 & 2\ 143     & 1\ 034\ 972\ 230& 2\ 142& 2\ 143& 28\\
    8 & 495\ 115   & ?& 495\ 114& 495\ 115 & 36\\
    9 & ?   & ?& ?& ? & 45
  \end{tabular}
  \vspace{1cm}

  \caption{The ranks of certain matrix monoids over $\B$; a * denotes that the
    rank was already known or is computable by brute force, and a ? indicates
    that the value is unknown.}
  \label{tab:BMatResults}
\end{table}
There are several obvious relationships between columns in
Table~\ref{tab:BMatResults}; we prove that these relationships hold for all $n
\in \N$.

There are a number of other submonoids of $\Bn$ that may be considered. If we
define the \defn{containment closure} $\bar{S}$ of a subsemigroup $S \leq \Bn$
to be the set of matrices $A \in \Bn$ containing some element of $S$, then for
any choice of subsemigroup $S$, $S \leq \bar{S} \leq \Bn$. In
particular, the submonoids $\Refn$, $\Halln$, and $\MTn$ are of this type. It
remains an open problem to determine minimal generating sets for arbitrary
containment closures. This problem seems difficult; a more tractable problem may
be to restrict $S$ to subgroups of $S_n$ or submonoids of transformation
matrices.

%TODO: namedrop gossip monoid

The rest of Section~\ref{sec:BoolMat} is organised as follows. In
Section~\ref{sec:BMatPrelim}, we introduce a number of concepts and results
particular to matrices over $\B$. These are used throughout the rest of
Section~\ref{sec:boolmat}. In Section~\ref{sec:FullBoolMat}, we describe how to
compute minimal generating sets for $\Bn$ based on a theorem of
Devadze~\cite{Devadze1968aa}. In Section~\ref{sec:RefBoolMat}, we describe the
unique minimal generating sets for $\Refn$ and how to compute it; in
Sections~\ref{sec:HallBoolMat} and~\ref{sec:TransBoolMat} we describe how all
minimal generating sets for $\Halln$ and $\MTn$ may be obtained from minimal
generating sets for $\Bn$; and in Section~\ref{sec:TriBoolMat} we give a simple
description of the unique minimal generating sets for $\UTn$ and $\LTn$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preliminaries}
\label{sec:BMatPrelim}
The semiring $\B$ is one of the simplest examples of a semiring, and the matrix
monoid $\Bn$ has been widely studied in the literature; see~\cite{TODO}. In
particular, there is a description of a minimal generating set for $\Bn$, due to
Devadze in 1968~\cite{Devadze??} and proven correct by Konieczny in
2011~\cite{Konieczny2011aa}. However, these generating sets are difficult to
compute and so explicit generating sets, even for $n = 6$, were unknown. It was
known that the size of a minimal generating set for $\Bn$ grows very quickly
with $n$; see~\thref{cor:ExponentialGenSets}.

In contrast, the subsemigroup of $\Bn$ generated by all the regular elements can
be generated by the four matrices

\begin{align*}
  T = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    1 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  U = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    0 & 0 & 0 & 0 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & 0 & 0 & 0 & \cdots & 0 
  \end{pmatrix},&\\
  E = \begin{pmatrix}
    1 & 0 & 0 & 0 & \cdots & 0 \\
    1 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  F = \begin{pmatrix}
    0 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1
  \end{pmatrix};
\end{align*}
see \cite{Roush1977aa} for further details.
We will continue to use these names for these matrices throughout
Section~\ref{sec:boolmat}. Note that together $T$ and $U$ generate $S_n$ for $n
\geq 2$.

We call any matrix similar to $E$ an \defn{elementary} matrix. In particular,
the elementary matrix which consists of the identity matrix with an additional
$1$ in position $j$ of the $i$th row will be denoted by $E^{i,j}$. If $J_E$ is
the $\J$-class of $E$ in $\Bn$, then it is easy to show that $J_E =
\set{E^{i,j}}{1 \leq i, j \leq n}$ and we call $J_E$ the \defn{elementary
  $\J$-class}. 
\begin{thm}[Devadze's Theorem \cite{Konieczny2011aa}]
  \thlabel{thm:DevadzeKon}
  For $n > 2$, the set $\{T, U, E, F\} \cup P$ is a generating set for $\Bn$ of
  minimum cardinality, where $P$ is any set containing one matrix from every
  $\J$-class of $\Bn$ which contains a prime matrix. 
\end{thm}
By Devadze's Theorem, in order to determine the rank of $\Bn$ it is sufficient
to compute a set of representatives of the $\J$-classes of $\Bn$ containing a
prime matrix; this is the content of Section~\ref{sec:fullboolmat}.

As well as the description of a minimal generating set for $\Bn$, there are
certain additional concepts attached to $\Bn$ which do not apply to matrices
over arbitrary semirings. Many of these arise from the observation that we may
view a vector $v \in \B^n$ as the characteristic function of a subset $s(v)$ of
$\{1, \ldots, n\}$, where $i \in s(v)$ if and only if $v_i = 1$.  Then we define
the \defn{union} of two vectors $v, w$ to be $s^{-1}(s(v) \cup s(w))$. Note that
the union and sum of two vectors coincide in $\B^n$. In fact, since there is a
single non-zero element of $\B$, unions, sums, and linear combinations all
coincide. Given $v, w \in \B^n$, we also say that $v$ is \defn{contained} in
$w$, and write that $v \leq w$, if $s(v) \subseteq s(w)$.

It is straightforward to verify that if $A \in \Bn$, then there is a unique row
basis $r(A)$, which is the unique minimal generating set for $R(A)$ under union,
consisting of the non-zero $\leq$-minimal rows. The dual statement for column
spaces also holds. This yields a strengthening of
\thref{lem:GreensRowColumnSpaces}.

\begin{prop} 
  \thlabel{lem:BMatGreensRowColumnBases}
  Let $A, B \in \Bn$. Then $A \L B$ in $\Bn$ if and only if $r(A) = r(B)$,
  and $A \R B$ in $\Bn$ if and only if $c(A) = c(B)$.
\end{prop}
There is a simple algorithm to compute the row and column bases of matrices in
$\Bn$ in time and space cubic in $n$, and hence the previous proposition gives
an efficient method for determining whether two matrices are $\L$- or
$\R$-related in $\Bn$. This, in combination with
\thref{lem:GreensRowColumnSpaces}, allows for the efficient computation of the
$\L$- and $\R$-structure of $\Bn$. However, the number of $\L$- and $\R$-classes
grows extremely rapidly with $n$, as shown in Table~\ref{tab:NumberLRClasses},
so that it quickly becomes infeasible to compute the $\L$- and $\R$-structure of
$\Bn$. Note that transposition gives an anti-automorphism from $\Bn$ to itself
which exchanges $\L$ and $\R$ classes, and hence determining the $\L$- and
$\R$-structure only requires computation of one of the relations.

\begin{table}
  \centering
  \begin{tabular}{r|r|r|r|r|r|r|r}
    $n$ & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
    \hline
     & 2 & 7 & 55 & 1\ 324& 120\ 633& 42\ 299\ 663& ?  
  \end{tabular}
\vspace{1cm}

\caption{The number of $\L$- or $\R$-classes in $\Bn$.} 
  \label{tab:NumberLRClasses}
\end{table}

Even determining the possible cardinalities of row spaces of matrices in $\Bn$
is a hard problem: see \cite{Breen2001aa, Konieczny1992aa, Li1995aa,
  Shaofang1998aa, Zivkovic2006aa}. This is in stark contrast to the row-spaces
of matrices over fields, which have dimension a power of the cardinality of the
field. For example, the matrix \[\mat{0}{1}{1}{1} \in \Bn\] has row space
cardinality $3$.

It is significantly more difficult to determine the $\J$-relation in $\Bn$ than
the $\L$- or $\R$-relation. Indeed, the problem of determining whether two
matrices are $\J$-related in $\Bn$ is NP-hard~\cite[Theorem 2.7]{Fenner2018aa}.
The $\J$-relation on $\Bn$ is characterised by row space embeddings in the
following theorem; a function $f: R(A) \to R(B)$ is a \defn{row space embedding}
if it respects containment and non-containment, i.e.\ $f(v) \leq f(w)$ if and
only if $v \leq w$ for all $v, w,
\in R(A)$.
\begin{thm}[Zaretskii's Theorem~\cite{Zaretskii1963aa}]
  \thlabel{thm:Zaretskii}
  Let $A, B \in \Bn$. Then $A \leq_{\J} B$ if and only if there exists a row
  space embedding $f: R(A) \to R(B)$.
\end{thm}
Zaretskii's Theorem reduces the problem of determining the $\J$-order $\Bn$ to
problem of digraph embedding, but it should be noted that the size of $R(A)$ is
bounded above by $2^n$, and equality is possible. Computing the $\J$-structure of
$\Bn$ is challenging; see \cite{Breen1997aa}. The largest $n$ for which the
number of $\J$-classes of $\Bn$ is known is $8$; see \cite{Breen2001aa}.


Considering rows as subsets of $\{1, \ldots, n\}$, it is natural to consider
when rows of a matrix $A \in \Bn$ are contained in other rows of $A$. We will
call $A$ \defn{row-trim} if no non-zero row of $A$ is contained in another row.
\defn{Column-trim} is defined dually. We say that $A$ is \defn{trim} if it is
both row-trim and column-trim.

Our interest in trim matrices is due to the following result.

\begin{lemma}[{\cite[Lemma 3.1]{Konieczny2011aa}}]
  \thlabel{lem:PrimeMatricesAreTrim}
  Every prime matrix in $\Bn$ is trim.
\end{lemma}
\begin{proof}
  Let $A \in \Bn$ be prime. Suppose some non-zero row indexed $k$ of $A$ is
  contained in a row indexed $l$ of $A$. Define $X \in \Bn$ to be the matrix
  such that $X_{ij} = 1$ precisely if $A_{j*} \leq A_{i*}$. Then $XA = A$, and
  since $|X_{l*}| \geq 2$, $X \not\in S_n$, a contradiction. A dual argument
  shows that no non-zero column of $A$ is contained in another column.
\end{proof}

It is difficult to enumerate prime matrices directly, but comparatively simple
to enumerate trim matrices. This is key to our strategy for computing a minimal
generating set for $\Bn$.

The technique used to define the matrix $X$ in the proof of
\thref{lem:PrimeMatricesAreTrim} will be useful throughout. Given two matrices
$A, B \in \Bn$, we say that the \defn{greedy left multiplier} of $(A, B)$ is the
matrix $C$ containing a $1$ in position $j$ of row $i$ if and only if $A_{j*}
\leq B_{i*}$. The \defn{greedy right multiplier} of $(A, B)$ is the matrix $D$
containing a $1$ in position $j$ of row $i$ if and only if $A_{*i} \leq B_{*j}$.

A similar property to being trim is being \defn{reduced}. A matrix $A \in \Bmn$
is \defn{row-reduced} if no row of $A$ can be written as a union of other rows
of $A$. \defn{Column-reduced} is defined dually. We say that $A$ is
\defn{reduced} if it is both row-reduced and column-reduced. Since no row of a
trim matrix is contained in another row, it follows that no row can be expressed
as a union of other rows. A dual argument applies to columns, and hence we have
the following lemma.

\begin{lemma}
  \thlabel{lem:TrimMatricesAreReduced}
  Every trim matrix is reduced.
\end{lemma}

The following lemma describes the $\J$-relation on reduced matrices in $\Bn$.

\begin{lemma}[{\cite[Theorem 1.8]{Plemmons1970aa}}]
  \thlabel{lem:PermutingReducedMatrices}
  Let $A, B \in \Bn$ be reduced. Then $A \J B$ if and only if $A$ and $B$ are
  similar.
\end{lemma}

Due to the previous lemma, reduced matrices are particularly convenient to
compute with. A linear reduction to graph isomorphism, described in
Section~\ref{sec:fullboolmat}, shows that the problem of determining whether two
reduced matrices are $\J$-related has complexity at most quasi-polynomial; see
\ref{TODO:babai}.
%TODO: babai paper not published yet?
It also implies that the $\J$-class of any prime matrix $P$ consists of prime
matrices similar to $P$, and we refer to such a $\J$-class as a \defn{prime
  $\J$-class}. Note that a prime $\J$-class therefore contains at most $(n!)^2$
elements. This observation, combined with Devadze's Theorem, has the following
corollary.

\begin{cor}
  \thlabel{cor:ExponentialGenSets}
  The size $\mathbf{d}(\Bn)$ of a minimal generating set for $\Bn$ grows
  super-exponentially with $n$.
\end{cor}
\begin{proof}
  This follows from the fact that there at least $2^{\frac{n^2}{4} - O(n)}$
  prime boolean matrices in $\Bn$ (see~\cite[Theorem 2.4.1]{Kim1982aa}) and each
  prime $\J$-class contains at most $(n!)^2$ elements; hence there are
  super-exponentially many prime $\J$-classes.
\end{proof}
%TODO: add lower bounds here - can only do once can access book

The prime matrices of $M_n(\mathbb{S})$ sit directly below the group of units in
the $\J$-order on $M_n(\mathbb{S})$ for any semiring $\mathbb{S}$. In the case of
$\Bn$, there is an additional $\J$-class immediately below $S_n$: the $\J$-class
$J_E$ of the elementary matrix $E$ from \ref{}. The next result shows that in
fact these are all of the $\J$-classes immediately below $S_n$.

Let $\beta_n$ denote the set $\set{R(A)}{A\in \Bn\setminus S_n}$ of all
possible proper row subspaces of elements of $\Bn$, and let $\B^n$ denote
the space of all boolean vectors of length $n$. Note that $A \in \Bn$ has row
space equal to $\B^n$ if and only if permutation matrices.

\begin{thm}[cf. Theorem 5.1 in~\cite{Caen1981ab}]
  \thlabel{thm:MaximalRowSpaces}
  Let $A \in \Bn\setminus S_n$. Then $R(A)$ is maximal with respect to
  containment in $\beta_n$ if and only if $A$ is prime or elementary.  
\end{thm}

We may now prove a slightly stronger form of Devadze's Theorem.

\begin{thm}[Devadze's Theorem \cite{Konieczny2011aa}]
  \thlabel{thm:Devadzefull}
  For $n > 2$, any minimal generating set for $\Bn$ is given by $\{T', U', E',
    F'\} \cup P$, where $T'$ and $U'$ generate $S_n$, $E'$ is elementary, $F'$
  is a matrix similar to $F$, and $P$ is a set of representatives of the prime
  $\J$-classes of $\Bn$. Conversely, any such set generates $\Bn$.
\end{thm}
\begin{proof}
  The converse follows immediately from \thref{thm:DevadzeKon}, noting that $A
  \in \genset{\{A', T', U'\}}$ for any similar matrices $A, A' \in \Bn$.

  Let $X$ be a minimal generating set for $\Bn$. Since $\mathbf{d}(S_n) = 2$,
  and $X$ must contain generators of the group of units $S_n$, it follows that
  $X$ contains two elements which together generate $S_n$, which we denote by
  $T'$ and $U'$. By \cite[Lemma 4.2]{Konieczny2011aa}, $X$ also contains a set
  $P$ of representatives of the prime $\J$-classes of $\Bn$. By \cite[Lemma
  4.5]{Konieczny2011aa}, and the fact that the elementary $\J$-class lies
  immediately below the group of units, $X$ must also contain an elementary
  matrix, say $E'$. It only remains to show that $X$ must contain a matrix
  similar to $F$. Since none of the elements of $P$, nor $E'$, contain a
  zero row, $P \cup \{E'\}$ does not generate $F$, and $X$ must contain a matrix
  with at least one zero row. Since matrices similar to $F$ have the maximal row
  spaces amongst matrices containing zero rows, $X$ must contain a matrix
  similar to $F$.
\end{proof} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Full Boolean Matrix Monoid}
\label{sec:FullBoolMat}
As mentioned above, in order to compute minimal generating sets for $\Bn$ it is
sufficient to compute sets of representatives of the prime $\J$-classes of
$\Bn$. In this section we describe how such a computation may be performed.

The \defn{kernel} of a function $f: X \to Y$ is the equivalence relation
containing a pair $(a, b)$ if and only if $f(a) = f(b)$.
We call a function $\phi: \Bn \to \Bn$ a \defn{canonical form} if
$\ker\phi = \J$. Given a canonical form $\phi$, the image $\im\phi$ is a
set of representatives of the $\J$-classes of $\Bn$, and the image
$P_\phi = \phi(\set{A \in \Bn}{\text{$A$ prime}})$ is a set of
representatives of the prime $\J$-classes of $\Bn$. 

We wish to enumerate $P_\phi$ for some canonical form $\phi$. Roughly speaking,
our strategy is to enumerate efficiently as small a superset $Q_\phi \subsetneq
\im\phi$ of $P_\phi$ as is practical, and then to filter $Q_\phi$ to remove the
non-prime matrices.
The full image $\im\phi$ is a set of representatives for the $\J$-classes of
$\Bn$; Table~\ref{tab:NumberJClasses} demonstrates the growth of $\im\phi$ for
$n = 1, \ldots, 8$. The number of trim matrices in Breen form in $\Bn$ is
comparable to the number of $\J$-classes for $n \leq 8$.
Since is infeasible to compute the image of each of the $2^{n^2}$ elements of
$\Bn$ for $n \geq 7$; we instead compute the images of a smaller set of matrices
which contains at least one matrix of every $\J$-class of $\Bn$.
particular form. 

\begin{de}[{{\cite[Proposition 3.6]{Breen1997aa}}}]
  \thlabel{de:BreenForm}
  We say that a matrix $A \in \Bmn$ is in \emph{Breen form} if it has all of
  the following properties:
  \begin{enumerate}
  \item{$A$ is reduced,}
  \item{all non-zero rows of $A$ are at the bottom,}
  \item{all non-zero columns of $A$ are at the right,}
  \item{the non-zero rows of $A$ as binary numbers are a strictly increasing
      sequence, as are the columns}
  \item{all ones in the first non-zero row of $A$ are on the right,}
  \item{all ones in the first non-zero column of $A$ are at the bottom,}
  \item{every non-zero row has at least as many ones as the first non-zero row.}
  \end{enumerate}
\end{de}

This definition appears as a proposition in \cite{Breen1997aa}; Breen defines a
matrix in $\Bn$ to be in \emph{standard form} if the matrix has minimal value as
a binary number in its $\J$-class, and proves that such a matrix has the
properties of \thref{de:BreenForm}~\cite[Prop 3.6]{Breen1997aa}. This leads
directly to the following proposition:

\begin{prop}
  \thlabel{prop:BreenFormsExist}
  In every $\J$-class $\Bn$, there exists a matrix in Breen form. 
\end{prop}

In contrast, being in Breen form is not enough to guarantee that a matrix is
minimal. Consequently there is not a unique matrix in each $\J$-class of $\Bn$
in Breen form, as the following example demonstrates. 
\begin{ex}
Let $A, B \in \Bn$ be the matrices defined by
\begin{align*}
  \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\quad \quad
  \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}&\\
\end{align*}
respectively. Then $A$ and $B$ are in the Breen form of
\thref{de:BreenForm}. Swapping rows $1$ and $2$ and columns $3$
and $4$ shows that $A$ and $B$ are similar, and hence are $\J$-related in $\Bn$.
\end{ex}

There are significantly fewer than $2^{n^2}$ matrices in Breen form in $\Bn$,
as shown in Table~\ref{tab:BreenFormMatrices}, and so it is feasible to
enumerate the matrices in Breen form for several values of $n$ for which it
is not feasible to enumerate the matrices in $\Bn$.
Given the set $S$ of matrices in Breen form in $\Bn$, and a canonical form
$\phi$, the image $Q_\phi = \phi(S)$ contains $P_\phi$. Later in this section,
we will discuss several methods of filtering $Q_\phi$ to obtain the prime
matrices. 

\begin{table}
  \centering
  \begin{tabular}{l|r|r|r|r|r}
    $n$ & $|\Bn|$ & $|\mathcal{B}_n|$ & $|\mathcal{TB}_n|$ & $\phi(\mathcal{TB}_n)$ &
    $|J(\Bn)|$~\cite{Breen2001aa, Breen1997aa} \\
      \hline
    $1$ & 2 & 2 & 2 & 2 & 2\\
    $2$ & 16 & 4 & 3 & 3 & 3\\
    $3$ & 512 & 13 & 5 & 5 & 11\\
    $4$ & 65\ 536 & 146 & 12 & 10 & 60\\
    $5$ & 33 554 432& 7\ 549 & 141& 32 & 877\\
    $6$ & 68\ 719\ 476\ 736& 1\ 660\ 301& 15\ 020 & 394 & 42\ 944\\
    $7$ & $5.6 \times 10^{14}$ & 1\ 396\ 234\ 450 & 7\ 876\ 125 & 34\ 014 & 7\ 339\ 704 \\
    $8$ & $1.8 \times 10^{19}$ & ? & 18\ 409\ 121\ 852 & 17\ 120\ 845 & 4\ 256\ 203\ 214
  
  \end{tabular}
  \vspace{1cm}

  \caption{The sizes of: the monoid $\Bn$, the set $\mathcal{B}_n$ of matrices
    in $\Bn$ in Breen Form; the set $\mathcal{TB}_n$ of trim matrices in Breen
    form in $\Bn$; the image $\phi(\mathcal{TB}_n)$ of the trim Breen-form
    matrices under any canonical form $\phi$; and the set $J(\Bn)$ of
    $\J$-classes of $\Bn$.}
  \label{tab:BreenFormMatrices}
\end{table}

While theoretically any canonical form $\phi$ is sufficient, the complexity of
computing $\phi$ is important. We now describe how to obtain canonical forms
$\Phi_n$ that are practical to compute with, using a reduction to bipartite
graphs.

Given a matrix $A \in \Bn$, we may form the vertex-coloured bipartite graph
$\Gamma(A)$ with vertices $\{1, \ldots, 2n\}$, colours 
\[\mathbf{col}(v) = \begin{cases}
    0 \qquad &1 \leq v \leq n, \\
    1 \qquad &n < v \leq 2n,
  \end{cases}
\]
and an edge from $i$ to $j+n$ if and only if $A_{ij} = 1$. The numbers $\{1,
  \ldots, n\}$ represent indices of rows and the numbers $\{n + 1, \ldots, 2n\}$
represents indices of columns in the matrix $A$.

It is easy to see that $\Gamma$ is a bijection from $\Bn$ to the set $\BGSet$ of
bipartite graphs with two parts of size $n$, where one part is coloured $0$ and
the other coloured $1$. We call a function $\psi: \BGSet \to \BGSet$ a
\emph{canonical form} for $\BGSet$ if the equivalence classes of $\ker\psi$ are
the graph-theoretical colour-preserving isomorphism classes of $\BGSet$.
Computing canonical forms for graphs is a well-studied problem; for a recent
article see~\cite{McKay2013aa} and the references within. 
and we use the software bliss\footnote{In fact, a slightly-modified version of
  bliss which avoids repeated memory allocation was used; this is available at
  \cite{TODO}}~\cite{Junttila2007aa, Bliss} to obtain such functions $\psi_n$. 
\begin{lemma}
  The function $\Phi_n = \Gamma^{-1}\psi_n\Gamma$ is a canonical form when
  restricted to reduced matrices. 
\end{lemma}
\begin{proof}
  We must show that $\ker\Phi_n = \J$, in other words $\Phi_n(A) = \Phi_n(B)$ if and
  only if $A\J B$. This is equivalent to showing $\Gamma(A)$ is isomorphic to
  $\Gamma(B)$ if and only if $A \J B$. Denote the vertices of $\Gamma(A)$ by
  $\{1, \ldots, 2 n\}$ and the vertices of $\Gamma(B)$ by $\{1', \ldots, 2n'\}$,
  as above.
  Suppose that there is a colour-preserving isomomorphism $\Psi: \Gamma(A) \to
  \Gamma(B)$. Since $\Psi$ preserves colours, $\Psi$ maps $\{1, \ldots, n\} \to
  \{1', \ldots, n'\}$ and $\{n + 1, \ldots, 2n\} \to \{(n + 1)', \ldots, 2n'\}$.
  Define permutations $\alpha, \beta$ on $\{1,\ldots, n\}$ by 
  \begin{align*}
    \alpha(i) &= j \text{ if } \Psi(i) = j',\\
    \beta(i)  &= j \text{ if } \Psi(n + i) = (n + j)'.
  \end{align*}
  Then by permuting the rows and columns of $A$ by $\alpha$ and $\beta$
  respectively, $A$ is similar to $B$ and hence $A \J B$ in $\Bn$.

  Conversely, suppose that $A \J B$ in $\Bn$. Then by
  \thref{lem:PermutingReducedMatrices}, there exist $\alpha$ and $\beta$ such
  that by permuting the rows and columns of $A$ by $\alpha$ and $\beta$
  respectively $B$ is obtained. The map $\Psi$ defined by
  \[\Psi(i) = \begin{cases}
      j' \quad &\text{if } 1 \leq i \leq n \text{ and }\alpha(i) = j, \\
      (n + j)' \quad &\text{if } n < i \leq 2n \text{ and }\beta(i) = j
    \end{cases}
  \]
  is a colour-preserving isomorphism between $\Gamma(A)$ and $\Gamma(B)$.
\end{proof}

Given $v \in \B^n$, it will convenient to denote the number represented by $v$
in binary as $\bar{v}$. We will also write $n^\dagger$ to denote the boolean
vector such that $\bar{n^\dagger} = n$.

We now describe how to backtrack through matrices in Breen form to find a
superset of prime matrices $Q_{\Phi_n}$. This may be seen as a depth-first
traversal of a (non-rooted) tree, with nodes $m\times n$ matrices ($m \leq
n$) and leaves $n \times n$ matrices.

\begin{alg}
  \thlabel{alg:canonicalbacktrack}Backtracking for canonical forms.\\
  \textbf{Input}: A natural number $n$. \\
  \textbf{Output}: A set $Q_{\Phi_n}$, with $P_{\Phi_n} \subseteq Q_{\Phi_n}
  \subseteq \im\Phi_n$.
  \begin{enumerate}
    \item We assume that we are at a node $A$ of dimension $m \times n$, and the
      index of the first non-zero row of $A$ is $f \leq m$. 
    \item If $m = n$, the non-zero columns of $A$ form a strictly increasing
      sequence, and $A$ is column-reduced, then add $\Phi_n(A)$ to $X$, the set
      of matrices to return.
    \item If $m < n$, then for each $x \in \{\bar{A_{m*}} + 1,
        \ldots, 2^n - 1\}$, if:
      \begin{enumerate}[label={(\roman*)}]
        \item $x^\dagger$ does not contain $A_{l*}$ for any $1 \leq l \leq m$,
          and
        \item $x^\dagger$ has at least as many ones as $A_{f*}$,
        \item for all column indices $1 \leq i < j \leq m$ such that $A_{*i} =
          A_{*j}$, if $x^\dagger_i = 1$ then $x^\dagger_j = 1$.
      \end{enumerate}
      set the current node to be the matrix obtained from $A$ by adjoining
      $x^\dagger$ as the last row, and return to step 1.
    \item after every $x$ has been processed, return to the previous node (if
      any) and carry out step $3$ for the next $x$ at that node (if any).
  \end{enumerate}
  Having initialised step $1$ with each $m \times n$ matrix ($m \geq 1$)
  consisting of $m - 1$ zero rows followed by a row containing some non-zero
  number of $1$s on the right, return $X$.
\end{alg}

\begin{lemma}
  \thlabel{lem:backtrackworks}
  The output of \thref{alg:canonicalbacktrack}, with input $n$, is a subset of
  $\im\Phi_n$ containing $P_{\Phi_n}$. Moreover, \thref{alg:canonicalbacktrack}
  does not compute $\Phi_n(A)$ of any matrix $A$ not in Breen form.
\end{lemma} 
\begin{proof}
  We will prove that the $A$s of step $4$ for which $\Phi_n(A)$ are calculated
  are precisely the set of trim matrices in Breen form; since every prime
  matrix is trim (\thref{lem:PrimeMatricesAreTrim}) and every $\J$-class
  contains a matrix in Breen form, this implies that the output contains
  $P_{\Phi_n}$. We will first prove that each such $A$ is in Breen form.

  Define a matrix to be in \emph{quasi-Breen form} if it satisfies each
  property of \thref{de:BreenForm} other than being column reduced and the
  non-zero columns forming a strictly-increasing sequence.
  We will prove that each node $A$ visited in the algorithm is trim and in
  quasi-Breen form. Note that the matrices that the algorithm is initialised
  with are all trim and in quasi-Breen form, so we must simply prove that
  passing from a node $A$ which is trim and in quasi-Breen form to a node
  $A'$ by adding a row $x^{\dagger}$ in step $3$ preserves these properties.

  Trimness is preserved due to condition (i) of step $3$. Since all trim
  matrices are reduced, $A'$ is also reduced. The conditions on non-zero rows
  being at the bottom and forming a strictly increasing sequence of binary
  numbers are satisfied by choosing $x$ from the range $\{\bar{A_{m*}} + 1,
    \ldots, 2^n - 1\}$.  The conditions on non-zero columns being on the right
  follows from requirement (iii) of step $3$; note that this requirement also
  forces the columns to appear in (not-necessarily-strictly) increasing order.
  The first non-zero column contains the most significant digit of the rows as
  binary numbers, and since the rows of $A'$ are increasing the set of rows with
  that digit equal to $1$ must be contiguous and at the end of $A'$. Hence all
  of the ones in the first non-zero column of $A'$ are at the bottom.

  Since each leaf $A$ visited is trim and in quasi-Breen form, the two
  conditions of step 2, that the non-zero columns form a strictly increasing
  sequence and that $A$ is column-reduced, guarantee that $A$ is in standard
  form. Hence, we only calculate the canonical form $\Phi_n(A)$ if $A$ is trim
  and in Breen form.

  It remains to prove that every trim matrix $A \in \Bn$ in Breen form is
  visited as a node in the enumeration. First, note that the first $m$ rows of
  any trim, standard-form matrix $A \in \Bn$ form an $m \times n$ trim matrix in
  quasi-Breen form. Also, the zero-rows of $A$ together with the first
  non-zero row form one of the matrices with which step $1$ is initialised. It
  simply remains to show that from each $m \times n$ node $X$ consisting of the
  first $m$ rows of $A$, we visit the $(m + 1)\times n$ node $X'$ consisting of
  the first $m + 1$ rows of $A$. It is easy to verify that each of the three
  conditions in step $3$ is satisfied by row $m + 1$ of $A$, and hence $X'$ is
  visited.
\end{proof}

Given $\Phi_n$ and $Q_{\Phi_n}$, the final step is to detect when an element of
$Q_{\Phi_n}$ is prime. We present two algorithms for doing so, in
\thref{alg:filter1} and \thref{alg:filter2}.

\begin{alg}
  \thlabel{alg:filter1}Filtering canonical forms by row spaces.\\
  \textbf{Input}: A set $Q_{\Phi_n}$, containing the images $P_{\Phi_n}$ of the
  prime matrices of $\Bn$ under $\Phi_n$, and not containing any permutation
  matrices. \\
  \textbf{Output}: The set $P_{\Phi_n}$.
  \begin{enumerate}
  \item 
    Compute $X = \set{R(A\alpha)}{A \in Q_{\Phi_n} \cup \{E\}, \alpha \in S_n}$
  \item
    For every $A \in Q_{\Phi_n}$, and for every $R(B\beta) \in X$, if $A \neq B$ and
    $R(A) \subsetneq R(B\beta)$ then discard $R(A\alpha)$ from $X$ for all
    $\alpha \in S_n$.
  \item
    Output $T\subset Q_{\Phi_n}$, the set of non-elementary elements $A$ such that $R(A)$
    remains in $X$ after the previous step.
  \end{enumerate}
\end{alg}

\begin{lemma}
  The output of \thref{alg:filter1} is a set of representatives of prime
  $\J$-classes.
\end{lemma}
\begin{proof}
  Since the $\J$-class of a prime matrix consists only of similar matrices, the
  set $\set{R(A\alpha)}{A \in P_{\Phi_n}} \subset X$ contains all row spaces of
  prime matrices in $\Bn$, and hence so does $X$. Similarly, $X$ contains the
  row space of every elementary matrix. Hence, the elements that are maximal in
  $X$ are precisely the maximal elements of $\beta_n$ and thus by
  \thref{thm:MaximalRowSpaces} correspond to primes and elementary matrices.
  Since $R(A)$ remains in $X$ after step 2 precisely when $R(A)$ (and
  $R(A\alpha)$, for all $\alpha \in S_n$) is maximal in $X$, the output is
  $P_{\Phi_n}$.
\end{proof} 

Note that step 2 of \thref{alg:filter1} requires $O(|Q_{\Phi_n}||X|)$ comparisons.  The
size of $X$ grows extremely rapidly with $n$ as shown in
Table~\ref{tab:filter1numbers}, and so this algorithm is only suitable for small $n$.
\begin{table}
  \centering
  \begin{tabular}{l|r|r}
    $n$ & $|Q_{\Phi_n}|$ & $|X|$ \\
    \hline
    3 & 6 & 91 \\ 
    4 & 11 & 588 \\
    5 & 33 & 8194 \\
    6 & 395 & 570\ 636 \\ 
    7 & 34\ 015 & 342\ 915\ 296 \\
    8 & 17\ 120\ 845 & ? 
  \end{tabular}
\vspace{1cm}

\caption{The number of row spaces generated during \thref{alg:filter1} when
  given input $Q_{\Phi_n}$, the output of \thref{alg:canonicalbacktrack}}. 
  \label{tab:filter1numbers}
\end{table}

Using \thref{alg:canonicalbacktrack} and \thref{alg:filter1}, minimal
generating sets for $n \leq 7$ may be obtained.

For $n=8$ this algorithm is no longer sufficient, and it is necessary to use
heuristics to reduce the size of $Q$. The simplest way to do this is to select a
small subset $X \subset Q$ of matrices with large row spaces, generate the row
spaces $Y = \{R(A\alpha) :\: A \in X\} \subset R$, and check whether $R(B)$ is
contained in any element of $Y$ for each element $B \in Q$.  It is also
worthwhile to filter $R$ by checking containment in the row spaces of all the
column permutations of a known set of prime matrices, such as those described in
the following lemma.

\begin{lemma}
  \thlabel{lem:ExtendingPrimeMatrices}
  Let $A$ be a prime matrix in $M_{n-1}(\B)$. Extend $A$ to a matrix $B \in \Bn$
  by adding a row of zeros at the bottom and a column of zeros on the right,
  then setting $B_{n,n} = 1$. Then $B$ is prime in $\Bn$.
\end{lemma}
\begin{proof}
  We will show that $R(B)$ is maximal in $\beta_n$, by showing that if 
  $R(C) \in \beta_n$ contains $R(B)$, then $r(B) = r(C)$.
  Let $C$ be such a matrix.
  The last row of $B$ must also be in $C$ since it is a minimal in $\B^{n}$. 
  Now $R(A)$ has a unique basis of $n-1$ rows which must be contained in both $B$ and
  $C$, so we have $r(B) = r(C)$.
\end{proof}

For $n=8$ prefiltering by some of the large row spaces and extended prime
matrices is enough to obtain a minimal generating set, though the computation is
lengthy; see Table~\cite{tab:runtimestats} for some details. A significant
improvement can be obtained by using Zaretskii's Theorem.

\begin{table}
  \centering
  \begin{tabular}{l|r|r|r|r|r|r}
    $n$ & \thref{alg:canonicalbacktrack} & \thref{alg:filter1} &
    \thref{alg:filter2} & prefiltering & \thead{\thref{alg:filter1} with \\
      prefiltering}  & \thead{\thref{alg:filter2} with \\ prefiltering} \\
    \hline
    1 & ? & ? & ? & ? & ? \\
    2 & ? & ? & ? & ? & ? \\
    3 & ? & ? & ? & ? & ? \\
    4 & ? & ? & ? & ? & ? \\
    5 & ? & ? & ? & ? & ? \\
    6 & ? & ? & ? & ? & ? \\
    7 & ? & ? & ? & ? & ? \\
    8 & ? & ? & ? & ? & ?
  \end{tabular}
\vspace{1cm}

% include prefiltering stats (choose x% of the largest row spaces?)
\caption{Runtime of different filtering approaches; executed on TODO}
  \label{tab:runtimestats}
\end{table}


Let $A \in \Bn$. The \defn{graph} of $R(A)$ is the directed graph with vertices
$R(A)$ and an edge from $v$ to $w$ if $v \leq w$. The graph of $C(A)$ is defined
analogously.

It is an immediate corollary of Zaretskii's Theorem that $A \leq_{\J} B$ if and
only if there exists a homomorphic embedding of the graph of $R(A)$ into the
graph of $R(B)$ which respect non-edges. An efficient search for such embeddings
is implemented in~\cite{Digraphs2020aa}.

For practical computational purposes, it is useful to add extra structure to the
row space graphs to guide searches for embeddings. The \emph{augmented graph of
  $R(A)$} is the disjoint union of the graph of $R(A)$ with the empty graph on
the vertices $C = \{c_i \: : \: 1 \leq i \leq n\}$, with an edge from $v \in R(A)$
to $c_i$ if $v_i = 1$.

\begin{lemma}
  \thlabel{lem:EmbeddingGraphs}
  Let $Q$ be a superset of a canonical set of prime matrices $P$ which does not
  contain a permutation matrix, and let $A \in
  Q$. Then $A$ is not prime or elementary if and only if for some $B \in
  (Q\cup\{E\})\setminus\{A\}$ there exists a digraph embedding
  $\phi$ from the augmented graph of $R(A)$ into the augmented graph of $R(B)$
  which permutes $\{ c_i : 1 \leq i \leq n \}$ and respects non-adjacency.
\end{lemma}
\begin{proof}
  Let $A$ not be prime or elementary; then $R(A)$ is contained in the row space
  of some column permutation $\alpha$ of a $B \in Q \setminus \{A\}$.
  Then the embedding that extends the map $c_i \to c_{\alpha^{-1}i}$ has the
  properties required. Conversely, if such a map $\phi$ exists, the permutation
  $\alpha$ induced by the restriction to $C$ has the property that
  $R(B\alpha^{-1})$ contains $R(A)$, and hence by \thref{thm:MaximalRowSpaces}
  $A$ is not prime or elementary. 
\end{proof}

Note that such an embedding $\phi$ must also map a vector containing $i$ ones to
another containing $i$ ones to preserve adjacency and non-adjacency with the set
$C$.

We can therefore use the following improved algorithm to filter canonical
supersets of prime matrices.

\begin{alg}
  \thlabel{alg:filter2} Filtering canonical forms by digraph embeddings.\\
  \textbf{Input}: A canonical superset $Q$ of prime matrices $P$, which does not
  contain a permutation matrix.\\
  \textbf{Output}: The set $P$.
  \begin{enumerate}
  \item
    Generate the set $G$ of augmented graphs of row spaces of matrices in $Q$.
  \item 
    For every $K, L \in G$, if there exists an embedding of $K$ into $L$ as in
    \thref{lem:EmbeddingGraphs}, then discard $K$ from $G$.
  \item
    Output $X\subset Q$, the set of non-elementary elements $A$ with
    corresponding graphs remaining in $G$ after the previous step.
\end{enumerate}
\end{alg}

Note that this is in effect the same computation as in \thref{alg:filter1}; it
replaces a brute-force search through all permutations of columns with a guided
search for an appropriate permutation. It is also superior in that no more data
has to be computed, unlike \thref{alg:filter1} where new row spaces must be
produced for each column permutation. Additionally, information about the graphs
can be reused (in particular their automorphism group). However, this is not as
useful as it might seem, since the automorphism group of prime row spaces
appears to be almost always be trivial.

Using this method of filtration, a minimal generating sets for $\Bn$, $6 \leq 8$
have been computed; the size of such generating sets is contained in
Table~\ref{tab:BMatResults}. It seems unlikely that these methods can produce
minimal generating sets for $n > 8$. The generating sets obtained from this
algorithm are obtainable at TODO, along with code to produce them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reflexive Boolean Matrices}
\label{sec:RefBoolMat}
An interesting submonoid of $\Bn$ is the monoid $\Refn$ of reflexive boolean
matrices, i.e. boolean matrices with $1$s on the main diagonal. Minimal
generating sets for $\Refn$ are significantly larger than those of $\Bn$; this
is essentially caused by the following well-known facts.

\begin{lemma}
  \thlabel{lem:reflexivecontainment}
  For any $A, B \in \Refn$, we have $A \leq AB$ and $B \leq AB$, with
  respect to containment.
\end{lemma}
\begin{proof}
  Since $A, B$ both contain the identity matrix, the product $AB$ must
  contain both every row of $A$ and every column of $B$.
\end{proof}

\begin{lemma}
  \thlabel{lem:reflexivejtrivial}
  $\Refn$ is $\J$-trivial. 
\end{lemma}
\begin{proof}
  If $A \J B$, then $A \leq B$ and $B \leq A$ with respect to containment. Hence
  $A = B$.    
\end{proof}

In order to determine generating sets for $\Refn$, we require the following results:

\begin{lemma}
  \thlabel{lem:reflexivegenstrimorelem}
  If $A$ is a non-trim, non-elementary matrix, then $A$ is properly
  decomposable.
\end{lemma}
\begin{proof}
Let $A$ be a non-trim, non-elementary matrix. Then $A$ has some row $i$
contained in some other row $j$. Let $B$ be the matrix obtained by setting entry
$i$ of row $j$ to be $0$. Then $B < A$ with respect to  containment, and letting
$C$ be the greedy left multiplier of $(A, B)$, $A = CB$. Hence $B, C > A$ in the
$\J$-order. As $A$ is non-elementary, $B$ and $C$ are non-identity matrices;
hence $A$ is properly decomposable.
\end{proof}

\begin{lemma}
  \thlabel{lem:reflexiveelementaryindecomposable}
  Elementary matrices are properly indecomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Elementary matrices are precisely those matrices in $\Refn$ containing $n + 1$
  ones. Since non-identity matrices in $\Refn$ have at least $n + 1$ ones, by
  \thref{lem:reflexivecontainment} elementary matrices are not properly
  indecomposable.
\end{proof}

\begin{cor}
  \thlabel{cor:reflexiveindecomposable}
  Let $X$ denote the set of matrices in $\Refn$ that are not properly
  decomposable, $T \subset X$ denote the trim matrices in $X$, and $E$ denote
  the elementary matrices. Then $X \setminus T = E$. 
\end{cor}

%TODO: use the generating set lemma from section 2 here
\begin{lemma}
  The unique minimal (monoid) generating set for $\Refn$ is $T \cup E$.
\end{lemma}
\begin{proof}
  We first note that $T$ must be contained in any generating set for $\Refn$.
  Since the elements of $E$ are precisely those reflexive matrices containing
  $n + 1$ ones, \thref{lem:reflexivecontainment} implies that they are not
  properly decomposable and hence $E$ must be contained in any generating set.

  Now let $A \in \Refn$; we must show that $A \in \genset{T \cup E}$. If $A \in
  T \cup E$ then we are done, so suppose not. By
  \thref{lem:reflexivegenstrimorelem} and the definition of $T$, $A$ must be a
  properly decomposable matrix; say $A = BC$ for $B, C \in \Refn\setminus\{I,
  A\}$. By \thref{lem:reflexivejtrivial}, $B$ and $C$ are strictly above $A$ in
  the $\J$-order of $\Refn$. Now if $B$ or $C$ are not in $T \cup E$, we may
  again decompose to find elements still higher in the $\J$-order. Since $\Refn$
  has finite height, we must eventually not be able to properly decompose the
  elements we have found; by \thref{cor:reflexiveindecomposable} we have then
  found a decomposition of $A$ as a product of matrices in $T \cup E$.
\end{proof}

Given a matrix $A \in \Refn$, it is helpful to be able to determine whether $A$
is properly decomposable. The following lemmas suggest a method for doing so.

\begin{lemma}
  \thlabel{lem:greedymaximal}
  Given matrices $A, B \in \Bn$:
  \begin{enumerate}
    \item
      the greedy left multiplier $C$ of $(A, B)$ is maximal with respect to
      containment in the set $\set{X \in \Bn}{XA \leq B}$,
    \item 
      the product $CA$ is maximal with respect to containment amongst products
      $XA$ contained in $B$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  Let $D \in \set{X \in \Bn}{XA = B}$, and suppose that row $i$ of $D$ contains
  a $1$ in position $j$. Then row $j$ of $A$ is contained in row $i$ of $B$, and
  hence $C$ has a $1$ in position $j$ of row $i$. Therefore $D \leq X$. The
  second part follows directly from this.
\end{proof}

\begin{lemma}
  \thlabel{lem:decomposeintersection}
  A trim matrix $A \in \Refn$ can be decomposed as $A = BC$, $B, C \in
  \Refn\setminus\{I, A\}$, if and only if $A = B'C'$ where $C'$ is the matrix
  whose $i$th row $C_i$ is the intersection 
  \[ C_i = \cap_{K_i} A_i \]
  where $K_i$ is the positions of the $1$s in the $i$th column of $B$, $B'$ is
  the greedy left multiplier of $(C', A)$, and $B', C' \in \Refn
  \setminus\{A\}$.
\end{lemma}
\begin{proof}
  ($\Rightarrow$)
  Suppose that $A = BC$ for $B, C \in \Refn \setminus\{I, A\}$, and let $B', C',
  K_i$ be defined as above. Fix $i$, and consider the $i^{\text{th}}$ row $C_i'$
  of $C'$. By the definition of $K_i$, for each $j \in K_i$, we have $C_i \leq
  A_j$; hence $C_i \leq C'_i \leq A_j$. This implies that $A = BC'$, since $A =
  BC \leq BC' \leq A$. By \thref{lem:greedymaximal}, $A = B'C'$, and $B' \in
  \Refn$ since $B \leq B'$. Since $C_i \leq C'_i$ for all $i$, $C'$ is also in
  $\Refn$. It remains to show that neither $B', C' \not\in \{I, A\}$. Note
  that since $B \leq B'$ (\thref{lem:greedymaximal}) and $C \leq C'$, $B', C'$
  are not the identity matrix. Since $A$ is trim, if $B'$ or $C'$ were equal
  to $A$ the product $B'C'$ would have more ones than $A$ does.\\
  ($\Leftarrow$) Immediate.
\end{proof}
Hence, in order to determine whether a trim matrix $A$ is decomposable it
suffices to:
\begin{enumerate}
  \item generate all matrices $C$ with rows intersections of rows of $A$, and
    for each $C$
    %TODO: fix this
  \item check whether the product $BC$ with the greedy left multiplier is equal
    to $A$, and $B, C \not\in \{I, A\}$.
\end{enumerate}
If no such matrices $B, C$ are found, then $A$ is indecomposable. This method is
clearly superior to checking all products of matrices in $\Refn$, but still
quickly becomes infeasible to use for all trim matrices in $\Refn$.\\
%TODO: tables

In order to reduce the time spent checking matrices using
\thref{lem:decomposeintersection}, we would like to only check a smaller set of
canonical representatives. Unfortunately, the following two matrices illustrate
that two reflexive matrices can have the same canonical form under row and
column permutations in $\Bn$, while only one of them is decomposable in $\Refn$. 
\begin{ex}
  Let
\begin{align*}
  A = \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\text{, }&
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
Then $A, B \in \Ref{5}$, and $B$ may be obtained by exchanging columns $3$ and
$5$ of $A$. However, $A$ is indecomposable whilst
\begin{align*}
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 \\
    1 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1 
  \end{pmatrix}
  \begin{pmatrix}
    1 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
\end{ex} 

However, the following lemma shows that a more restricted form of
canonicalisation can be applied in $\Refn$:

\begin{lemma}
  \thlabel{lem:reflexivecanonical}
  Let $A, B \in \Refn$ be such that $A = P^{-1} B P$ for some permutation matrix
  $P \in S_n$ (i.e. $A$ is obtained by permuting the rows and columns of $B$ by
  the same permutation). Then $A$ is decomposable in $\Refn$ if and only if $B$
  is decomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Suppose that $B = XY$ for $X, Y \in \Refn\setminus \{I, A\}$. Then $P^{-1}XP,
  P^{-1}YP \in \Refn\setminus\{I, A\}$ and $P^{-1}XPP^{-1}YP = A$. The proof of
  the other direction is dual, since $PAP^{-1} = B$.
\end{proof}

This means that it is sufficient to enumerate the trim reflexive matrices in the
following standard form:
\begin{itemize}
  \item{all $1$s in the first row of $A$ are on the left,}
  \item{no row has fewer ones than the first row,}
  \item{if a $1$ appears in row $i$ in column $j$, then for each $k < j$ there
      is some row $l < i$ with a $1$ in position $k$.}
\end{itemize}

We then have the following algorithm for finding a minimal generating set for
$\Refn$:
\begin{enumerate}
  \item
    Enumerate the trim reflexive boolean matrices in standard form using a
    backtrack search, storing canonical representatives under a row and column
    permutation in a set $S$
  \item 
    Filter out the properly decomposable matrices in $S$ using
    \thref{lem:decomposeintersection}, leaving a set $T$ of trim matrices that
    are not properly decomposable
  \item
    The minimal generating set of $\Refn$ is then $T \cup E$.
\end{enumerate}
Using this algorithm, we can calculate the sizes of minimal generating sets up
to $n = 7$; these are contained in Table~\ref{tab:BMatResults}.

There are a small number of matrices in $\Ref{7}$ for which an approach based on
\thref{lem:decomposeintersection} is too inefficient; we chose to use a
different approach for $12$ matrices in total. Observe that a matrix $A$ is
decomposable into a product of generators $X_1 X_2 \ldots X_k$ from some minimal
generating set if and only if $\alpha A \alpha^{-1} = \alpha (X_1 X_2 \ldots
X_{k-1})\alpha^{-1}\alpha X_k \alpha^{-1}$ for all permutations $\alpha$. Since
the set $S$ of Algorithm TODO contains $\alpha X_k \alpha^{-1}$ for some $\alpha
\in S_n$, we can detect if $A$ is properly decomposable by testing whether
$\alpha A \alpha^{-1} = CB$ for any $\alpha \in S_n$, $B \in S$ and with $C$ the
greedy multiplier of $(\alpha A \alpha^{-1}, B)$. A brute force approach based
on this observation is sufficient to filter the $12$ difficult matrices for $n =
7$.

% The single matrix that is kept is:
%1000010
%0100101
%1010101
%1001101
%0110110
%0111010
%0111001

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hall Matrices}
\label{sec:HallBoolMat}
The submonoid of $\Bn$ consisting of those boolean matrices containing a
permutation matrix is particularly interesting. It is often called the
\emph{Hall monoid} since matrices containing a permutation matrix correspond to
instances of the Hall marriage problem that have a solution, and are thus
referred to as \emph{Hall matrices}. We will denote the Hall monoid by
$\Halln$. 

In order to prove our main result on the Hall monoid, we will need the following
classical result, restated in our context.

\begin{thm}[Hall's Marriage Theorem]
  Let $A \in \Bn$. Then $A$ is a Hall matrix if and only if every union of $k$
  rows contains at least $k$ ones, for $1 \leq k \leq n$.
\end{thm}
We shall say that a subset $X$ of the rows of a matrix \emph{satisfies the Hall
  condition} if the union of the rows in $X$ contains at least $|X|$ ones, and
that a matrix satifies the Hall condition if every subset of the rows satisfies
the Hall condition.

It will be useful in this section to define $e_i$ to be the boolean vector of
length $n$ with a single $1$ in position $i$.

The Hall monoid is similar in certain ways to $\Refn$. In particular
the $\J$-relation is easily described through the following lemmas.

\begin{lemma}
  \thlabel{lem:HallContainment}
  For any $A, B \in \Halln$, the product $AB$ contains at least as many ones as
  $A$ or $B$ does.
\end{lemma}
\begin{proof}
  Since $A \in \Halln$, $A$ contains a permutation matrix; hence $AB$ contains a
  row-permuted copy of $B$. Similarly, $AB$ contains a column-permuted copy of
  $A$.
\end{proof}

\begin{lemma}
  \thlabel{lem:HallJRelation}
  Two matrices $A, B \in \Halln$ are $\J$-related in $\Halln$ if and only if $A
  = PBQ$ for two permutation matrices $P, Q \in S_n$.
\end{lemma}
\begin{proof}
  The forward direction is clear. For the reverse, suppose that $A = SBT$ and $B
  = UAV$ for matrices $S, T, U, V \in \Halln$. Then $BT$ contains a
  column-permuted copy of $B$, and hence $A$ contains a row- and column-permuted
  copy of $B$. Since, similarly, $B$ contains a row- and column-permuted copy of
  $A$, it follows that $A$ is a row- and column-permutation of $B$.
\end{proof}

Unlike $\Refn$, $\Halln$ has minimal generating sets that are strongly related
to the minimal generating sets for $\Bn$.
\begin{lemma}
  Every minimal generating set for $\Halln$ is obtained by removing a rank $n-1$
  matrix from a minimal generating set for $\Bn$. That is, every minimal
  generating set for $\Halln$ consists of a set of representatives $P$ of the
  prime $J$-classes of $\Bn$ together with two generators for the group of units
  and an elementary matrix.
\end{lemma}

\begin{proof}
  The fact that $P \subset \Halln$ is a consequence of the discussion after
  \cite[Definition 2.4]{Caen1981aa}. Let $G \subset \Halln$ be obtained as in
  the statement. To establish that $G$ is a generating set, we will show that
  any Hall matrix $A$ that lies below the matrices in $G$ in the $\J$-order may
  be written as a product of two Hall matrices that are strictly higher in the
  $\J$-order than $A$, and therefore by \thref{lem:GenSetDecomposition}, $G$ is
  a generating set. Since we require a matrix from every prime $\J$-class, two
  generators for $S_n$, and an elementary matrix in any generating set for
  $\Bn$, and each of these lie in $\Halln$, we must require these matrices in
  any generating set for $\Halln$; hence $G$ is minimal. The same argument shows
  that every minimal generating set is obtained in this way.

  Note that $G$ consists of matrices from the maximal $\J$-class and all
  $\J$-classes immediately below the maximal $\J$-class. By
  \thref{lem:PermutingReducedMatrices}, every matrix in the $\J$-classes of
  matrices in $G$ is generated by $G$.

  Let $A$ be a Hall matrix that lies below $G$ in the $\J$-order. We may assume
  without loss of generality that $A$ contains the identity permutation, since
  $\langle G \rangle$ contains $S_n$. We will decompose $A$ as a product of
  non-permutation Hall matrices that lie above $A$ in the $\J$-order. 

  First, suppose that $A$ is not trim; then some $i$th row of $A$ is contained
  in a $j$th row. Let $B$ be the matrix obtained by setting entry $i$ of row $j$
  to be equal to $0$. Since $A$ contains the identity permutation, so does $B$;
  therefore $B$ is a Hall matrix. Now $A = E^{j,i}B$, and by
  \thref{lem:HallJRelation} neither $E^{j,i}$ nor $B$ is $\J$-related to $A$.

  We now suppose that $A$ is trim. Since $A$ lies below $G$ in the $\J$-order, it
  has non-maximal row space. Let $B$ be a maximal non-permutation matrix in
  $\Bn$ which contains the row space of $A$. Then $B$ is prime or elementary,
  and hence is similar to some matrix in $G$. Letting $C$ be the greedy
  multiplier of $(A, B)$, we have $A = CB$. Since $A$ is trim, we must also have
  that $C$ is trim. However, $C$ might not be a Hall matrix.
  
  Suppose that $C$ is a Hall matrix. Then, since $B$ is not similar to $A$, $C$
  is not a permutation matrix.  Since $B$ is not a permutation matrix, and $C$
  is trim, $C$ is not similar to $A$. By \thref{lem:HallJRelation}, $B$ and $C$
  are not $\J$-related to $A$ in the $\Halln$.

  Now suppose that $C$ is not a Hall matrix. Since $A$ is a Hall matrix, $C$
  must contain a $1$ in every row. However, it may be the case that $C$ does not
  contain a $1$ in every column. We will show how that case may be reduced to
  the case where $C$ does contain a $1$ in ever column. 

  Suppose that the columns of $C$ indexed by $\{c_1, c_2, \ldots, c_k\}$ do not
  contain a $1$, and that $B$ contains the permutation $\alpha$. For $1 \leq i
  \leq k$, define $B'_{c_i*}$ to have a single $1$ in position $\alpha(c_i)$;
  the remaining rows of $B'$ are the corresponding rows of $B$. Then $B'$
  contains $\alpha$. Let $C'$ be the greedy multiplier of $(A, B')$; then for
  all $1 \leq i \leq k$, $C'_{\alpha(c_i)c_i} = 1$ since
  $A_{\alpha(c_i)\alpha(c_i)} = 1$. Hence we have found $B', C' \in \Bn$ such
  that $A = C'B'$, $B' \in \Halln$, and every row and column of $C'$ contains a
  $1$. Of course, this is not sufficient to guarantee that $C'$ is a Hall
  matrix; we give a construction later in the proof that remedies this situation.
  In order to continue, we must finally prove that $B'$ and $C'$ are not
  $\J$-related to $A$ in $\Halln$. Note that $C'$ may not even be an element of
  $\Halln$. Suppose that $A\J B'$; then $B'$ is similar to $A$, and hence $B'$ is
  trim. Since $C$ contains a $1$ in every row, and $C'$ contains all $1$s of $C$
  together with at least one more, $C'$ is not the identity matrix.  Together
  with $B'$ being trim, this implies that $C'B'$ contains more $1$s than $B'$.
  But $C'B' = A$, and if $A\J B$ then $A$ and $B$ have the same number of $1$s.
  Hence $A$ is not $\J$-related to $B'$. Now suppose that $A\J C'$. Then $C'$ is
  similar to $A$, and thus trim. We would like to apply the same argument as we
  applied to $B'$, but in order to do so we must know that $B'$ is not a
  permutation matrix. Since $B$ was not a permutation matrix, and $B'$ was
  obtained by replacing some rows of $B$ by rows containing a single $1$, the
  only way that $B'$ may be a permutation matrix is if the non-replaced rows of
  $B$ - indexed by $\{1, 2, \ldots, n\}\setminus\{c_1, c_2, \ldots, c_k\}$ - all
  contained a single $1$.  But since $C$ contains $1$s only in those columns,
  the product $A = CB$ could then only contain $1$s in the columns  $\{1, 2,
    \ldots, n\}\setminus\{c_1, c_2, \ldots, c_k\}$ and thus would not be a Hall
  matrix. Hence, $B'$ is not a permutation matrix and a similar argument to that
  which showed that $A <_\J B'$ applies to $A$ and $C'$, to show that $A$ is not
  $\J$-related to $C'$ in $\Halln$.
  
  We may now assume that $A$ is a trim matrix containing the identity
  permutation, with $A = CB$ for two matrices $B, C \in \Bn$ where $B \in
  \Halln$, $C$ is a non-Hall matrix containing a $1$ in every column, and
  neither $B$ nor $C$ are $\J$-related to $A$ in $\Halln$.
  
  Since $C$ is not a Hall matrix, it does not satisfy the Hall condition and
  hence there is some maximal subset of rows, indexed by $W  = \{w_1, w_2,
    \ldots, w_k\} \subset \{1, \ldots, n\}$, that do not satisfy the Hall
  condition. Since $C$ contains a $1$ in every column, $k < n$. We will show
  how we can modify $C$ and $B$ so that the rows indexed by $W$ satisfy the
  Hall condition, resulting in a smaller maximal subset of rows not satisfying
  the Hall condition. We will define two new matrices $S, T \in \Bn$ from $B$
  and $C$.

  Let $X = \{x_1, \ldots, x_l\} \subset \{1, \ldots, n\}$ denote the indices of
  those columns of $C$ that do not contain any $1$s in the rows indexed by $W$.
  By multiplying $C$ by an appropriate permutation matrix on the right, and $B$
  by the inverse of this permutation matrix on the left, we may assume that $X^C
  \subset W$, and that $X \cap W = \{x_1, \ldots, x_{m - 1}\}$, where $m = k + l -
    n + 1$. That is, the $1$s that occur in rows $W$ occur in a subset of the
    columns $W$, and those columns indexed by $W$ in which a $1$ does not occur
    in rows $W$ are labelled by $\{x_1, \ldots, x_{m - 1}\}$.Consider the
    remaining $n - k$ column indices $\{x_m, \ldots, x_k\}$. The $(n-k) \times
    (n-k)$ submatrix of $C$ consisting of rows $W^C = \{1, \ldots, n\}\setminus
    W$ of $C$ and columns $\{x_m, \ldots, x_k\}$
    must be a Hall matrix, for otherwise it would contain some set of rows
    violating the Hall condition, and the union of these rows with those indexed
    by $W$ would be a larger subset of rows of $C$ not satisfying the Hall
    condition, contradicting the maximality of $W$. Hence, this submatrix
    contains a permutation matrix, which defines a bijection $f: W^C \to \{x_m,
      \ldots, x_k\}$ such that for all $i \in W^C$, $f(i)$ is the column
    containing a $1$ in row $i$. For all $i \in W^C$, we define row $i$ of $S$
    to be $e_{f(i)}$, and row $f(i)$ of $T$ to be $A_{i*}$. Then $(ST)_{i*} =
    A_{i*}$. Note that since row $C_{i,f(i)} = 1$, row $f(i)$ of $B$ is
    contained in row $i$ of $A$ and hence also contained in row $i$ of $T$.

  For all $j \in X^C = \{1, \ldots, n\}\setminus X$, we define row $j$ of $T$ to
  be $B_{j*}$; then for all $i \in W$, $(CT)_{i*} = A_{i*}$. It remains to
  define rows $W$ of $S$ and rows $\{x_1, \ldots, x_{m - 1}\}$ of $T$. Since
  $B$ is a Hall matrix, it contains a permutation matrix $U$. The rows $X^C
  \cup \{x_m, \ldots, x_k\}$ of $T$ contain the corresponding rows of $U$. For
  all $j \in \{x_1 \ldots, x_k\}$, consider the cycle in the permutation $u$,
  corresponding to the permutation matrix $U$, starting at $j$. If $u(j) \in W$,
  then define $T_{j*} = e_{u(j)}$. Otherwise, $u(j) \not\in W$, and we may
  construct the tuple $(u^1(j), u^2(j), \ldots, u^{q}(j), iu^{q+1}(j))$ where
  $u^{i}(j) \not\in W^C$ for $1 \leq i \leq q$, and $u^{q + 1}(j) \in W$. Then
  we define $T_{j*} = e_{u^{q + 1}(j)}$. By the assumptions on $X$, for $1 \leq
  i \leq q$ we have $u^{i}(j) \in \{x_m, \ldots, x_l\}$, and by the definitions
  of rows $\{x_m, \ldots, x_l\}$ of $T$, we have that $T_{u^{i}(q),u^{i}(q)} =
  1$. For each such tuple, we modify $U$ by defining $U_{j*} = e_{u^{q +
      1}(j)}$, and $U_{u^{i}(q)*} = e_{u^{q + 1}(j)}$ for $1 \leq i \leq q$.
  Note that this modification is well-defined since $u$ is a permutation and
  thus decomposes into disjoint cycles. After this modification, $T$ is fully
  defined and contains the permutation matrix $U$.

  For each $j \in \{x_1, \ldots, x_{m - 1}\}$, we have $T_{j*} = e_w$ for some $w
  \in W$, and hence there is a $1$ in position $(w, j)$ of the greedy
  multiplier of $(A, T)$. Define the rows $W$ of $S$ to be the corresponding
  rows of the greedy multiplier of $(A, T)$. Then the union $z$ of the rows $W$
  of $S$ contains $1s$ in columns $\{x_1, \ldots, x_{m - 1}$. Note that since
  the rows of $T$ indexed by $X^C$, the set of columns that had a $1$ in some
  row of $W$, are equal to the corresponding rows of $B$, we have $S_{w*} \leq
  C_{w*}$ for all $w \in W$. Hence $y$ contains $(n - l) + m = k$ ones, and so
  the rows $W$ satisfy the Hall condition.

  It is straightforward to verify that $A = ST$. We wish to now show that $S$
  contains a $1$ in every column, and that $A$ is not $\J$-related to $S$ or to
  $T$. That $S$ contains a $1$ in every column follows from the union $y$ of the
  rows $W$ containing ones each of the columns indexed by $W$, and the other
  rows being defined via the bijection $f$. That $T$ is not $\J$-related to $A$
  follows from the same argument as above; since $A$ is trim so would be $B$,
  but $S$ contains at least one row with more than one $1$, a contradiction. In
  order to prove that $S$ is not $\J$-related to $A$, we must as above prove
  that $T$ is not a permutation matrix. Similarly to the argument above, we note
  that if $T$ is a permutation matrix then each row of $T$ indexed by $X^C$
  contains a single one, but these are equal to the corresponding rows of $B$.
  Then the union of rows $W$ of $CB$ would contain precisely $n - l < k$ ones,
  and hence $A$ would not be Hall. Hence $T$ is not a permutation matrix, and
  the argument proceeds as above. 

  It is still not the case that $S$ must be a Hall matrix. However, we have
  reduced the effective size of the maximal subset of rows which violates the
  Hall condition. Observe that rows $W^C$ of $S$ contain a single and distinct
  $1$ each, and these $1$s occur precisely in the columns in which no $1$ occurs
  in rows $W$ of $S$. Hence, a set of rows $V \subset W$ violates the Hall
  condition if and only if $V \cup Y$ violates the Hall condition for any subset
  $Y \subset W^C$. By iteratively repeating the construction of $S$ and $T$,
  while choosing the next subset of rows which violates the Hall condition as
  the maximal violating subset of the current set each time, we must eventually
  be unable to choose such a subset. At this point, $S$ satisfies the Hall
  condition and hence $S \in \Halln$; we also have that $A = ST$, $T \in
  \Halln$, and neither $S$ nor $T$ are $\J$-related to $A$. The theorem now
  follows from \thref{lem:GenSetDecomposition}.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Transformation Hall Matrices}
\label{sec:TransBoolMat}
The previous section may be viewed in the context of ``matrices which are forced
to contain a certain permutation''. We now relax this requirement to consider
the monoid $\MTn$ of matrices which contain a transformation, i.e. have a $1$ in
every row.

\begin{lemma}
  All minimal generating sets for $\MTn$ are obtained by replacing the rank $n -
  1$ matrix in a minimal generating set for $\Bn$ by a matrix similar to
  \begin{align*}
    F' = \begin{pmatrix}
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 0 & 1 & 0 & \cdots & 0 \\
      0 & 0 & 0 & 1 & \cdots & 0 \\
        &   &   \dots & \dots & \\
      0 & 0 & 0 & 0 & \cdots & 1
    \end{pmatrix}
  \end{align*}
\end{lemma}
\begin{proof}
  Since all prime matrices have full rank, such a set $G$ is contained in
  $\MTn$. To see that it is a generating set, consider a matrix $A$ which is not
  $\J$-related to any matrix in $G$. We wish to write $A$ as a product of
  matrices which lie strictly above $A$ in the $\J$-order. 
  
  Suppose that $A$ is not row-trim, and row $i$ is contained in row $j$. Then
  subtracting row $i$ from row $j$, we obtain a new matrix $A'$. If row $j$ is
  now empty, we then insert any row that is not in the row space of $A$ as row
  $j$. Now $A$ is the product $F''A'$ of $A'$ with some matrix similar to $F'$. By
  replacing $A$ with $A'$, and repeating if necessary, we may assume that $A$ is
  row-trim; a dual procedure allows us to assume that $A$ is column-trim. 
  
  Let $A_0 = A$. Then we write $A_0 = B_0C_0$ where $B_0, C_0 \in \Bn$, $B_0$ has a
  maximal row-space amongst non-permutation matrices, and $C_0$ is the greedy left
  multiplier. Since $B_0$ is Hall, it lies in $\MTn$; it is also $\J$-related to
  some matrix in $G$ and hence lies above $A_0$. Since $A_0$ is trim, $C_0$ must also
  be trim, and similarly since $A_0$ contains no zero row neither does $C_0$.
  However, $B_0$ is not a permutation matrix, and therefore $A_0 = C_0B_0$ contains more
  $1$s than $C_0$ does. Now either $C_0$ also lies strictly above $A_0$, in which case
  we are done, or we can repeat the process with $A_1 = C_0$. Since we
  cannot continue producing matrices with fewer and fewer ones forever,
  eventually we must decompose one of the $A_i$s as desired; then the product $A
  = C_i B_i B_{i - 1} \ldots B_1$ consists of matrices strictly above $A$ in the
  $\J$-order, which all lie in $\MTn$. Hence by \thref{lem:GenSetDecomposition},
  $G$ generates $\MTn$.
  Now, since every generating set for $\Bn$ must contain a representative of
  each prime $\J$-class and an elementary matrix, so too must every generating
  set for $\MTn$. Now $F'$ is not Hall, while all prime and elementary matrices
  are Hall, so $F'$ is not generated by prime and elementary matrices. Hence,
  any such generating set $G$ is minimal.
  %TODO: clean up this last paragraph.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Triangular Boolean Matrices}
\label{sec:TriBoolMat}
We now turn our attention to the monoids of upper and lower triangular boolean
matrices, denoted by $\UTn$ and $\LTn$ respectively. These matrices have a
particularly simple minimal generating set:

\begin{lemma}
  \thlabel{lem:mingeneratingsetfortriangular}
  The unique minimal (monoid) generating set $X$ for $\UTn$ [$\LTn$] consists of
  those elementary matrices and matrices similar to $F$ which are upper [lower]
  triangular.
\end{lemma}

\begin{proof}
  We will prove the lemma for upper triangular matrices; the proof for lower
  triangular matrices is dual.
  We will first construct any matrix $A \in \UTn$ as a product of matrices in
  $X$. We iteratively define a product $A_i$, $0 \leq i \leq n$ where $A_0$ is
  the identity and $n$ is the number of $1$s in $A$. For the $i$-th $1$
  contained in $A$ (ordered by row then column) with position $(x_i, y_i)$, we
  obtain $A_i$ from $A_{i - 1}$ by left-multiplying by $E_{x_i, y_i}$. Let the
  zero rows of $A$ have indices $\{z_1, \ldots, z_{k}\}$. Note that the matrices
  in $\UTn$ similar to $F$ are precisely those matrices obtained by deleting a
  single $1$ from an identity matrix. We define $A_{n + j}$ to be matrix
  obtained by left multiplying $A_{n + j - 1}$ by the element of $X$ with a zero
  row in position $z_j$. Then $A_{n + k} = A$. (TODO: prove this construction
  actually works).
  
  
  Now it is easy to show that for each matrix $A \in X$, if $A$ is written as a
  product $A = BC$ in $\UTn$ then one of $B$ or $C$ must be equal to $A$; hence
  any generating set for $\UTn$ must contain all matrices in $X$. Hence $X$ is
  the unique minimal generating set for $\UTn$.
\end{proof}

\begin{cor}
  \thlabel{cor:RankTriBoolMat}
  For $n > 1$, the ranks of $\UTn$ and $\LTn$ are the $n$-th triangular number
  $T_n = \frac{n(n+1)}{2}$.
\end{cor}

\section{Tropical matrices}
%TODO: we would like to include the following results since they seem like a
%natural fit, these are the things which need to be proved and we don't quite
%know what the proofs are:

Another class of semiring which has attracted significant recent attention (see
~\cite{TODO}) is the tropical min-plus semirings which are interesting because
TODO. The monoids of matrices over these semirings have significantly more
complex behaviour than the boolean matrix monoid (see \cite{TODO}).

\subsection{Min-plus matrices}

\begin{thm}[J, J, J]\label{thm-min-plus}
  The monoid $M_{2}(K^{\infty})$ of $2 \times 2$ min-plus matrices is
  generated by the matrices:
  \begin{equation*}
          A_{i} = \mat{i}{0}{0}{\infty},
    \quad B     = \mat{1}{\infty}{\infty}{0},
    \quad \text{and}
    \quad C     =  \mat{\infty}{\infty}{\infty}{0}
  \end{equation*}
  where $i \in \N \cup \{\infty\}$.
\end{thm}

\begin{cor}[J, J, J]\label{cor-finite-min-plus}
  Let $t \in \N$ be arbitrary. Then the finite monoid $M_{2}(K^{\infty}_t)$ of
  $2 \times 2$ min-plus matrices is generated by the $t + 4$ matrices:
  \begin{equation*}
          A_{i} = \mat{i}{0}{0}{\infty},
    \quad B     = \mat{1}{\infty}{\infty}{0},
    \quad \text{and}
    \quad C     =  \mat{\infty}{\infty}{\infty}{0}
  \end{equation*}
  where $i \in \{0, 1, \ldots, t, \infty\}$.
\end{cor}

\subsection{Max-plus matrices}
???? Seems like a natural thing to include.

\section{Matrices over $\mathbb{Z}_n$}

\begin{thm}[Wilf]
  The monoid $M_{k}(\mathbb{Z}_{n})$ is generated by $GL_{k}(\mathbb{Z}_{n})$ and
  any one element from each of the $\D$-classes immediately below the group of
  units. In particular, you could choose
  the diagonal matrices
  $$\begin{pmatrix}
    n/p    & 0      & \cdots & 0  \\
    0      & 1      &        & \vdots \\
    \vdots &        & \ddots & 0 \\
    0      & \cdots & 0      & 1  \\
   \end{pmatrix},$$
   for each prime divisor $p$ of $n$.
\end{thm}
Note that by the same logic as everywhere else this must be minimal.

\printbibliography
\end{document} 
