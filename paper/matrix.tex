\documentclass[11pt]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb, latexsym, mathrsfs, pifont,
tabu, enumitem}
\usepackage[cm]{fullpage}
\usepackage{theoremref}
\usepackage[ruled, linesnumbered]{algorithm2e}
\usepackage{makecell}

\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem*{defi}{Definition}
\newtheorem{exa}[thm]{Example}
\newtheorem{algo}[thm]{Algorithm}
\newenvironment{de}[1][]{\begin{defi}[#1]\rm}{\end{defi}}
\newenvironment{ex}{\begin{exa}\rm}{\end{exa}}
\newenvironment{alg}{\begin{algo}\rm}{\end{algo}}
\newcommand{\proofref}[1]{\noindent {\emph{Proof of Theorem}~\ref{#1}.\ }}
\newcommand{\defn}[1]{\textbf{\textit{#1}}}
\numberwithin{equation}{section}

% Lists
%\def\labelenumi{\theenumi}
%\def\theenumi{(\roman{enumi})}

% Macros
\newcommand{\id}{\mbox{\rm id}}
\newcommand{\set}[2]{\ensuremath{\{#1 : #2 \}}}
\newcommand{\genset}[1]{\ensuremath{\langle\: #1 \:\rangle}}
\renewcommand{\to}{\longrightarrow}

\DeclareMathOperator{\im}{im}

% For Algorithms
\SetKwProg{Fn}{Function}{}{}
\SetKwFunction{FZeroIfNotSubset}{ZeroIfNotSubset}
\SetKwFunction{FRemoveDuplicateRows}{RemoveDuplicateRows}
\SetKwComment{Comment}{}{}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\DontPrintSemicolon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\B}{\mathbb{B}}
\newcommand{\Bn}{M_n(\B)}
\newcommand{\Bm}[1]{M_{#1}(\B)}
\newcommand{\Bmn}{M_{m,n}(\B)}
\newcommand{\Refn}{M_n^{\text{id}}(\B)}
\newcommand{\Ref}[1]{M_{#1}^{\text{id}}(\B)}
\newcommand{\Halln}{M_n^{\text{S}}(\B)}
\newcommand{\Hall}[1]{M_{#1}^{\text{S}}(\B)}
\newcommand{\MTn}{M_n^{\text{T}}(\B)}
\newcommand{\MT}[1]{M_{#1}^{\text{T}}(\B)}
\newcommand{\UTn}{UT_n(\B)}
\newcommand{\LTn}{LT_n(\B)}
\renewcommand{\L}{\mathscr{L}}
\newcommand{\R}{\mathscr{R}}
\newcommand{\D}{\mathscr{D}}
\newcommand{\J}{\mathscr{J}}
\renewcommand{\H}{\mathscr{H}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\rank}{\operatorname{rank}}

\newcommand{\K}{\mathbb{K}}

\newcommand{\BGSet}{\mathcal{B}_{n,n}}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newcommand{\mat}[4]{\begin{pmatrix}#1&#2\\#3&#4\end{pmatrix}}

\usepackage[backend=biber, bibencoding=utf8]{biblatex}
\bibliography{matrix}

\title{Minimal generating sets for matrix monoids}
\author{F. Hivert, J. D. Mitchell, F. L. Smith, and W. A. Wilson}
\date{\today}
\begin{document}

\maketitle

\begin{abstract}
  TODO
\end{abstract}

\section{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%The \defn{boolean semiring} $\B$ is the set $\{0, 1\}$ with addition defined by 
%\begin{align*}
%  0 + 1 = 1 + 0 &= 1 + 1 = 1 \\
%  0 + 0 &= 0
%\end{align*}
%and multiplication defined as usual for the real numbers $0$ and $1$.  The
%addition and multiplication of elements of $\B$ naturally extends to row and
%column vectors of equal length with entries in $\B$.  The main object of study
%in this document is the collection $\Bn$ of $n\times n$ matrices with entries in
%$\B$. Under the usual multiplication of matrices, using addition and
%multiplication in $\B$, the set $\Bn$ forms a monoid; call the \defn{full
%  boolean matrix monoid}. The monoid $\Bn$ is classical in the literature of
%semigroup theory being among the first monoids to be studied; see, for example,
%\cite{Zaretskii1963aa}. The monoids $\Bn$, $n\in \N$, have been extensively
%studied in the literature, by many authors, and a great deal is known about its
%structure and properties. For example, if $G$ is a finite group, then there
%exists an $n\in \N$ such that $G$ occurs as a maximal subgroup of $\Bn$; the
%probability that a random product of matrices in $\Bn$ equals the universal
%matrix:
%\begin{equation*} 
%  \begin{pmatrix}
%  1 & 1 & \cdots & 1\\
%  1 & 1 & \cdots & 1\\ 
%  \vdots & \vdots & \ddots & \vdots\\
%  1 & 1 & \cdots & 1\\ 
%\end{pmatrix} 
%\end{equation*} 
%tends to $1$ as $n\to \infty$; the minimal size of a generating set for $\Bn$
%grows exponentially with $n$ (see~\thref{cor:ExponentialGenSets});
%Devadze~\cite{Devadze1968aa} and Konieczny~\cite{Konieczny2011aa} characterise
%minimum cardinality generating sets for $\Bn$; TODO: more.
%
%Despite its venerable status, many aspects of the monoids $\Bn$ are still
%shrouded in mystery. The purpose of this article is to cast some light on the
%problems of determining the minimum cardinality $\mathbf{d}(\Bn)$ of a
%generating set for $\Bn$ and certain submonoids of $\Bn$ such as the reflexive
%boolean matrix monoid $\Refn$, and other submonoids where the matrices contain
%particular matrices.
%% The time and space complexity of determining any of these value is exponential
%% in $n$. 
%It seems unlikely that an explicit formula for any of these numbers exists.
%In this paper we describe algorithms for computing the numbers listed,
%and the output of our implementation~\cite{} of these algorithms. The latter
%are summarised in Figures~\ref{figure-table-1} and \ref{fig:reflexiverank}.
%

%TODO: make tables horizontal?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
\label{section-preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Green's relations}
On any semigroup $S$, there are some key equivalence relations. These are known
as Green's relations, and are defined in terms of principal ideals as follows.
Let $S$ be any semigroup and let $s, t \in S$. Then
\begin{align*}
  s \L t &\text{ if and only if } S^1 s = S^1 t \\
  s \R t &\text{ if and only if } s S^1 = t S^1 \\
  s \J t &\text{ if and only if } S^1 s S^1 = S^1 t S^1.
\end{align*}
Finally, we define Green's $\H$-relation as the intersection of $\L$ and $\R$.
We write $X_s$ for the Green's $\mathcal{X}$-class of $s$, where
$\mathcal{X} \in \{\L, \R, \J, \H\}$.
There is a natural partial order on certain Green's classes
\begin{align*}
  R_s \leq R_t &\text{ if and only if } sS^1 \subseteq tS^1 \\
  L_s \leq L_t &\text{ if and only if } S^1s \subseteq S^1t \\
  J_s \leq J_t &\text{ if and only if } S^1 s S^1 \subseteq S^1 t S^1.
\end{align*}
Further background on Green's relations can be found in~\cite{Howie1995aa}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Semirings}
The theory of matrices over fields is familiar and well-studied, but we are
concerned with matrices over more general objects, semirings. For our purposes,
a semiring is a set $\mathbb{S}$ with two operations, $\oplus$ and $\otimes$,
such that $(\mathbb{S}, \oplus)$ forms a commutative monoid with identity $e$,
$(\mathbb{S}, \otimes)$ forms a monoid, $e\otimes x = x\otimes e = e$ for all $x
\in \mathbb{S}$, and multiplication distributes over addition. We call the
additive identity the \defn{zero} of the semiring and the multipicative identity
the \defn{one}. Throughout, semirings will be denoted by blackboard bold
symbols. We are particularly interested in several special types of semiring.

The \defn{boolean semiring} $\B$ is the set $\{0, 1\}$ with addition defined by 
\begin{align*}
  0 \oplus 1 = 1 \oplus 0 &= 1 \oplus 1 = 1 \\
  0 \oplus 0 &= 0
\end{align*}
and multiplication defined as usual for the real numbers $0$ and $1$. This
semiring, and the matrices over it, have been studied since at least Zaretskii's
foundational paper~\cite{Zaretskii1963aa} in 1963. \\

The \defn{min-plus semiring} $\K^{\infty}$ is the set $\N \cup \{\infty\}$, with
$\oplus = \min$ and $\otimes$ extending the usual addition on $\N$ so that
$x\otimes\infty = \infty\otimes x = \infty$ for all $x \in \K^{\infty}$. For our
purposes, $0 \in \N$, and so the one of $\K^{\infty}$ is $0$ and the zero is
$\infty$. \\ 
%The min-plus semiring was first introduced by
%Simon~\cite{Simon1978aa} in the context of automata theory; see also
%Pin~\cite{Pinab}. 
The \defn{max-plus semiring} $\K^{-\infty}$ is the set $\N \cup \{-\infty\}$ with
$\oplus = \max$ and $\otimes$ extending the usual addition on $\N$ so that
$x\otimes-\infty = -\infty\otimes x = -\infty$ for all $x \in \K^{-\infty}$. The
one of $\K^{-\infty}$ is $0$ and the zero is $-\infty$.

We are also interested in certain finite quotients of these semirings. The
\defn{min-plus semiring with threshold $t$}, denoted $\K^{\infty}_t$, is the set
$\{0, 1, \ldots, t, \infty\}$ with operations $\oplus = \min$ and $\otimes$
defined by
\begin{align*}
  a \otimes b = \begin{cases}
    \min(t, a + b) \quad &\text{$a \neq \infty$ and $b \neq \infty$} \\
    \infty \quad &\text{$a = \infty$ or $b = \infty$}.
  \end{cases}
\end{align*}

The \defn{max-plus semiring with threshold $t$}, denoted $\K^{-\infty}_t$, is
constructed analogously; its elements are $\{-\infty, 0, 1, \ldots, t\}$,
addition is $\max$, and multiplication is defined by $a \otimes b = \min(t, a +
b)$ for all $a, b \in \K^{-\infty}_t$.

% TODO: check this
These finite semirings with threshold $t$ may also be defined as the quotient of
the corresponding infinite semirings by the congruence generated by $(t, t +
1)$.

The min-plus and max-plus semirings are known as \defn{tropical} semirings.
Tropical semirings have attracted significant attention recently due to ???
TODO, see TODO.

The final semirings that we are concerned with are the \defn{modular integers}
$\Z_n$; given $n \in \N$, $\Z_n$ consists of the set $\{0, 1, \ldots, n - 1\}$
where $\oplus$ is addition modulo $n$, and $\otimes$ is multiplication modulo
$n$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Matrix semigroups}
\label{sec:matsemigp}
% TODO: mathbb all of this and make it S, not R
Given a semiring $\mathbb{S}$ and $m, n \in \N$, we may study the set of $m
\times n$ matrices over $\mathbb{S}$; we will denote this by $M_{m,
  n}(\mathbb{S})$. In particular, we are interested in the multiplicative monoid
of square matrices of dimension $n \in
\N$ over $\mathbb{S}$, denoted by $M_n(\mathbb{S})$.
There are a number of common features of such matrix monoids. As usual, we let
$0$ denote the additive identity of $\mathbb{S}$ and $1$ denote the
multiplicative identity.

% TODO: definition of linear independence
Let $A \in M_n(\mathbb{S})$. We write $A_{i*}$ to denote the $i$th row of $A$,
and $A_{*i}$ to denote the $i$th column. A \defn{linear combination} of rows is
a sum of scalar multiples of the rows, where both operations are defined
componentwise in the usual way. The \defn{row space}
$R(A)$ of $A$ is the set of all linear combinations of the rows of $A$. 
A set of rows is \defn{linearly independent} if some row can be written as a
linear combination of other rows; this coincides with the usual definition when
$\mathbb{S}$ is a field. \defn{Spanning sets} are defined exactly as for
matrices over fields: a spanning set for a row space is a set of rows which
every element of the row space may be written as a linear combination of. A
\defn{row basis} of $A$ is then a linearly independent spanning set for the row
space of $A$. \defn{Column spaces} and \defn{column bases} are defined dually.
The importance of row and column bases arises from the following well-known
results~\cite{TODO}:

%TODO: fix enum 
\begin{prop}
  \thlabel{prop:rowsandideals}
  Let $A, B \in M_n(\mathbb{S})$. Then the following hold:
  \begin{enumerate}[label=\roman*]

    \item
      If $R(A) \subseteq R(B)$, then $A \in M_n(\mathbb{S}) B$.  Similarly, if $C(A)
      \subseteq C(B)$, then $A \in B M_n(\mathbb{S})$.

    \item 
      $R(AB) \subseteq R(B)$ and $C(AB) \subseteq C(B)$.
  \end{enumerate}
\end{prop}
\begin{proof}
  \noindent \textbf{(i).}
  If $R(A) \subseteq R(B)$, then every row of $A$ can be expressed as a linear
  combination of rows of $B$. For $1 \leq i \leq n$ of $A$, let $A_{i*} =
  \sum_{j = 1}^{n}x_{ij}B_{j*}$, and define $X = [x_{ij}]$. Then $A = XB \in
  M_n(\mathbb{S})B$. The other case is dual.
  \bigskip

  \noindent \textbf{(ii).}
  Suppose that $A = [\alpha_{ij}]$ and $B = [\beta_{ij}]$. If 
  $AB = [\gamma_{ij}]$, then 
  \[
  \gamma_{ij} = \alpha_{i1} \beta_{1j} + \alpha_{i2}\beta_{2j} 
                + \cdots + \alpha_{in}\beta_{nj}
              = \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kj}.
  \]
  It follows that the $i$th row of $AB$ is 
  \[
  (\gamma_{i1}, \gamma_{i2}, \ldots, \gamma_{in})
   =  \left (\sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k1},
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k2},
     \ldots, 
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kn}\right) \\
   % & = & (\alpha_{i1}\beta_{11} + \alpha_{i2}\beta{21} + \cdots +
   %  \alpha_{in}\beta{n1},
   %  \alpha_{i1}\beta_{12} + \alpha_{i2}\beta{22} + \cdots +
   %  \alpha_{in}\beta{n2},
   %  \ldots,
   %  \alpha_{i1}\beta_{1n} + \alpha_{i2}\beta{2n} + \cdots +
   %  \alpha_{in}\beta{nn}) \\
   % & = & 
   % (\alpha_{i1}\beta_{11}, \alpha_{i1}\beta_{12}, 
   % \ldots, \alpha_{i1}\beta_{1n})
   % + 
   % (\alpha_{i2}\beta_{21}, \alpha_{i2}\beta_{22}, 
   % \ldots, \alpha_{i2}\beta_{2n})
   % + \cdots +
   % (\alpha_{in}\beta_{n1}, \alpha_{in}\beta_{n2}, 
   % \ldots, \alpha_{in}\beta_{nn}) \\
    =
    \sum_{k = 1} ^ {n} 
    \alpha_{ik}B_{k*}.
  \]
  Thus the $i$th row of $AB$ is a sum of rows of $B$, and so $R(AB) \subseteq
  R(B)$. 
\end{proof}

\begin{prop} 
  \thlabel{lem:GreensRowColumnSpaces}
  Let $A, B \in M_n(\mathbb{S})$. Then the following are equivalent:
  \begin{enumerate}[label=\roman*]
    \item 
      $A \L B$;

    \item 
      $R(A) = R(B)$;
  \end{enumerate}
  An analogous statement holds for Green's $\R$-relation using column spaces. 
\end{prop}
\begin{proof}
  \textbf{(i) $\Rightarrow$ (ii).} 
  If $A \L B$, then there are $X, Y \in M_n(\mathbb{S})$ such that $XA = B$ and
  $YB = A$. Then $R(B) = R(XA) \subseteq R(A)$ and $R(A) = R(YB) \subseteq R(B)$
  by Proposition~\ref{prop:rowsandideals}(ii).
  \bigskip

  \textbf{(ii) $\Rightarrow$ (i).} Follows immediately by
  Proposition~\ref{prop:rowsandideals}(i). 
\end{proof}

The \defn{group of units} of $M_n(\mathbb{S})$ is the group of invertible
matrices (\defn{units}) in $M_n(\mathbb{S})$; the identity matrix is always a
unit. The group of units is always the maximal class in the $\J$-order of
$M_n(\mathbb{S})$.

For any semiring $\mathbb{S}$, the symmetric group embeds into the group of units of
$M_n(\mathbb{S})$ by the map 
\begin{align*}
  \phi:\: &\alpha \to [a_{ij}], \\
  &a_{ij} =
    \begin{cases}
      1 \quad & i\alpha = j \\ 
      0 \quad &\text{otherwise}.
    \end{cases}
\end{align*}
The image of this embedding will often simply be referred to as $S_n$ or the
symmetric group when context prevents ambiguity. Elements of this embedding
$S_n$ are called \defn{permutation matrices}; multiplying by a permutation
matrix on the left permutes rows of a matrix, and multiplying on the right
permutes columns.

Two matrices $A, B\in M_n(\mathbb{S})$ are \defn{similar} if each can be
obtained from the other by permuting the rows and/or columns. Note that similar
matrices are $\J$-related in $M_n(\mathbb{S})$, by multiplying on the left
and/or right by permutation matrices.

\begin{de}[\textbf{Prime matrices.}]
  A non-unit matrix $A \in M_n(\mathbb{S})$ is \defn{prime} if $A = BC$ implies $B$ or
  $C$ is a unit.
\end{de}

The prime matrices of $M_n(\mathbb{S})$ are immediately below the group of units
in the $\J$-order. 
%TODO: justify? 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Minimal generating sets}

Given a semigroup $S$, we may ask what the minimum cardinality is of a
generating set for $S$. This is known as the \defn{rank} of $S$ and is denoted
by $\mathbf{d}(S)$. A generating set $X$ for $S$ is \defn{irredundant} if no
subset of $X$ generates $S$, and we say that any irredundant generating set of
cardinality $\mathbf{d}(S)$ is a \defn{minimal generating set}. If
$\mathbf{D}(S) \in \N$, then every generating set of cardinality $\mathbf{d}(S)$
is irredundant and hence minimal; this does not hold when $\mathbf{d}(S)$ is not
finite.

%TODO: fix this
\begin{de}[\textbf{Decomposable elements}]
  An element $x$ of a monoid $M$ with identity $e$ is \defn{decomposable} if
  there exist $y, z \in M$ with $x = yz$, and \defn{properly decomposable} if
  there exist $y, z \in M\setminus\{e, x\}$ such that $x = yz$.
\end{de}

\begin{lemma}
  \thlabel{lem:GenSetDecomposition}
  Let $S$ be a finite semigroup and let $X \subseteq$ be a set of elements which
  generate all elements of the maximal $\J$-classes of $S$. Suppose that for all
  $s$ not in the maximal $\J$-classes of $S$, $s$ can be written as a product of
  elements which lie strictly above $s$ in the $\J$-order. Then $X$ generates
  $S$. 
\end{lemma}
\begin{proof}
  Let $x \in S$. Then either $x$ is in a maximal $\J$-class, in which case we
  are done, or $x$ may be written as a product of elements which lie strictly
  above $x$ in the $\J$-order. This argument may be repeated for each of those
  elements. Since $S$ is finite, we must eventually reach a decomposition of $x$
  into elements in maximal $\J$-classes, and hence $x \in \genset{x}$.
\end{proof}

\begin{prop}[Wilf, elsewhere]
  \thlabel{prop-wilf}
  Let $S$ be a finite semigroup.  Suppose that $X$ is an irredundant generating
  subset of $S$ that contains at most one element from each $\D$-class of $S$.
  Then $X$ has minimal cardinality, i.e. $\rank(S) = |X|$.
\end{prop}
\begin{proof}
  Wilf claims to have proven this.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Boolean Matrix Monoids}
\label{sec:boolmat}
% TODO
% In this section, we compute...
% Signpost rest of section
% Results up front

In this section, we compute minimal generating sets for the full boolean matrix
monoid $\Bn$, the monoid $\Refn$ of reflexive boolean matrices, the monoid
$\MTn$ of boolean matrices containing a transformation, and the monoids $\UTn$
and $\LTn$ of upper- and lower-triangular boolean matrices. The ranks of these
monoids, for $n$ from $1$ to the largest known value, are found in
Figure~\ref{fig:BMatResults}.


\begin{figure}
  \centering
  \begin{tabular}{l|r|r|r|r|r}
    $n$ & $\mathbf{d}(\Bn)$ & $\mathbf{d}(\Refn)$ & $\mathbf{d}(\MTn)$ &
    $\mathbf{d}(\UTn)$ & $\mathbf{d}(\LTn)$ \\ 
    \hline
    1 & 2*          & 1*&  & & \\
    2 & 3*          & 2*& & & \\
    3 & 5*          & 8*& & & \\
    4 & 7*          & 38*& & & \\
    5 & 13*         & 1\ 415& & & \\
    6 & 68         & 482\ 430& & & \\
    7 & 2\ 143     & 1\ 034\ 972\ 230& & & \\
    8 & 495\ 115   & ?& & &
  \end{tabular}
  \vspace{1cm}

  \caption{The ranks of certain matrix monoids over $\B$; an ``*'' denotes that
    the rank was already known or is computable by hand, and a ``?'' indicates
    that the value is unknown}
  \label{fig:BMatResults}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preliminaries}
The semiring $\B$ is one of the simplest examples of a semiring, and the matrix
monoid $\Bn$ is more well-studied than most other matrix semirings;
see~\cite{TODO}. In particular, there is a description of a minimal generating
set for $\Bn$, due to Devadze in 1968~\cite{Devadze??} and proven correct by
Konieczny in 2011~\cite{Konieczny2011aa}. However, these generating sets are difficult to
compute and so explicit generating sets, even for $n = 6$, were unknown. It was
known that the size of a minimal generating set for $\Bn$ grows very quickly
with $n$; see~\thref{cor:ExponentialGenSets}.\\

In contrast, the subsemigroup of $\Bn$ generated by all the regular elements can
be generated by the four matrices \cite{Roush1977aa}

\begin{align*}
  T = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    1 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  U = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    0 & 0 & 0 & 0 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    1 & 0 & 0 & 0 & \cdots & 0 
  \end{pmatrix},&\\
  E = \begin{pmatrix}
    1 & 0 & 0 & 0 & \cdots & 0 \\
    1 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  F = \begin{pmatrix}
    0 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1
  \end{pmatrix}.
\end{align*}
We will continue to use these names for these matrices throughout
Section~\ref{sec:boolmat}. Note that together $T$ and $U$ generate $S_n$.

We call any matrix similar to $E$ an \defn{elementary} matrix, and call the
$\J$-class $J_E$ the \defn{elementary $\J$-class}. The elementary matrix which
consists of the identity matrix with an additional $1$ in position $j$ of the
$i$th row will be denoted by $E^{i,j}$.

\begin{thm}[Devadze's Theorem \cite{Konieczny2011aa}]
  \thlabel{thm:DevadzeKon}
  The set $\{T, U, E, F\} \cup P$ is a generating set for $\Bn$ of minimum
  cardinality, where $P$ is any set containing one matrix from every $\J$-class
  of $\Bn$ which contains a prime matrix. 
\end{thm}

As well as the description of a minimal generating set for $\Bn$, there are
certain additional concepts attached to $\Bn$ which do not apply to matrices
over arbitrary semirings. Many of these arise from the observation that we may
view a vector $v \in \B^n$ as the characteristic function of a subset $s(v)$ of
$\{1, \ldots, n\}$, where $i \in s(v)$ if and only if $v_i = 1$.  Then we define
the \emph{union} of two vectors $v, w$ to be $s^{-1}(s(v) \cup s(w))$. Note that
union and sum correspond for $\B^n$. In fact, since there is a single non-zero
element of $\B$, unions, sums, and linear combinations all coincide. Given $v, w
\in \B^n$, we also say that $v$ is \defn{contained} in $w$, and write that $v <
w$, if $s(v) \subseteq s(w)$.

It is straightforward to verify that if $A \in \Bn$, then there is a unique row
basis $r(A)$, which is the unique minimal generating set for $R(A)$ under union,
consisting of the non-zero $\leq$-minimal rows. The dual statement for column
spaces also holds. This yields a strengthening of
\thref{lem:GreensRowColumnSpaces}.

\begin{prop} 
  \thlabel{lem:BMatGreensRowColumnBases}
  Let $A, B \in \Bn$. Then $A \L B$ in $\Bn$ if and only if $r(A) = r(B)$,
  and $A \R B$ in $\Bn$ if and only if $c(A) = c(B)$.
\end{prop}
Since the row and column bases of matrices in $\Bn$ can be computed in time and
space polynomial in $n$, the previous proposition gives an efficient method for
determining whether two matrices are $\L$- or $\R$-related in $\Bn$. This, in
combination with \thref{lem:GreensRowColumnSpaces}, allows the $\L$- and
$\R$-structure to be computed. However, the number of $\L$- and $\R$- classes
grows extremely rapidly with $n$ so that it quickly becomes infeasible to
compute the $\L$- and $\R$-structure of $\Bn$.

%TODO: table here of the number of L/R classes?

It is significantly more difficult to determine the $\J$-relation in $\Bn$ than
the $\L$- or $\R$-relation. Indeed, the problem of determining whether two
matrices are $\J$-related in $\Bn$ is NP-hard~\cite[Theorem 2.7]{Fenner2018aa}.
The $\J$-relation is characterised by \defn{row space embeddings}; a function
$f: R(A) \to R(B)$ is a row space embedding if it respects containment and
non-containment, i.e.\ $f(v) \leq f(w)$ if and only if $v \leq w$.
\begin{thm}[Zaretskii's Theorem~\cite{Zaretskii1963aa}]
  \thlabel{thm:Zaretskii}
  Let $A, B \in \Bn$. Then $A \leq_{\J} B$ if and only if there exists a row
  space embedding $f: R(A) \to R(B)$.
\end{thm}
Zaretskii's theorem gives a reduction of determining the $\J$-order to finding
digraph homomorphisms, but it should be noted that the number of elements of the
row spaces grows exponentially with $n$. Computing the $\J$-structure of $\Bn$
is challenging; see \cite{Breen1997aa}. Indeed, it is not even known what
cardinalities of row spaces can occur in general in
$\Bn$~\cite{rowspacecardinalities}. 

Considering rows as subsets of $\{1, \ldots, n\}$, it is natural to consider
when rows of a matrix $A \in \Bn$ are contained in other rows of $A$. We will
call $A$ \defn{row-trim} if no non-zero row of $A$ is contained in another row.
\defn{Column-trim} is defined dually. We say that $A$ is \defn{trim} if it is
both row-trim and column-trim.

Our interest in trim matrices is due to the following result.

\begin{lemma}[{\cite[Lemma 3.1]{Konieczny2011aa}}]
  \thlabel{lem:PrimeMatricesAreTrim}
  Every prime matrix in $\Bn$ is trim.
\end{lemma}
\begin{proof}
  Let $A \in \Bn$ be prime. Suppose some non-zero row indexed $k$ of $A$ is
  contained in a row indexed $l$ of $A$. Define $X \in \Bn$ to be the matrix
  such that $X_{ij} = 1$ precisely if $A_j \leq A_i$. Then $XA = A$, and since
  $|X_l| \geq 2$, $X \not\in S_n$, a contradiction. A dual argument shows that
  no non-zero column of $A$ is contained in another column.
\end{proof}

It is difficult to enumerate prime matrices directly, but comparatively simple
to enumerate trim matrices. This will be key to our strategy for computing a
minimal generating set for $\Bn$.

The matrix $X$ defined in the proof of \thref{lem:PrimeMatricesAreTrim} will be
a useful concept throughout. Given two matrices $A, B \in \Bn$, we say that the
\defn{greedy left multiplier} of $A$ w.r.t. $B$ is the matrix $C$ containing a
$1$ in position $j$ of row $i$ if and only if $A_{j*} \leq B_{i*}$. The
\defn{greedy right multiplier} of $A$ w.r.t. $B$ is the matrix $D$ containing a
$1$ in position $j$ of row $i$ if and only if $A_{*i} \leq B_{*j}$.

Given an expression of the form $CA = B$, we will often simply say that
\emph{$C$ is the greedy multiplier} if $C$ is the greedy left multiplier of $A$
w.r.t $B$; similarly we often say that $A$ is the greedy multiplier if $A$ is
the greedy multiplier of $C$ with respect to $B$.

A similar property to being trim is being \defn{reduced}. A matrix $A \in \Bmn$
is \defn{row-reduced} if no row of $A$ can be written as a union of other rows
of $A$. \defn{Column-reduced} is defined dually. We say that $A$ is
\defn{reduced} if it is both row-reduced and column-reduced. Since no row of a
trim matrix is contained in another row, it follows that no row can be expressed
as a union of other rows. A dual argument applies to columns, and hence we have
the following lemma.

\begin{lemma}
  \thlabel{lem:TrimMatricesAreReduced}
  Every trim matrix is reduced.
\end{lemma}

Reduced matrices are particularly convenient to compute with, due to the
following lemma. 
\begin{lemma}[\cite{Plemmons1970aa}]
  \thlabel{lem:PermutingReducedMatrices}
  Let $A, B \in \Bn$ be reduced. Then $A \J B$ if and only $A$ and $B$ are
  similar.
\end{lemma}

This result allows us to find single representatives of the $\J$-classes of
reduced matrices by computing a canonical image under row and column
permutations. It also implies that the $\J$-class of any prime matrix $P$
consists of prime matrices similar to $P$, and we refer to such a $\J$-class as
a \defn{prime $\J$-class}. Note that a prime $\J$-class therefore contains at
most $(n!)^2$ elements.

\begin{cor}
  \thlabel{cor:ExponentialGenSets}
  The size $\mathbf{d}(\Bn)$ of a minimal generating set for $\Bn$ grows
  exponentially with $n$.
\end{cor}
\begin{proof}
  This follows from the fact that there at least $2^{\frac{n^2}{4} - O(n)}$
  prime boolean matrices in $\Bn$ (see~\cite[Theorem 2.4.1]{Kim1982aa}) and each
  prime $\J$ class contains at most $(n!)^2$ elements; hence there are
  exponentially many prime $\J$-classes.
\end{proof}
%TODO: add lower bounds here

%TODO: prove that primes appear as J classes of arbitrary above?
The prime matrices of $M_n(R)$ sit directly below the group of units in
$\J$-order on $M_n(R)$ for any semiring $\mathbb{S}$. In the case of $\Bn$,
there is another extra $\J$-class immediately below $S_n$: $J_E$. Note that $J_F
\leq J_E$. The next result shows that in fact these are all of the $\J$-classes
immediately below $S_n$.

Let $\beta_n$ denote the set $\set{R(A)}{A\in \Bn\setminus S_n}$ of all
possible proper row subspaces of elements of $\Bn$, and let $\B^n$ denote
the space of all boolean vectors of length $n$. Note that $\B^n$ is the
row/column space of precisely the permutation matrices.

\begin{thm}[cf. Theorem 5.1 in~\cite{Caen1981ab}]
  \thlabel{thm:MaximalRowSpaces}
  Let $A \in \Bn\setminus S_n$. Then $R(A)$ is maximal with respect to
  containment in $\beta_n$ if and only if $A$ is prime or elementary.  
\end{thm}


We may now prove a slightly stronger form of Devadze's Theorem.
\begin{thm}[Devadze's Theorem \cite{Konieczny2011aa}]
  \thlabel{thm:Devadzefull}
  Any minimal generating set for $\Bn$ is given by $\{T', U', E', F'\} \cup P$,
  where $T'$ and $U'$ generate $S_n$, $E'$ is elementary, $F'$ is a matrix
  similar to $F$, and $P$ is a set of representatives of the prime $\J$-classes
  of $\Bn$. Conversely, any such set generates $\Bn$.
\end{thm}
\begin{proof}
  The converse follows immediately from \thref{thm:DevadzeKon}, noting that $A
  \in \genset{\{A', T', U'\}}$ for any similar matrices $A, A' \in \Bn$.

  Let $X$ be a minimal generating set for $\Bn$. Since $\mathbf{d}(S_n) = 2$,
  and $X$ must contain generators of the group of units $S_n$, it follows that
  $X$ contains two elements which together generate $S_n$, which we denote by
  $T'$ and $U'$. By \cite[Lemma 4.2]{Konieczny2011aa}, $X$ also contains a set
  $P$ of representatives of the prime $\J$-classes of $\Bn$. By \cite[Lemma
  4.5]{Konieczny2011aa}, and the fact that the elementary $\J$-class lies
  immediately below the group of units, $X$ must also contain an elementary
  matrix, say $E'$. It only remains to show that $X$ must contain a matrix
  similar to $F$. Since none of the elements of $P$, nor $E'$, contain a
  zero row, $P \cup \{E'\}$ does not generate $F$, and $X$ must contain a matrix
  with at least one zero row. Since matrices similar to $F$ have the maximal row
  spaces amongst matrices containing zero rows, $X$ must contain a matrix
  similar to $F$.
\end{proof}


\subsection{The Full Boolean Matrix Monoid}

% TODO: as mentioned above...
By Devadze's Theorem, in order to compute minimal generating sets for $\Bn$ it
is sufficient to compute sets of representatives of the prime $\J$-classes of
$\Bn$. We call a function $\phi: \Bn \to \Bn$ a \defn{canonical form} if
$\ker\phi = \J$; that is, the equivalence classes of elements in $\Bn$ with the
same image under $\phi$ are the same as the equivalence classes of the
$\J$-relation on $\Bn$. Given a canonical form $\phi$, the image $\im\phi$ is a
set of representatives of the $\J$-classes of $\Bn$, and the image
$P_\phi = \phi(\set{A \in \Bn}{\text{$A$ prime}})$ is a set of
representatives of the prime $\J$-classes of $\Bn$. 

We wish to enumerate $P_\phi$ for some canonical form $\phi$. Our strategy will
be to enumerate a set $P_\phi \subseteq Q_\phi \subseteq \im\phi$, and then
filter $Q_\phi$ to remove the non-prime matrices.  The most obvious set
$Q_\phi$ to enumerate is $\im\phi$. However, it is infeasible to compute the
image of each of the $2^{n^2}$ elements of $\Bn$ for $n \geq 7$. We instead work
with a certain set of matrices of a particular form. 

\begin{de}[{{\cite[Proposition 3.6]{Breen1997aa}}}]
  \thlabel{de:StandardForm}
  We say that a matrix $A \in \Bmn$ is in \emph{standard form} if it has all of
  the following properties:
  \begin{itemize}
  \item{$A$ is reduced,}
  \item{all non-zero rows of $A$ are at the bottom,}
  \item{all non-zero columns of $A$ are at the right,}
  \item{the non-zero rows of $A$ as binary numbers are a strictly increasing
      sequence, as are the columns}
  \item{all ones in the first non-zero row of $A$ are on the right,}
  \item{all ones in the first non-zero column of $A$ are at the bottom,}
  \item{every non-zero row has at least as many ones as the first non-zero row.}
  \end{itemize}
\end{de}
Note that this definition is not the same as given in \cite{Breen1997aa}; Breen
defines a matrix in $\Bn$ to be in standard form if the matrix has minimal value
as a binary number in its $\J$-class, and proves that such a matrix has the
properties of \thref{de:StandardForm}~\cite[Prop 3.6]{Breen1997aa}. This leads
directly to the following proposition:

\begin{prop}
  \thlabel{prop:StandardFormsExist}
  In every $\J$-class $\Bn$, there exists a matrix in standard form. 
\end{prop}

In contrast, being in standard form is not enough to guarantee that a matrix is
minimal. Consequently there is not a unique matrix in each $\J$-class of $\Bn$
in standard form, as the following example demonstrates. 
\begin{ex}
Let
\begin{align*}
  A = \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\text{,}&
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
Then $A$ and $B$ are in the standard form of
\thref{de:StandardForm}. Swapping rows $1$ and $2$ and columns $3$
and $4$ shows that $A$ and $B$ are similar, and hence are $\J$-related in $\Bn$.
\end{ex}

%TODO: numbers of standard form matrices
There are significantly fewer than $2^{n^2}$ matrices in standard form in $\Bn$,
as shown in Figure~\ref{fig:StandardFormMatrices}, and so it is feasible to
enumerate the matrices in standard form for several values of $n$ for which it
is not feasible to enumerate the matrices in $\Bn$.
Given the set $S$ of matrices in standard form in $\Bn$, and a canonical form
$\phi$, the image $Q_\phi = \phi(S)$ contains $P_\phi$. We will discuss several
methods of filtering $Q_\phi$ to obtain the prime matrices desired later in this
section. We first describe how to obtain canonical forms $\Phi_n$ using a
reduction to bipartite graphs, and sets $Q_{\Phi_n}$ using a backtrack search.

\begin{figure}
  \centering
  \begin{tabular}{r|r|r|r|r|r|r|r|r}
    $n$ & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
    \hline
    $|S|$ & & & & & & & & 
  \end{tabular}
\vspace{1cm}

  \caption{The size of the set $S$ in standard form in $\Bn$}
  \label{fig:StandardFormMatrices}
\end{figure}

Given a matrix $A \in \Bn$, we may form the vertex-coloured bipartite graph
$\Gamma(A)$ with vertices $\{1, \ldots, 2n\}$, colours 
%TODO: give this a better name
\[\mathbf{col}(v) = \begin{cases}
    0 \qquad &1 \leq v \leq n, \\
    1 \qquad &n < v \leq 2n,
  \end{cases}
\]
and an edge from $i$ to $j+n$ if and only if $A_{ij} = 1$. Then $\{1, \ldots,
  n\}$ represent indices of rows and $\{n + 1, \ldots, 2n\}$ represent indices
of columns in the matrix $A$.

It is easy to see that $\Gamma$ is a bijection from $\Bn$ to the set $\BGSet$ of
bipartite graphs with two parts of size $n$, where one part is coloured $0$ and
the other coloured $1$. We call a function $\psi: \BGSet \to \BGSet$ a
\emph{canonical form} for $\BGSet$ if the equivalence classes of $\ker\psi$ are
the graph-theoretical colour-preserving isomorphism classes of $\BGSet$.
Computing canonical forms for graphs is a well-studied problem; for a recent
article see~\cite{TODO:BrendanMackay} and the references within. 
% TODO: refer to bliss and the article which introduces it
and we use the software bliss\footnote{In fact, a slightly-modified version of
  bliss which avoids repeated memory allocation was used; this is available at
  \cite{TODO}}~\cite{TODO:BLISS}to obtain such functions $\psi_n$. 
\begin{lemma}
  The function $\Phi_n = \Gamma^{-1}\psi_n\Gamma$ is a canonical form when
  restricted to reduced matrices. 
\end{lemma}
\begin{proof}
  We must show that $\ker\Phi_n = \J$, in other words $\Phi_n(A) = \Phi_n(B)$ if and
  only if $A\J B$. This is equivalent to showing $\Gamma(A)$ is isomorphic to
  $\Gamma(B)$ if and only if $A \J B$. Denote the vertices of $\Gamma(A)$ by
  $\{1, \ldots, 2 n\}$ and the vertices of $\Gamma(B)$ by $\{1', \ldots, 2n'\}$,
  as above.
  Suppose that there is a colour-preserving isomomorphism $\Psi: \Gamma(A) \to
  \Gamma(B)$. Since $\Psi$ preserves colours, $\Psi$ maps $\{1, \ldots, n\} \to
  \{1', \ldots, n'\}$ and $\{n + 1, \ldots, 2n\} \to \{(n + 1)', \ldots, 2n'\}$.
  Define permutations $\alpha, \beta$ on $\{1,\ldots, n\}$ by 
  \begin{align*}
    \alpha(i) &= j \text{ if } \Psi(i) = j',\\
    \beta(i)  &= j \text{ if } \Psi(n + i) = (n + j)'.
  \end{align*}
  Then by permuting the rows and columns of $A$ by $\alpha$ and $\beta$
  respectively, $A$ is similar to $B$ and hence $A \J B$ in $\Bn$.

  Conversely, suppose that $A \J B$ in $\Bn$. Then by
  \thref{lem:PermutingReducedMatrices}, there exist $\alpha$ and $\beta$ such
  that by permuting the rows and columns of $A$ by $\alpha$ and $\beta$
  respectively $B$ is obtained. The map $\Psi$ defined by
  \[\Psi(i) = \begin{cases}
      j' \quad &\text{if } 1 \leq i \leq n \text{ and }\alpha(i) = j, \\
      (n + j)' \quad &\text{if } n < i \leq 2n \text{ and }\beta(i) = j
    \end{cases}
  \]
  is a colour-preserving isomorphism between $\Gamma(A)$ and $\Gamma(B)$.
\end{proof}

Given $v \in \B^n$, it will convenient to denote the number represented by $v$
in binary as $\bar{v}$. We will also write $n^\dagger$ to denote the boolean
vector $v \in \Bn$ such that $\bar{v} = n$.

We now describe how to backtrack through matrices in standard form to find a
superset of prime matrices $Q_{\Phi_n}$. This may be seen as a depth-first
traversal of a (non-rooted) tree, with nodes $m\times n$ matrices ($m \leq
n$) and leaves $n \times n$ matrices.
\begin{alg}
  \thlabel{alg:canonicalbacktrack}
  \ \\
  \textbf{Input}: A natural number $n$. \\
  \textbf{Output}: A set $Q_{\Phi_n}$, with $P_{\Phi_n} \subseteq Q_{\Phi_n}
  \subseteq \im\Phi_n$.
  \begin{enumerate}
    \item We assume that we are at a node $A$ of dimension $m \times n$, and the
      index of the first non-zero row of $A$ is $f \leq m$. 
    \item If $m = n$, the non-zero columns of $A$ form strictly increasing
      sequence, and $A$ is column-reduced, then add $\Phi_n(A)$ to $X$, the set
      of matrices to return.
    \item If $m < n$, then for each $x \in \{\bar{A_{m*}} + 1,
        \ldots, 2^n - 1\}$, if:
      \begin{enumerate}[label=\roman*]
        \item $x^\dagger$ does not contain $A_{l*}$ for any $1 \leq l \leq m$,
          and
        \item $x^\dagger$ has at least as many ones as $A_{f*}$,
        \item for all column indices $1 \leq i < j \leq m$ such that $A_{*i} =
          A_{*j}$, if $x^\dagger_i = 1$ then $x^\dagger_j = 1$.
      \end{enumerate}
      set the current node to be the matrix obtained from $A$ by adjoining
      $x^\dagger$ as the last row, and return to step 1.
    \item after every $x$ has been processed, return to the previous node (if
      any) and carry out step $3$ for the next $x$ of the previous node (if any).
  \end{enumerate}
  Having initialised step $1$ with each $m \times n$ matrix ($m \geq 1$)
  consisting of $m - 1$ zero rows followed by a row containing some non-zero
  number of $1$s on the right, return $X$.
\end{alg}

\begin{lemma}
  \thlabel{lem:backtrackworks}
  The output of \thref{alg:canonicalbacktrack}, with input $n$, is a subset of
  $\im\Phi_n$ containing $P_{\Phi_n}$. Moreover, \thref{alg:canonicalbacktrack}
  does not compute $\Phi_n(A)$ of any matrix $A$ not in standard form.
\end{lemma} 
\begin{proof}
  We will prove that the $A$s of step $4$ for which $\Phi_n(A)$ are calculated
  are precisely the set of trim matrices in standard form; since every prime
  matrix is trim (\thref{lem:PrimeMatricesAreTrim}) and every $\J$-class
  contains a matrix in standard form, this implies that the output contains
  $P_{\Phi_n}$. We will first prove that each such $A$ is in standard form.

  %TODO: a better name
  Define a matrix to be in \emph{quasi-standard form} if it satisfies each
  property of \thref{de:StandardForm} other than being column reduced and the
  non-zero columns forming a strictly-increasing sequence.
  We will prove that each node $A$ visited in the algorithm is trim and in
  quasi-standard form. Note that the matrices that the algorithm is initialised
  with are all trim and in quasi-standard form, so we must simply prove that
  passing from a node $A$ which is trim and in quasi-standard form to a node
  $A'$ by adding a row $x^{\dagger}$ in step $3$ preserves these properties.

  Trimness is preserved due to condition (i) of step $3$. Since all trim
  matrices are reduced, $A'$ is also reduced. The conditions on non-zero rows
  being at the bottom and forming a strictly increasing sequence of binary
  numbers are satisfied by choosing $x$ from the range $\{\bar{A_{m*}} + 1,
    \ldots, 2^n - 1\}$.  The conditions on non-zero columns being on the right
  follows from requirement (iii) of step $3$; note that this requirement also
  forces the columns to appear in (not-necessarily-strictly) increasing order.
  The first non-zero column contains the most significant digit of the rows as
  binary numbers, and since the rows of $A'$ are increasing the set of rows with
  that digit equal to $1$ must be contiguous and at the end of $A'$. Hence all
  of the ones in the first non-zero column of $A'$ are at the bottom.

  Since each leaf $A$ visited is trim and in quasi-standard form, the two
  conditions of step 2, that the non-zero columns form a strictly increasing
  sequence and that $A$ is column-reduced, guarantee that $A$ is in standard
  form. Hence, we only calculate the canonical form $\Phi_n(A)$ if $A$ is trim
  and in standard form.

  It remains to prove that every trim matrix $A \in \Bn$ in standard form is
  visited as a node in the enumeration. First, note that the first $m$ rows of
  any trim, standard-form matrix $A \in \Bn$ form an $m \times n$ trim matrix in
  quasi-standard form. Also, the zero-rows of $A$ together with the first
  non-zero row form one of the matrices with which step $1$ is initialised. It
  simply remains to show that from each $m \times n$ node $X$ consisting of the
  first $m$ rows of $A$, we visit the $(m + 1)\times n$ node $X'$ consisting of
  the first $m + 1$ rows of $A$. It is easy to verify that each of the three
  conditions in step $3$ is satisfied by row $m + 1$ of $A$, and hence $X'$ is
  visited.
\end{proof}

Given $\Phi_n$ and $Q_{\Phi_n}$, we wish to detect when an element of $Q_{\Phi_n}$ is
prime. We present two algorithms for doing so, in \thref{alg:filter1} and
\thref{alg:filter2}.

\begin{alg}
  \thlabel{alg:filter1}
  \ \\
  \textbf{Input}: A set $Q_{\Phi_n}$, containing the images $P_{\Phi_n}$ of the
  prime matrices of $\Bn$ under $\Phi_n$, and not containing any permutation
  matrices.
  \textbf{Output}: The set $P_{\Phi_n}$.
  \begin{enumerate}
  \item 
    Compute $X = \set{R(A\alpha)}{A \in Q \cup \{E\}, \alpha \in S_n}$
  \item
    For every $A \in Q_{\Phi_n}$, and for every $R(B\beta) \in X$, if $A \neq B$ and
    $R(A) \subsetneq R(B\beta)$ then discard $R(A\alpha)$ from $X$ for all
    $\alpha \in S_n$.
  \item
    Output $T\subset Q_{\Phi_n}$, the set of non-elementary elements $A$ such that $R(A)$
    remains in $X$ after the previous step.
  \end{enumerate}
\end{alg}

\begin{lemma}
  The output of \thref{alg:filter1} is a canonical set of prime matrices.
\end{lemma}
\begin{proof}
  Since the $\J$-class of a prime matrix consists only of similar matrices, the
  set $\set{R(A\alpha)}{A \in P_{\Phi_n}} \subset X$ contains all row spaces of
  prime matrices in $\Bn$, and hence so does $X$. Similarly, $X$ contains the
  row space of every elementary matrix. Hence, the elements that are maximal in
  $X$ are precisely the maximal elements of $\beta_n$ and thus by
  \thref{thm:MaximalRowSpaces} correspond to primes and elementary matrices.
  Since $R(A)$ remains in $X$ after step 2 precisely when $R(A)$ (and
  $R(A\alpha)$, for all $\alpha \in S_n$) is maximal in $X$, the output is
  $P_{\Phi_n}$.
\end{proof} 

Note that step 2 of \thref{alg:filter1} requires $O(|Q_{\Phi_n}||X|)$ comparisons.  The
size of $X$ grows extremely rapidly with $n$ as shown in
Figure~\ref{fig:filter1numbers}, and so this algorithm is only suitable for small $n$.
\begin{figure}
  \centering
  \begin{tabular}{l|r|r}
    $n$ & $|Q_{\Phi_n}|$ & $|X|$ \\
    \hline
    3 & 6 & 91 \\ 
    4 & 11 & 588 \\
    5 & 33 & 8194 \\
    6 & 395 & 570\ 636 \\ 
    7 & 34\ 015 & 342\ 915\ 296 \\
    8 & 17\ 120\ 845 & ? 
  \end{tabular}
\vspace{1cm}

\caption{The number of row spaces generated during \thref{alg:filter1} when
  given input $Q_{\Phi_n}$, the output of \thref{alg:canonicalbacktrack}}. 
  \label{fig:filter1numbers}
\end{figure}

Using \thref{alg:canonicalbacktrack} and \thref{alg:filter1}, minimal
generating sets for $n \leq 7$ may be obtained.

For $n=8$ this algorithm is no longer sufficient, and it is necessary to use
heuristics to reduce the size of $Q$. The simplest way to do this is to select a
small subset $X \subset Q$ of matrices with large row spaces, generate the row
spaces $Y = \{R(A\alpha) :\: A \in X\} \subset R$, and check whether $R(B)$ is
contained in any element of $Y$ for each element $B \in Q$.  It is also
worthwhile to filter $R$ by checking containment in the row spaces of all the
column permutations of a known set of prime matrices, such as those described in
the following lemma.

\begin{lemma}
  \thlabel{lem:ExtendingPrimeMatrices}
  Let $A$ be a prime matrix in $M_{n-1}(\B)$. Extend $A$ to a matrix $B \in \Bn$
  by adding a row of zeros at the bottom and a column of zeros on the right,
  then setting $B_{n,n} = 1$. Then $B$ is prime in $\Bn$.
\end{lemma}
\begin{proof}
  We will show that $R(B)$ is maximal in $\beta_n$, by showing that if 
  $R(C) \in \beta_n$ contains $R(B)$, then $r(B) = r(C)$.
  Let $C$ be such a matrix.
  The last row of $B$ must also be in $C$ since it is a minimal in $\B^{n}$. 
  Now $R(A)$ has a unique basis of $n-1$ rows which must be contained in both $B$ and
  $C$, so we have $r(B) = r(C)$.
\end{proof}

For $n=8$ prefiltering by some of the large row spaces and extended prime
matrices is enough to obtain a minimal generating set, though the computation is
lengthy; see Figure~\cite{fig:runtimestats} for some details. A significant
improvement can be obtained by using Zaretskii's Theorem.

\begin{figure}
  \centering
  \begin{tabular}{l|r|r|r|r|r|r}
    $n$ & \thref{alg:canonicalbacktrack} & \thref{alg:filter1} &
    \thref{alg:filter2} & prefiltering & \thead{\thref{alg:filter1} with \\
      prefiltering}  & \thead{\thref{alg:filter2} with \\ prefiltering} \\
    \hline
    1 & ? & ? & ? & ? & ? \\
    2 & ? & ? & ? & ? & ? \\
    3 & ? & ? & ? & ? & ? \\
    4 & ? & ? & ? & ? & ? \\
    5 & ? & ? & ? & ? & ? \\
    6 & ? & ? & ? & ? & ? \\
    7 & ? & ? & ? & ? & ? \\
    8 & ? & ? & ? & ? & ?
  \end{tabular}
\vspace{1cm}

% include prefiltering stats (choose x% of the largest row spaces?)
\caption{Runtime of different filtering approaches; executed on TODO}
  \label{fig:runtimestats}
\end{figure}


Let $A \in \Bn$. The \defn{graph} of $R(A)$ is the directed graph with vertices
$R(A)$ and an edge from $v$ to $w$ if $v \leq w$. The graph of $C(A)$ is defined
analogously.

It is an immediate corollary of Zaretskii's Theorem that $A \leq_{\J} B$ if and
only if there exists a homomorphic embedding of the graph of $R(A)$ into the
graph of $R(B)$ which respect non-edges. An efficient search for such embeddings
is implemented in~\cite{Digraphs2020aa}.

For practical computational purposes, it is useful to add extra structure to the
row space graphs to guide searches for embeddings. The \emph{augmented graph of
  $R(A)$} is the disjoint union of the graph of $R(A)$ with the empty graph on
the vertices $C = \{c_i \: : \: 1 \leq i \leq n\}$, with an edge from $v \in R(A)$
to $c_i$ if $v_i = 1$.

\begin{lemma}
  \thlabel{lem:EmbeddingGraphs}
  Let $Q$ be a superset of a canonical set of prime matrices $P$ which does not
  contain a permutation matrix, and let $A \in
  Q$. Then $A$ is not prime or elementary if and only if for some $B \in
  (Q\cup\{E\})\setminus\{A\}$ there exists a digraph embedding
  $\phi$ from the augmented graph of $R(A)$ into the augmented graph of $R(B)$
  which permutes $\{ c_i : 1 \leq i \leq n \}$ and respects non-adjacency.
\end{lemma}
\begin{proof}
  Let $A$ not be prime or elementary; then $R(A)$ is contained in the row space
  of some column permutation $\alpha$ of a $B \in Q \setminus \{A\}$.
  Then the embedding that extends the map $c_i \to c_{\alpha^{-1}i}$ has the
  properties required. Conversely, if such a map $\phi$ exists, the permutation
  $\alpha$ induced by the restriction to $C$ has the property that
  $R(B\alpha^{-1})$ contains $R(A)$, and hence by \thref{thm:MaximalRowSpaces}
  $A$ is not prime or elementary. 
\end{proof}

Note that such an embedding $\phi$ must also map a vector containing $i$ ones to
another containing $i$ ones to preserve adjacency and non-adjacency with the set
$C$.

We can therefore use the following improved algorithm to filter canonical
supersets of prime matrices.

\begin{alg}
  \thlabel{alg:filter2}
  \ \\
  \textbf{Input}: A canonical superset $Q$ of prime matrices $P$, which does not
  contain a permutation matrix.\\
  \textbf{Output}: The set $P$.
  \begin{enumerate}
  \item
    Generate the set $G$ of augmented graphs of row spaces of matrices in $Q$.
  \item 
    For every $K, L \in G$, if there exists an embedding of $K$ into $L$ as in
    \thref{lem:EmbeddingGraphs}, then discard $K$ from $G$.
  \item
    Output $X\subset Q$, the set of non-elementary elements $A$ with
    corresponding graphs remaining in $G$ after the previous step.
\end{enumerate}
\end{alg}

Note that this is in effect the same computation as in \thref{alg:filter1}; it
replaces a brute-force search through all permutations of columns with a guided
search for an appropriate permutation. It is also superior in that no more data
has to be computed, unlike \thref{alg:filter1} where new row spaces must be
produced for each column permutation. Additionally, information about the graphs
can be reused (in particular their automorphism group). However, this is not as
useful as it might seem, since the automorphism group of prime row spaces
appears to be almost always be trivial.

Using this method of filtration, minimal generating sets for $\Bm{8}$ have been
computed; the size of such generating sets is contained in
Figure~\ref{figure-table-1}. It seems unlikely that these methods can produce
minimal generating sets for $n > 8$. The generating sets obtained from this
algorithm are obtainable at TODO, along with code to produce them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reflexive Boolean Matrices}
An interesting submonoid of $\Bn$ is the monoid $\Refn$ of reflexive boolean
matrices, i.e. boolean matrices with $1$s on the main diagonal. Minimal
generating sets for $\Refn$ are significantly larger than those of $\Bn$; this
is essentially caused by the following well-known facts.

\begin{lemma}
  \thlabel{lem:reflexivecontainment}
  For any $A, B \in \Refn$, we have $A \leq A * B$ and $B \leq A * B$, with
  respect to containment.
\end{lemma}
\begin{proof}
  Since $A, B$ both contain the identity matrix, the product $A * B$ must
  contain both every row of $A$ and every column of $B$.
\end{proof}

\begin{lemma}
  \thlabel{lem:reflexivejtrivial}
  $\Refn$ is $\J$-trivial. 
\end{lemma}
\begin{proof}
  If $A \D B$, then $A \leq B$ and $B \leq A$ w.r.t containment. Hence $A = B$.    
\end{proof}

In order to determine generating sets for $\Refn$, we require the following results:

\begin{lemma}
  \thlabel{lem:reflexivegenstrimorelem}
  If $A$ is a non-trim, non-elementary matrix, then $A$ is properly
  decomposable.
\end{lemma}
\begin{proof}
Let $A$ be a non-trim, non-elementary matrix. Then $A$ has some row $i$
contained in some other row $j$. Let $B$ be the matrix obtained by setting entry
$i$ of row $j$ to be $0$. Then $B < A$ w.r.t containment, and letting $C$ be the
greedy left multiplier, $A = CB$. Hence $B, C > A$ in the $\J$-order. As $A$ is
non-elementary, $B$ and $C$ are non-identity matrices; hence $A$ is properly
decomposable.
\end{proof}

\begin{lemma}
  \thlabel{lem:reflexiveelementaryindecomposable}
  Elementary matrices are properly indecomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Elementary matrices are precisely those matrices in $\Refn$ containing $n + 1$
  ones. Since non-identity matrices in $\Refn$ have at least $n + 1$ ones, by
  \thref{lem:reflexivecontainment} elementary matrices are not properly
  indecomposable.
\end{proof}

\begin{cor}
  \thlabel{cor:reflexiveindecomposable}
  Let $X$ denote the set of matrices in $\Refn$ that are not properly
  decomposable, $T \subset X$ denote the trim matrices in $X$, and $E$ denote
  the elementary matrices. Then $X \setminus T = E$. 
\end{cor}

\begin{lemma}
  The unique minimal (monoid) generating set for $\Refn$ is $T \cup E$.
\end{lemma}
\begin{proof}
  We first note that $T$ must be contained in any generating set for $\Refn$.
  Since the elements of $E$ are precisely those reflexive matrices containing
  $n + 1$ ones, \thref{lem:reflexivecontainment} implies that they are not
  properly decomposable and hence $E$ must be contained in any generating set.

  Now let $A \in \Refn$; we must show that $A \in \genset{T \cup E}$. If $A \in
  T \cup E$ then we are done, so suppose not. By
  \thref{lem:reflexivegenstrimorelem} and the definition of $T$, $A$ must be a
  properly decomposable matrix; say $A = BC$ for $B, C \in \Refn\setminus\{I,
  A\}$. By \thref{lem:reflexivejtrivial}, $B$ and $C$ are strictly above $A$ in
  the $\J$-order of $\Refn$. Now if $B$ or $C$ are not in $T \cup E$, we may
  again decompose to find elements still higher in the $\J$-order. Since $\Refn$
  has finite height, we must eventually not be able to properly decompose the
  elements we have found; by \thref{cor:reflexiveindecomposable} we have then
  found a decomposition of $A$ as a product of matrices in $T \cup E$.
\end{proof}

Given a matrix $A \in \Refn$, it is helpful to be able to determine whether $A$
is properly decomposable. The following lemmas suggest a method for doing so.

\begin{lemma}
  \thlabel{lem:greedymaximal}
  Given matrices $A, B \in \Bn$:
  \begin{enumerate}
    \item
      the greedy left multiplier $C$ of $A$ w.r.t $B$ is maximal w.r.t
      containment in the set $\set{X \in \Bn}{XA \leq B}$,
    \item 
      the product $CA$ is maximal w.r.t containment amongst products $XA$
      contained in $B$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  Let $D \in \set{X \in \Bn}{XA = B}$, and suppose that row $i$ of $D$ contains
  a $1$ in position $j$. Then row $j$ of $A$ is contained in row $i$ of $B$, and
  hence $C$ has a $1$ in position $j$ of row $i$. Therefore $D \leq X$. The
  second part follows directly from this.
\end{proof}

\begin{lemma}
  \thlabel{lem:decomposeintersection}
  A trim matrix $A \in \Refn$ can be decomposed as $A = BC$, $B, C \in
  \Refn\setminus\{I, A\}$, if and only if $A = B'C'$ where $C'$ is the matrix
  whose $i$th row $C_i$ is the intersection 
  \[ C_i = \cap_{K_i} A_i \]
  where $K_i$ is the positions of the $1$s in the $i$th column of $B$, $B'$ is
  the greedy left multiplier, and $B', C' \in \Refn \setminus\{A\}$.
\end{lemma}
\begin{proof}
  ($\Rightarrow$)
  Suppose that $A = BC$ for $B, C \in \Refn \setminus\{I, A\}$, and let $B', C',
  K_i$ be defined as above. Fix $i$, and consider the $i^{\text{th}}$ row $C_i'$
  of $C'$. By the definition of $K_i$, for each $j \in K_i$, we have $C_i \leq
  A_j$; hence $C_i \leq C'_i \leq A_j$. This implies that $A = BC'$, since $A =
  BC \leq BC' \leq A$. By \thref{lem:greedymaximal}, $A = B'C'$, and $B' \in
  \Refn$ since $B \leq B'$. Since $C_i \leq C'_i$ for all $i$, $C'$ is also in
  $\Refn$. It remains to show that neither $B', C' \not\in \{I, A\}$. Note
  that since $B \leq B'$ (\thref{lem:greedymaximal}) and $C \leq C'$, $B', C'$
  are not the identity matrix. Since $A$ is trim, if $B'$ or $C'$ were equal
  to $A$ the product $B'C'$ would have more ones than $A$ does.\\
  ($\Leftarrow$) Immediate.
\end{proof}
Hence, in order to determine whether a trim matrix $A$ is decomposable it
suffices to:
\begin{enumerate}
  \item generate all matrices $C$ with rows intersections of rows of $A$, and
    for each $C$
  \item check whether the product $BC$ with the greedy left multiplier is equal
    to $A$, and $B, C \not\in \{I, A\}$.
\end{enumerate}
If no such matrices $B, C$ are found, then $A$ is indecomposable. This method is
clearly superior to checking all products of matrices in $\Refn$, but still may
require significant time.\\

In order to reduce the time spent checking matrices using
\thref{lem:decomposeintersection}, we would like to only check a smaller set of
canonical representatives. Unfortunately, the following two matrices illustrate
that two reflexive matrices can have the same canonical form under row and
column permutations in $\Bn$, while only one of them is decomposable in $\Refn$. 
\begin{ex}
  Let
\begin{align*}
  A = \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\text{, }&
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
Then $A, B \in \Ref{5}$, and $B$ may be obtained by exchanging columns $3$ and
$5$ of $A$. However, $A$ is indecomposable whilst
\begin{align*}
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 \\
    1 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1 
  \end{pmatrix}
  \begin{pmatrix}
    1 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
\end{ex} 

However, the following lemma shows that a more restricted form of
canonicalisation can be applied in $\Refn$:

\begin{lemma}
  \thlabel{lem:reflexivecanonical}
  Let $A, B \in \Refn$ be such that $A = P^{-1} B P$ for some permutation matrix
  $P \in S_n$ (i.e. $A$ is obtained by permuting the rows and columns of $B$ by
  the same permutation). Then $A$ is decomposable in $\Refn$ if and only if $B$
  is decomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Suppose that $B = XY$ for $X, Y \in \Refn\setminus \{I, A\}$. Then $P^{-1}XP,
  P^{-1}YP \in \Refn\setminus\{I, A\}$ and $P^{-1}XPP^{-1}YP = A$. The proof of
  the other direction is dual, since $PAP^{-1} = B$.
\end{proof}

This means that it is sufficient to enumerate the trim reflexive matrices in the
following standard form:
\begin{itemize}
  \item{all $1$s in the first row of $A$ are on the left,}
  \item{no row has fewer ones than the first row,}
  \item{if a $1$ appears in row $i$ in column $j$, then for each $k < j$ there
      is some row $l < i$ with a $1$ in position $k$.}
\end{itemize}

We then have the following algorithm for finding a minimal generating set for
$\Refn$:
\begin{enumerate}
  \item
    Enumerate the trim reflexive boolean matrices in standard form using a
    backtrack search, storing canonical representatives under a row and column
    permutation in a set $S$
  \item 
    Filter out the properly decomposable matrices in $S$ using
    \thref{lem:decomposeintersection}, leaving a set $T$ of trim matrices that
    are not properly decomposable
  \item
    The minimal generating set of $\Refn$ is then $T \cup E$.
\end{enumerate}
Using this algorithm, we can calculate the sizes of minimal generating sets up
to $n = 7$; these are contained in Figure~\ref{fig:BMatResults}.

There are a small number of matrices in $\Ref{7}$ for which an approach based on
\thref{lem:decomposeintersection} is too inefficient. These matrices can be
handled by attempting to write each of them as a product $A = B(C\alpha)$, where
$C$ is an element of $S$ TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Hall Matrices}
%The submonoid of $\Bn$ consisting of those boolean matrices containing a
%permutation matrix is particularly interesting. It is often called the
%\emph{Hall monoid} since matrices containing a permutation matrix correspond to
%instances of the Hall marriage problem that have a solution, and are thus
%referred to as \emph{Hall matrices}. We will denote the Hall monoid by
%$\Halln$. 
%
%In order to prove our main result on the Hall monoid, we will need the following
%classical result, restated in our context.
%
%\begin{thm}[Hall's Marriage Theorem]
%  Let $A in \Bn$. Then $A$ is a Hall matrix if and only if every union of $k$
%  rows contains at least $k$ ones, for $1 \leq k \leq n$.
%\end{thm}
%We shall say that a subset $X$ of the rows of a matrix \emph{satisfies the Hall
%  condition} if the union of the rows in $X$ contains at least $|X|$ ones, and
%that a matrix satifies the Hall condition if every subset of the rows satisfies
%the Hall condition.
%
%It will be useful in this section to define $e_i$ to be the boolean vector of
%length $n$ with a single $1$ in position $i$.
%
%The Hall monoid is similar in certain ways to $\Refn$. In particular
%the $\J$-relation is easily described through the following lemmas.
%
%\begin{lemma}
%  \thlabel{lem:HallContainment}
%  For any $A, B \in \Halln$, the product $AB$ contains at least as many ones as
%  $A$ or $B$ does.
%\end{lemma}
%\begin{proof}
%  Since $A \in \Halln$, $A$ contains a permutation matrix; hence $AB$ contains a
%  row-permuted copy of $B$. Similarly, $AB$ contains a column-permuted copy of
%  $A$.
%\end{proof}
%
%\begin{lemma}
%  \thlabel{lem:HallJRelation}
%  Two matrices $A, B \in \Halln$ are $\J$-related in $\Halln$ if and only if $A
%  = PBQ$ for two permutation matrices $P, Q \in S_n$.
%\end{lemma}
%\begin{proof}
%  The forward direction is clear. For the reverse, suppose that $A = SBT$ and $B
%  = UAV$ for matrices $S, T, U, V \in \Halln$. Then $BT$ contains a
%  column-permuted copy of $B$, and hence $A$ contains a row- and column-permuted
%  copy of $B$. Since, similarly, $B$ contains a row- and column-permuted copy of
%  $A$, it follows that $A$ is a row- and column-permutation of $B$.
%\end{proof}
%
%Unlike $\Refn$, $\Halln$ has a particularly nice minimal generating set.
%\begin{lemma}
%  Every minimal generating set for $\Halln$ is obtained by removing a rank $n-1$
%  matrix from a minimal generating set for $\Bn$. That is, every minimal
%  generating set for $\Halln$ consists of a set of representatives $P$ of the
%  prime $J$-classes of $\Bn$ together with two generators for the group of units
%  $S_n$ and an elementary matrix.
%\end{lemma}
%\begin{proof}
%  The fact that $P \subset \Halln$ is a consequence of the discussion after
%  \cite[Definition 2.4]{Caen1981aa}. Let $G \subset \Halln$ be obtained as in
%  the statement. To establish that $G$ is a generating set, we will show that
%  any Hall matrix that lies below the matrices in $G$ in the $\J$-order may be
%  written as a product of two higher non-permutation Hall matrices, and
%  therefore by an infinite ascent argument may be factorized into matrices in
%  $G$.
%  
%  Note that $G$ consists of matrices from the maximal $\J$-class and all
%  one-below-maximal $\J$-classes. By \thref{lem:PermutingReducedMatrices}, every
%  matrix in the $\J$-classes of matrices in $G$ is generated by $G$.
%
%  Let $A$ be a Hall matrix that lies below $G$ in the $\J$-order. We may assume
%  without loss of generality that $A$ contains the identity permutation, since
%  $\langle G \rangle$ contains $S_n$. We will decompose $A$ as a product of
%  non-permutation Hall matrices that lie above $A$ in the $\J$-order. 
%
%  First, suppose that $A$ is not trim, i.e.\ some row $i$ of $A$ is contained in
%  row $j$. Let $B$ be the matrix obtained by setting entry $i$ of row $j$ to be
%  equal to $0$, and $C$ be the greedy left multiplier of $B$ with respect to
%  $A$. Then $B$ and $C$ both contain the identity permutation, and hence are
%  Hall matrices. Since row $i$ of $B$ is contained in row $j$ of $A$, entry $(j,
%  i)$ of $C$ is $1$ and hence $C$ is not a permutation matrix.  Since $A$ was
%  not an elementary matrix, and $B$ was obtained by removing a single $1$ from
%  $A$, $B$ is not a permutation matrix. Finally, $A = CB$.
%
%  We now assume that $A$ is trim. Since $A$ lies below $G$ in the $\J$-order, it
%  has non-maximal row space. Let $B$ be a maximal non-permutation matrix in
%  $\Bn$ which contains the row space of $A$. Then $B$ is prime or elementary,
%  and hence is similar to some matrix in $G$. By multiplying by permutation
%  matrices $U$ and $V$, we may assume that $UBV$ contains the identity
%  permutation. Now $A = CB$ where $C$ is the greedy multiplier. Since $A$ is
%  trim, we must also have that $C$ is trim. However, there is no reason that $C$
%  must be a Hall matrix.
%  
%  Suppose that $C$ is a Hall matrix. Then, since $B$ is not similar to $A$, $C$
%  is not a permutation matrix.  Since $B$ is not a permutation matrix, $C$ is
%  not similar to $A$. By \thref{lem:HallJRelation}, $B$ and $C$ are both
%  non-permutation matrices which are greater than $A$ in the $\J$-order.
%
%  Now, if $C$ is not a Hall matrix, then it does not satisfy the Hall condition
%  and hence there is some minimal subset of rows $W \subseteq \{1, \ldots, n \}$
%  that do not satisfy the Hall condition. By multiplying by permutation matrices
%  $X$ and $Y$, and working with the matrix $XCY$, we may assume that $W = \{1,
%    \ldots, r \}$ and that the union of rows $1$ up to $r$ contains a $1$ in
%  positions $1$ up to $s$, $s < r$. We now construct two new matrices $S, T \in
%  \Halln$ such that $A = ST$. 
%  Let $x, y, u, v$ be the permutations of $\{1, \ldots, n \}$ associated with
%  the matrices $X, Y, U, V$. For $1 \leq i \leq s$, define row $i$ of $S$ to
%  be row $i$ of $XCY$ and row $i$ of $T$ to be row $i$ of $UBV$. For $s + 1 \leq
%  i \leq r$, define row $i$ of $S$ to be row $i$ of $XCY$ plus $e_i$, and define
%  row $i$ of $T$ to be $e_i$. For $r + 1 \leq i \leq n$, define row $i$ of $S$
%  to be $e_i$, and row $i$ of $T$ to be row $i$ of $A$. 
%  
%  
%  Oh dear, this doesn't work.
% 
%
%  We note now
%  that if $A$ is similar to a direct sum of a Hall matrix in $\Hall{m}$, $m <
%  n$, and an $(n-m)$ dimension identity matrix, then $A$ is decomposable into 
%
%\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Transformation Hall Matrices}
The previous section may be viewed in the context of ``matrices which are forced
to contain a certain permutation''. We now relax this requirement to consider
the monoid $\MTn$ of matrices which contain a transformation, i.e. have a $1$ in
every row.

\begin{lemma}
  All minimal generating sets for $\MTn$ are obtained by replacing the rank $n -
  1$ matrix in a minimal generating set for $\Bn$ by a matrix similar to
  \begin{align*}
    F' = \begin{pmatrix}
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 0 & 1 & 0 & \cdots & 0 \\
      0 & 0 & 0 & 1 & \cdots & 0 \\
        &   &   \dots & \dots & \\
      0 & 0 & 0 & 0 & \cdots & 1
    \end{pmatrix}
  \end{align*}
\end{lemma}
\begin{proof}
  Since all prime matrices have full rank, such a set $G$ is contained in
  $\MTn$. To see that it is a generating set, consider a matrix $A$ which is not
  $\J$-related to any matrix in $G$. We wish to write $A$ as a product of
  matrices which lie strictly above $A$ in the $\J$-order. 
  
  Suppose that $A$ is not row-trim, and row $i$ is contained in row $j$. Then
  subtracting row $i$ from row $j$, we obtain a new matrix $A'$. If row $j$ is
  now empty, we then insert any row that is not in the row space of $A$ as row
  $j$. Now $A$ is the product $F''A'$ of $A'$ with some matrix similar to $F'$. By
  replacing $A$ with $A'$, and repeating if necessary, we may assume that $A$ is
  row-trim; a dual procedure allows us to assume that $A$ is column-trim. 
  
  Let $A_0 = A$. Then we write $A_0 = B_0C_0$ where $B_0, C_0 \in \Bn$, $B_0$ has a
  maximal row-space amongst non-permutation matrices, and $C_0$ is the greedy left
  multiplier. Since $B_0$ is Hall, it lies in $\MTn$; it is also $\J$-related to
  some matrix in $G$ and hence lies above $A_0$. Since $A_0$ is trim, $C_0$ must also
  be trim, and similarly since $A_0$ contains no zero row neither does $C_0$.
  However, $B_0$ is not a permutation matrix, and therefore $A_0 = C_0B_0$ contains more
  $1$s than $C_0$ does. Now either $C_0$ also lies strictly above $A_0$, in which case
  we are done, or we can repeat the process with $A_1 = C_0$. Since we
  cannot continue producing matrices with fewer and fewer ones forever,
  eventually we must decompose one of the $A_i$s as desired; then the product $A
  = C_i B_i B_{i - 1} \ldots B_1$ consists of matrices strictly above $A$ in the
  $\J$-order, which all lie in $\MTn$. Hence by \thref{lem:GenSetDecomposition},
  $G$ generates $\MTn$.
  Now, since every generating set for $\Bn$ must contain a representative of
  each prime $\J$-class and an elementary matrix, so too must every generating
  set for $\MTn$. Now $F'$ is not Hall, while all prime and elementary matrices
  are Hall, so $F'$ is not generated by prime and elementary matrices. Hence,
  any such generating set $G$ is minimal. TODO: clean up this last paragraph.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Triangular matrices}
We now turn our attention to the monoids of upper and lower triangular boolean
matrices, denoted by $\UTn$ and $\LTn$ respectively. These matrices have a
particularly simple minimal generating set:

\begin{lemma}
  \thlabel{lem:mingeneratingsetfortriangular}
  The unique minimal (monoid) generating set $X$ for $\UTn$ [$\LTn$] consists of
  those elementary matrices and matrices similar to $F$ which are upper [lower]
  triangular.
\end{lemma}

\begin{proof}
  We will prove the lemma for upper triangular matrices; the proof for lower
  triangular matrices is dual.
  We will first construct any matrix $A \in \UTn$ as a product of matrices in
  $X$. We iteratively define a product $A_i$, $0 \leq i \leq n$ where $A_0$ is
  the identity and $n$ is the number of $1$s in $A$. For the $i$-th $1$
  contained in $A$ (ordered by row then column) with position $(x_i, y_i)$, we
  obtain $A_i$ from $A_{i - 1}$ by left-multiplying by $E_{x_i, y_i}$. Let the
  zero rows of $A$ have indices $\{z_1, \ldots, z_{k}\}$. Note that the matrices
  in $\UTn$ similar to $F$ are precisely those matrices obtained by deleting a
  single $1$ from an identity matrix. We define $A_{n + j}$ to be matrix
  obtained by left multiplying $A_{n + j - 1}$ by the element of $X$ with a zero
  row in position $z_j$. Then $A_{n + k} = A$. (TODO: prove this construction
  actually works).
  
  
  Now it is easy to show that for each matrix $A \in X$, if $A$ is written as a
  product $A = BC$ in $\UTn$ then one of $B$ or $C$ must be equal to $A$; hence
  any generating set for $\UTn$ must contain all matrices in $X$. Hence $X$ is
  the unique minimal generating set for $\UTn$.
\end{proof}

\section{Tropical matrices}
Another class of semiring which has attracted significant recent attention (see
~\cite{TODO}) is the tropical min-plus semirings which are interesting because
TODO. The monoids of matrices over these semirings have significantly more
complex behaviour than the boolean matrix monoid (see \cite{TODO}).

\subsection{Min-plus matrices}

\begin{thm}[J, J, J]\label{thm-min-plus}
  The monoid $M_{2}(K^{\infty})$ of $2 \times 2$ min-plus matrices is
  generated by the matrices:
  \begin{equation*}
          A_{i} = \mat{i}{0}{0}{\infty},
    \quad B     = \mat{1}{\infty}{\infty}{0},
    \quad \text{and}
    \quad C     =  \mat{\infty}{\infty}{\infty}{0}
  \end{equation*}
  where $i \in \N \cup \{\infty\}$.
\end{thm}

\begin{cor}[J, J, J]\label{cor-finite-min-plus}
  Let $t \in \N$ be arbitrary. Then the finite monoid $M_{2}(K^{\infty}_t)$ of
  $2 \times 2$ min-plus matrices is generated by the $t + 4$ matrices:
  \begin{equation*}
          A_{i} = \mat{i}{0}{0}{\infty},
    \quad B     = \mat{1}{\infty}{\infty}{0},
    \quad \text{and}
    \quad C     =  \mat{\infty}{\infty}{\infty}{0}
  \end{equation*}
  where $i \in \{0, 1, \ldots, t, \infty\}$.
\end{cor}

\subsection{Max-plus matrices}
???? Seems like a natural thing to include.

\section{Matrices over $\mathbb{Z}_n$}

\begin{thm}[Wilf]
  The monoid $M_{k}(\mathbb{Z}_{n})$ is generated by $GL_{k}(\mathbb{Z}_{n})$ and
  any one element from each of the $\D$-classes immediately below the group of
  units. In particular, you could choose
  the diagonal matrices
  $$\begin{pmatrix}
    n/p    & 0      & \cdots & 0  \\
    0      & 1      &        & \vdots \\
    \vdots &        & \ddots & 0 \\
    0      & \cdots & 0      & 1  \\
   \end{pmatrix},$$
   for each prime divisor $p$ of $n$.
\end{thm}
Note that by the same logic as everywhere else this must be minimal.

\printbibliography
\end{document} 
