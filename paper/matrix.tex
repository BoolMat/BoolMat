\documentclass[11pt]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb, latexsym, mathrsfs, pifont,
tabu, enumerate}
\usepackage[cm]{fullpage}
\usepackage{theoremref}
\usepackage[ruled, linesnumbered]{algorithm2e}

\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{defi}[thm]{Definition}
\newtheorem{ex}[thm]{Example}
\newenvironment{de}{\begin{defi}\rm}{\end{defi}}
\newcommand{\proofref}[1]{\noindent {\emph{Proof of Theorem}~\ref{#1}.\ }}
\newcommand{\defn}[1]{\textbf{\textit{#1}}}
\numberwithin{equation}{section}

% Lists
\def\labelenumi{\theenumi}
\def\theenumi{(\roman{enumi})}

% Macros
\newcommand{\id}{\mbox{\rm id}}
\newcommand{\set}[2]{\ensuremath{\{#1 : #2 \}}}
\newcommand{\genset}[1]{\ensuremath{\langle\: #1 \:\rangle}}
\renewcommand{\to}{\longrightarrow}


% For Algorithms
\SetKwProg{Fn}{Function}{}{}
\SetKwFunction{FZeroIfNotSubset}{ZeroIfNotSubset}
\SetKwFunction{FRemoveDuplicateRows}{RemoveDuplicateRows}
\SetKwComment{Comment}{}{}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\DontPrintSemicolon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\B}{\mathbb{B}}
\newcommand{\Bn}{M_n(\B)}
\newcommand{\Refn}{M_n^{\text{id}}(\B)}
\newcommand{\Ref}[1]{M_{#1}^{\text{id}}(\B)}
\newcommand{\Halln}{M_n^{\text{S}}(\B)}
\newcommand{\Hall}[1]{M_{#1}^{\text{S}}(\B)}
\newcommand{\MTn}{M_n^{\text{T}}(\B)}
\newcommand{\MT}[1]{M_{#1}^{\text{T}}(\B)}
\newcommand{\Bm}[1]{M_{m}(\B)}
\renewcommand{\L}{\mathscr{L}}
\newcommand{\R}{\mathscr{R}}
\newcommand{\D}{\mathscr{D}}
\newcommand{\J}{\mathscr{J}}
\renewcommand{\H}{\mathscr{H}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\usepackage[backend=biber, bibencoding=utf8]{biblatex}
\bibliography{matrix}

\title{Minimal generating sets for the monoid of all boolean matrices}
\author{F. Hivert, J. D. Mitchell, and F. L. Smith}
\date{\today}
\begin{document}

\maketitle

\begin{abstract}
  TODO
\end{abstract}

\section{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The \defn{boolean semiring} $\B$ is the set $\{0, 1\}$ with addition defined by 
\begin{align*}
  0 + 1 = 1 + 0 &= 1 + 1 = 1 \\
  0 + 0 &= 0
\end{align*}
and multiplication defined as usual for the real numbers $0$ and $1$.  The
addition and multiplication of elements of $\B$ naturally extends to row and
column vectors of equal length with entries in $\B$.  The main object of study
in this document is the collection $\Bn$ of $n\times n$ matrices with entries in
$\B$. Under the usual multiplication of matrices, using addition and
multiplication in $\B$, the set $\Bn$ forms a monoid; call the \defn{full
  boolean matrix monoid}. The monoid $\Bn$ is classical in the literature of
semigroup theory being among the first monoids to be studied; see, for example,
\cite{Zaretskii1963aa}. The monoids $\Bn$, $n\in \N$, have been extensively
studied in the literature, by many authors, and a great deal is known about its
structure and properties. For example, if $G$ is a finite group, then there
exists an $n\in \N$ such that $G$ occurs as a maximal subgroup of $\Bn$; the
probability that a random product of matrices in $\Bn$ equals the universal
matrix:
\begin{equation*} 
  \begin{pmatrix}
  1 & 1 & \cdots & 1\\
  1 & 1 & \cdots & 1\\ 
  \vdots & \vdots & \ddots & \vdots\\
  1 & 1 & \cdots & 1\\ 
\end{pmatrix} 
\end{equation*} 
tends to $1$ as $n\to \infty$; the minimal size of a generating set for $\Bn$
grows exponentially with $n$ (see~\thref{lem:exponentialgensets});
Devadze~\cite{Devadze1968aa} and Konieczny~\cite{Konieczny2011aa} characterise
minimum cardinality generating sets for $\Bn$; TODO: more.

Despite its venerable status, many aspects of the monoids $\Bn$ are still
shrouded in mystery. The purpose of this article is to cast some light on the
problems of determining the minimum cardinality $\mathbf{d}(\Bn)$ of a
generating set for $\Bn$ and certain submonoids of $\Bn$ such as the reflexive
boolean matrix monoid $\Refn$.
% The time and space complexity of determining any of these value is exponential
% in $n$. 
It seems unlikely that an explicit formula for any of these numbers exists.
In this paper we describe algorithms for computing the numbers listed,
and the output of our implementation~\cite{} of these algorithms. The latter
are summarised in Figures~\ref{figure-table-1} and \ref{fig:reflexiverank}.

\begin{figure}
  \centering
  \begin{tabular}{l|r|r}
    $n$ & $\mathbf{d}(\Bn)$ &   \\
    \hline
    1 & 2          & - \\ 
    2 & 3          & - \\ 
    3 & 5          & - \\ 
    4 & 7          & - \\
    5 & 13         & ? \\
    6 & 68         & ? \\ 
    7 & 2\ 143     & \cmark \\
    8 & 495\ 115   & \cmark \\
    9 & ?          & ?
  \end{tabular}
\vspace{1cm}

  \caption{The minimum size $d(\Bn)$ of a generating set for the monoid
  consisting of all $n \times n$ Boolean matrices matrices where: 
  ``-'' indicates a value that can be computed by hand or brute force;
  ``\cmark'' indicates that the value was first found here;
  ``?'' indicates that the value is unknown.}
  \label{figure-table-1}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
\label{section-preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

On any semigroup $S$, there are some key equivalence relations. These are known
as Green's relations, and are defined in terms of principal ideals as follows.
Let $S$ be any semigroup and let $s, t \in S$. Then
\begin{align*}
  s \L t &\text{ if and only if } S^1 s = S^1 t \\
  s \R t &\text{ if and only if } s S^1 = t S^1 \\
  s \J t &\text{ if and only if } S^1 s S^1 = S^1 t S^1.
\end{align*}
Finally, we define Green's $\H$-relation as the intersection of $\L$ and $\R$.
We write $X_s$ for the Green's $\mathcal{X}$-class of $s$, where
$\mathcal{X} \in \{\L, \R, \J, \H\}$.
There is a natural partial order on certain Green's classes
\begin{align*}
  R_s \leq R_t &\text{ if and only if } sS^1 \subseteq tS^1 \\
  L_s \leq L_t &\text{ if and only if } S^1s \subseteq S^1t \\
  J_s \leq J_t &\text{ if and only if } S^1 s S^1 \subseteq S^1 t S^1.
\end{align*}
Further background on Green's relations can be found in~\cite{Howie1995aa}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The group of units of $\Bn$ is isomorphic to the symmetric group $S_n$, and we
will henceforth denote the group of units by $S_n$.

If $A \in \Bn$, then the \defn{row space} $R(A)$ of $A$ is the set of 
all finite sums of the rows of $A$.  If the rows of $A\in \Bn$ are viewed as
the characteristic function of a subset of $\{1, \ldots, n\}$, then summing two
rows is the same as taking the union of the corresponding subsets.  The
\defn{row basis} $r(A)$ of $A\in \Bn$ is the set of rows of $A$ that cannot be
written as a sum of other rows of $A$. The \defn{column space}
$C(A)$ and \defn{column basis} $c(A)$ of a boolean matrix $\Bn$ are defined
dually. It is straightforward to verify that if $A \in \Bn$, then $r(A)$ is the
unique minimal generating set for $R(A)$, and $c(A)$ is the unique minimal
generating set for $C(A)$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The importance of the row and column bases in the study of $\Bn$ arises due to
the following well-known results.

\begin{prop} 
  \thlabel{prop-principal}
  Let $A, B \in \Bn$. Then the following hold:
  \begin{enumerate}[\rm (i)]

    \item
      If $R(A) \subseteq R(B)$, then $A \in \Bn B$.  Similarly, if $C(A)
      \subseteq C(B)$, then $A \in B \Bn$.

    \item 
      $R(AB) \subseteq R(B)$ and $C(AB) \subseteq C(B)$.
  \end{enumerate}
\end{prop}
\begin{proof}
  \noindent \textbf{(i).}
  If $R(A) \subseteq R(B)$, then every row of $A$ can be expressed as a sum of
  rows of $B$. Define $X$ by $X = [x_{ij}]$ where $x_{ij}$ is $1$ whenever the
  $j$th row of $B$ is contained in the $i$th row of $A$. Then $A = XB \in \Bn
  B$.  The other case is dual.
  \bigskip

  \noindent \textbf{(ii).}
  Suppose that $A = [\alpha_{ij}]$ and $B = [\beta_{ij}]$. If 
  $AB = [\gamma_{ij}]$, then 
  \[
  \gamma_{ij} = \alpha_{i1} \beta_{1j} + \alpha_{i2}\beta_{2j} 
                + \cdots + \alpha_{in}\beta_{nj}
              = \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kj}.
  \]
  It follows that the $i$th row of $AB$ is 
  \[
  (\gamma_{i1}, \gamma_{i2}, \ldots, \gamma_{in})
   =  \left (\sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k1},
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{k2},
     \ldots, 
     \sum_{k = 1} ^ {n} \alpha_{ik}\beta_{kn}\right) \\
   % & = & (\alpha_{i1}\beta_{11} + \alpha_{i2}\beta{21} + \cdots +
   %  \alpha_{in}\beta{n1},
   %  \alpha_{i1}\beta_{12} + \alpha_{i2}\beta{22} + \cdots +
   %  \alpha_{in}\beta{n2},
   %  \ldots,
   %  \alpha_{i1}\beta_{1n} + \alpha_{i2}\beta{2n} + \cdots +
   %  \alpha_{in}\beta{nn}) \\
   % & = & 
   % (\alpha_{i1}\beta_{11}, \alpha_{i1}\beta_{12}, 
   % \ldots, \alpha_{i1}\beta_{1n})
   % + 
   % (\alpha_{i2}\beta_{21}, \alpha_{i2}\beta_{22}, 
   % \ldots, \alpha_{i2}\beta_{2n})
   % + \cdots +
   % (\alpha_{in}\beta_{n1}, \alpha_{in}\beta_{n2}, 
   % \ldots, \alpha_{in}\beta_{nn}) \\
    =
    \sum_{k = 1} ^ {n} 
    \alpha_{ik}
    (\beta_{k1}, \beta_{k2}, \ldots, \beta_{kn}).
  \]
  Thus the $i$th row of $AB$ is a sum of rows of $B$, and so $R(AB) \subseteq
  R(B)$. 
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{prop} 
  \thlabel{lem:BMatGreensRowColumnBases}
  Let $A, B \in \Bn$. Then the following are equivalent:
  \begin{enumerate}[\rm (i)]
    \item 
      $A \L B$;

    \item 
      $R(A) = R(B)$;

    \item 
      $r(A) = r(B)$.
  \end{enumerate}
  An analogous statement holds for Green's $\R$-relation using column spaces
  and bases. 
\end{prop}
\begin{proof}
  Parts (ii) and (iii) are equivalent since a row space is uniquely determined
  by its row basis. It remains to show that (i) and (ii) are
  equivalent.\bigskip

  \textbf{(i) $\Rightarrow$ (ii).} 
  If $A \L B$, then there are 
  $X, Y \in \Bn$ such that $XA = B$ and $YB = A$. Then $R(B) = R(XA) \subseteq
  R(A)$ and $R(A) = R(YB) \subseteq R(B)$ by
  Proposition~\ref{prop-principal}(ii).
  \bigskip

  \textbf{(ii) $\Rightarrow$ (i).} Follows immediately by
  Proposition~\ref{prop-principal}(i). 
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Minimal generating sets}

One of the problems we are particularly interested in is determining minimal
generating sets for $\Bn$. Unfortunately it is known that the size of a minimal
generating set for $\Bn$ grows very quickly with $n$;
see~\thref{lem:exponentialgensets}.\\


In contrast, the subsemigroup of $\Bn$ generated by all the regular elements can
be generated by the four matrices \cite{Roush1977aa}

\begin{align*}
  T = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    1 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    \vdots  & \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  U = \begin{pmatrix}
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
    0 & 0 & 0 & 0 & \cdots & 0 \\
      &   &   \dots & \dots & \\
    1 & 0 & 0 & 0 & \cdots & 0 
  \end{pmatrix},&\\
  E = \begin{pmatrix}
    1 & 0 & 0 & 0 & \cdots & 0 \\
    1 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
      &   &   \dots & \dots & \\
    0 & 0 & 0 & 0 & \cdots & 1 
  \end{pmatrix}\text{, }&
  F = \begin{pmatrix}
    0 & 0 & 0 & 0 & \cdots & 0 \\
    0 & 1 & 0 & 0 & \cdots & 0 \\
    0 & 0 & 1 & 0 & \cdots & 0 \\
    0 & 0 & 0 & 1 & \cdots & 0 \\
      &   &   \dots & \dots & \\
    0 & 0 & 0 & 0 & \cdots & 1
  \end{pmatrix}
\end{align*}
Note that together $T$ and $U$ generate the symmetric group (the maximal
$\J$-class of $\Bn$). 

If $A, B\in \Bn$, then $A$ and $B$ are \defn{similar} if 
one can be obtained from the other by permuting the rows and/or columns. Note
that similar matrices are $\J$-related.
We call any matrix similar to $E$ an \defn{elementary} matrix.

To find minimal generating sets, we need a few more concepts:

\begin{de}[\textbf{Prime matrices.}]
  A matrix $A \in \Bn$ is called \defn{prime} if $A = BC$ implies $B$ or $C$ is
  a permutation matrix, and $A$ itself is not a permutation matrix.
\end{de}

The prime matrices therefore sit directly below the top $\J$-class in the
partial order of $\J$-classes. There is, however, one more $\J$-class
immediately below the top: $D_E$. Note that $D_F \leq D_E$. The next results
show that in fact these are in fact all of the $\J$-classes immediately below
the top.

Let $\beta_n$ denote the set $\set{R(A)}{A\in \Bn\setminus S_n}$ of all
possible proper row subspaces of elements of $\Bn$, and let $\B^n$ denote
the space of all boolean vectors of length $n$. Note that $\B^n$ is the
row/column space of precisely the permutation matrices.

\begin{thm}[cf. Theorem 5.1 in~\cite{Caen1981ab}]
  \thlabel{thm:MaximalRowSpaces}
  Let $A \in \Bn\setminus S_n$. Then $R(A)$ is maximal with respect to
  containment in $\beta_n$ if and only if $A$ is prime or elementary.  
\end{thm}

\begin{de}[Reduced matrices]
  A matrix $A \in \Bn$ is \emph{row-reduced} if no row of $A$ can be written as
  a sum of other rows of $A$. \emph{Column-reduced} is defined dually. We say
  that $A$ is \emph{reduced} if it is both row-reduced and column-reduced.
\end{de}

An important result for computation is the following:
\begin{lemma}[\cite{Plemmons1970aa}]
  \thlabel{lem:PermutingReducedMatrices}
  Let $A, B \in \Bn$ be reduced. Then $A \J B$ if and only $A = \alpha B \beta$
  for some $\alpha, \beta \in S_n$. 
\end{lemma}

This result allows us to store single representatives of the $\J$-classes of
reduced matrices by computing a canonical image under permuting rows and
columns. \\

The following concept is useful when attempting to decompose matrices as
products.
\begin{defi}
  Given two matrices $A, B \in \Bn$, we say that the \textbf{\textit{greedy
  left [right] multiplier}} of $A$ w.r.t. $B$ is the matrix $C$ containing a $1$
  in position $(i, j)$ if and only if $A_j \leq B_i$ [$A^T_i \leq B^T_j$].
\end{defi}

Given an expression of the form $CA = B$, we will often simply say that
\textit{$C$ is the greedy multiplier} if $C$ is the greedy left multiplier
of $A$ w.r.t $B$; the dual is also true.

In order to find prime matrices, we must introduce another special class of
boolean matrices.

\begin{de}[Trim matrices]
  A matrix $A \in \Bn$ is \emph{row-trim} if no non-zero row of $A$ is contained in
  another row. \emph{Column-trim} is defined dually. We say that $A$ is
  \emph{trim} if it is both row-trim and column-trim.
\end{de}

The importance of trim matrices lies in the following facts:
\begin{lemma}[\cite{Konieczny2011aa}]
  \thlabel{lem:PrimeMatricesAreTrim}
  Every prime matrix is trim.
\end{lemma}
\begin{proof}
  Let $A \in \Bn$ be prime. Suppose some non-zero row $k$ of $A$ is contained in
  a row $l$ of $A$. Then $XA = A$, where $X$ is the greedy left multiplier, and
  since $|X_l| \geq 2$, $X \not\in S_n$, a contradiction. A dual argument shows
  that no non-zero column of $A$ is contained in another column.
\end{proof}

\begin{lemma}
  \thlabel{lem:TrimMatricesAreReduced}
  Every trim matrix is reduced.
\end{lemma}
\begin{proof}
  Since no row [column] of a reduced matrix is contained in another row
  [column], no row [column] can be expressed as a sum of other rows [columns].
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thm}[Devadze's Theorem \cite{Konieczny2011aa}]
  \thlabel{thm:Devadze}
  A minimal generating set for $\Bn$ is given by $\{T, U, E, F\} \cup P$
  where $P$ is a set of representatives of the prime $\J$-classes of $\Bn$.
\end{thm}

In fact, Devadze's theorem is stronger: \emph{any} minimal generating set for
$\Bn$ consists of $P$ together with two generators for the group of units $S_n$,
an elementary matrix, and some matrix $\J$-related to $F$. 

\begin{cor}
  \thlabel{lem:exponentialgensets}
  The size $\mathbf{d}(\Bn)$ of a minimal generating set for $\Bn$ grows
  exponentially with $n$.
\end{cor}
\begin{proof}
  This follows from the fact that there at least $2^{\frac{n^2}{4} - O(n)}$
  prime boolean matrices in $\Bn$ (see~\cite[Theorem 2.4.1]{Kim1982aa}) and each
  $\J$ class contains at most $(n!)^2$ elements; hence there are exponentially
  many prime $\J$-classes.
\end{proof}

A possible algorithm for computing minimal generating sets is the following:

\begin{itemize}
  \item
    Enumerate the trim boolean matrices using a backtrack search, storing 
    canonical representatives under row/column permutations in some set $S$
  \item 
    Compute $R = \set{R(A\alpha)}{A \in (S\setminus S_n) \cup \{E\}, \alpha \in S_n}$
  \item 
    Representatives of the prime $D$-classes are then those $A \in S\setminus S_n$ 
    with row space maximal in $R$.
\end{itemize}

\begin{proof}
  By \thref{lem:PrimeMatricesAreTrim} and \thref{lem:PermutingReducedMatrices},
  $S$ contains a single canonical representative of each prime $\J$-class.
  Now we can obtain a representative of every prime $L$-class by considering the
  products $A\alpha$ for $A \in S, \alpha \in S_n$ (note that there will be
  duplicate reps and non-prime reps), by \thref{lem:TrimMatricesAreReduced} and
  \thref{lem:PermutingReducedMatrices}, noting that multiplying on the left by a
  permutation matrix does not change the $L$-class.
  Similarly representatives of every elementary $L$-class can be obtained as the
  products $E\alpha$ for $\alpha \in S_n$, since the elementary matrices are
  defined as those which are permutationally equivalent to $E$.
  By \thref{thm:MaximalRowSpaces}, $R$ must therefore contain the maximal
  elements of $\beta_n$. Hence those elements of $S \setminus S_n$ which have
  row-space maximal in $R$ are precisely the prime representatives. 
\end{proof}

We can improve the algorithm by using the following result
to restrict the matrices we need to consider:

\begin{prop}[\cite{Breen1997aa}]
  \thlabel{prop:StandardFormProperties}
  In every $\J$-class of $\Bn$ there is a matrix $A$ in \emph{standard form} with the following properties:
  \begin{itemize}
  \item{$A$ is reduced,}
  \item{all non-zero rows [columns] of $A$ are at the top [right],}
  \item{considering the non-zero rows [columns] of $A$ as binary numbers, they
        form a strictly increasing sequence,}
  \item{all ones in the first non-zero row [column] of $A$ are on the right
        [bottom],}
  \item{no non-zero row has fewer ones than the first row,}
  \end{itemize}
\end{prop}

Each of these properties is an attempt to minimise the value of the matrix in its $\J$-class when considered as a binary number.
Unfortunately, having these properties is not enough to guarantee that the matrix is minimal, so standard form does not give a canonical form for matrices.

\begin{ex}
Let
\begin{align*}
  A = \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\text{, }&
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
Then $A$ and $B$ are in the standard form of
\thref{prop:StandardFormProperties}. Swapping rows $1$ and $2$ and columns $3$
and $4$ shows that $A$ and $B$ are similar, and hence are $\J$-related.
\end{ex}

Using this simple algorithm minimal generating sets for $n \leq 7$ have been obtained.
Some numbers are contained in Figure~\ref{figure-table-1}.

For $n=8$ this is no longer sufficient. In this case it is necessary to
prefilter the matrices before comparing the row spaces. The most obvious way
to do this is check containment of each row space in all the column permutations
of some set of the largest row spaces; this is actually fairly effective.
Another technique is based on the following lemma:

\begin{lemma}
  \thlabel{lem:ExtendingPrimeMatrices}
  Let $A$ be a prime matrix in $M_{n-1}(\B)$. Extend $A$ to a matrix $B \in \Bn$
  by adding a row of zeros at the bottom and a column of zeros on the right,
  then setting $B_{n,n} = 1$. Then $B$ is prime in $\Bn$.
\end{lemma}
\begin{proof}
  We will show that $R(B)$ is maximal in $\beta_n$, by showing that if 
  $R(C) \in \beta_n$ contains $R(B)$, then $r(B) = r(C)$.
  Let $C$ be such a matrix.
  The last row of $B$ must also be in $C$ since it is a minimal in $\B^{n}$. 
  Now $R(A)$ has a unique basis of $n-1$ rows which must be contained in both $B$ and
  $C$, so we have $r(B) = r(C)$.
\end{proof}

For $n=8$ prefiltering by some of the large row spaces and extended prime
matrices is enough to make the minimal generating set algorithm reasonable.
An improvement is based on the following ideas:

\begin{defi}
  Let $v, w \in \B^n$. We say that $v \leq w$ if $v_i = 1 \implies w_i = 1$ for all $i$.
\end{defi}

\begin{defi}
  Let $A \in \Bn$. The \emph{graph} of $R(A)$ is the directed graph with vertices $R(A)$ and an edge from $v$ to $w$ if $v \leq w$. The graph of $C(A)$ is defined analogously. 
\end{defi}

\begin{thm}[Zaretskii's theorem]
  \thlabel{thm:Zaretskii}
  Let $A, B \in \Bn$. Then $A \leq_{\J} B$ if and only if there exists 
  $f: R(A) \to R(B)$ such that for all $v, w \in R(A)$, $f(v) \leq f(w) \iff
  v \leq w$.
\end{thm}

In other words, $A \leq_{\J} B$ iff there exists a homomorphic embedding of the 
graph of $R(A)$ into the graph of $R(B)$ which respects edges and non-edges. \\

In our case, we can put restrictions on the homomorphic embeddings. We will instead
look for homomorphic embeddings between certain augmented graphs.

\begin{defi}
  Let $A \in \Bn$. The \emph{augmented graph of $R(A)$} is the disjoint union of the graph of $R(A)$ with the empty graph on the vertices $\{c_i \: : \: 1 \leq i \leq n\}$, with an edge from $v \in R(A)$ to $c_i$ if $v_i = 1$. The \emph{augmented graph of $r(A)$} is defined analogously.
\end{defi}

\begin{lemma}
  \thlabel{lem:EmbeddingGraphs}
  Let $S$ be a set of representatives of trim matrices, and let $A \in S$. Then $A$ is not prime or elementary if and only if for some $B \in S\setminus \{A\}$ there exists an embedding $\phi$ from the augmented graph of $r(A)$ into the augmented graph of $R(B)$ which permutes $\{ c_i : 1 \leq i \leq n \}$ and respects non-adjacency.
\end{lemma}
\begin{proof}
  Let $A$ not be prime or elementary; then by comments above $R(A)$ is contained in the row space of some column permutation $\alpha$ of a $B \in S \setminus \{A\}$. Then the map that extends $\phi : c_i \to c_{i\alpha^{-1}}$ has the required properties. Conversely if such a map $\phi : r(A) \to R(B)$ exists it induces a column permutation of $B$ which contains $A$. 
\end{proof}

Note that such an embedding $\phi$ must also map a vector containing $i$ ones to another containing $i$ ones to preserve adjacency and non-adjacency with the set $\{ c_i : 1 \leq i \leq n \}$.

We can therefore use the following improved algorithm.
\begin{itemize}
  \item
    Enumerate the trim boolean matrices using a backtrack search, storing 
    canonical representatives under row/column permutations in some set $S$
  \item 
    Compute the augmented graphs of $r(A)$ and $R(A)$ for each $A \in S$
  \item 
    For each pair $A, B$ of digraphs, if there is a $\phi$ as in \thref{lem:EmbeddingGraphs} discard $A$.
  \item
    The remaining matrices are then representatives of the prime matrices
\end{itemize}

The principle improvements in this algorithm are
\begin{itemize}
  \item 
    Efficient digraph homomorphism finding code can be used (e.g. Digraphs)
  \item
    No more data has to be computed, unlike the previous algorithm where new row spaces had to be produced for each column permutation
  \item
    Information about the graphs can be reused (in particular their automorphism group). However, this is not as useful as it might seem since the automorphism group of prime row spaces seems to be almost always trivial.
\end{itemize}

Some heuristics which seem to significantly improve the embedding search are:

\begin{itemize}
  \item
    Order the lattice digraphs by size and try to embed in the biggest digraphs
    first
  \item
    Force the embeddings to map the minimum element (zero vector) in the first
    digraph to the minimum element in the second digraph
\end{itemize}

\section{Reflexive Boolean Matrices}
An interesting submonoid of $\Bn$ is the monoid $\Refn$ of reflexive boolean
matrices, i.e. boolean matrices with $1$s on the main diagonal. Minimal
generating sets for $\Refn$ are significantly larger than those of $\Bn$; this
is essentially caused by the following well-known facts.

\begin{lemma}
  \thlabel{lem:reflexivecontainment}
  For any $A, B \in \Refn$, we have $A \leq A * B$ and $B \leq A * B$, with
  respect to containment.
\end{lemma}
\begin{proof}
  Since $A, B$ both contain the identity matrix, the product $A * B$ must
  contain both every row of $A$ and every column of $B$.
\end{proof}

\begin{lemma}
  \thlabel{lem:reflexivejtrivial}
  $\Refn$ is $\J$-trivial. 
\end{lemma}
\begin{proof}
  If $A \D B$, then $A \leq B$ and $B \leq A$ w.r.t containment. Hence $A = B$.    
\end{proof}


In order to find a generating set for $\Refn$, we require the following results:

\begin{defi}
  An element $x$ of a monoid $M$ with identity $e$ is \defn{decomposable} if
  there exist $y, z \in M$ with $x = yz$, and \defn{properly decomposable} if
  there exist $y, z \in M\setminus\{e, x\}$ such that $x = yz$.
\end{defi}

\begin{lemma}
  \thlabel{lem:reflexivegenstrimorelem}
  If $A$ is a non-trim, non-elementary matrix, then $A$ is properly
  decomposable.
\end{lemma}
\begin{proof}
Let $A$ be a non-trim, non-elementary matrix. Then $A$ has some row $i$
contained in some other row $j$. Let $B$ be the matrix obtained by setting entry
$i$ of row $j$ to be $0$. Then $B < A$ w.r.t containment, and letting $C$ be the
greedy left multiplier, $A = CB$. Hence $B, C > A$ in the $\J$-order. As $A$ is
non-elementary, $B$ and $C$ are non-identity matrices; hence $A$ is properly
decomposable.
\end{proof}

\begin{lemma}
  \thlabel{lem:reflexiveelementaryindecomposable}
  Elementary matrices are properly indecomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Elementary matrices are precisely those matrices in $\Refn$ containing $n + 1$
  ones. Since non-identity matrices in $\Refn$ have at least $n + 1$ ones, by
  \thref{lem:reflexivecontainment} elementary matrices are not properly
  indecomposable.
\end{proof}

\begin{cor}
  \thlabel{cor:reflexiveindecomposable}
  Let $X$ denote the set of matrices in $\Refn$ that are not properly
  decomposable, $T \subset X$ denote the trim matrices in $X$, and $E$ denote
  the elementary matrices. Then $X \setminus T = E$. 
\end{cor}

\begin{lemma}
  The unique minimal (monoid) generating set for $\Refn$ is $T \cup E$.
\end{lemma}
\begin{proof}
  We first note that $T$ must be contained in any generating set for $\Refn$.
  Since the elements of $E$ are precisely those reflexive matrices containing
  $n + 1$ ones, \thref{lem:reflexivecontainment} implies that they are not
  properly decomposable and hence $E$ must be contained in any generating set.

  Now let $A \in \Refn$; we must show that $A \in \genset{T \cup E}$. If $A \in
  T \cup E$ then we are done, so suppose not. By
  \thref{lem:reflexivegenstrimorelem} and the definition of $T$, $A$ must be a
  properly decomposable matrix; say $A = BC$ for $B, C \in \Refn\setminus\{I,
  A\}$. By \thref{lem:reflexivejtrivial}, $B$ and $C$ are strictly above $A$ in
  the $\J$-order of $\Refn$. Now if $B$ or $C$ are not in $T \cup E$, we may
  again decompose to find elements still higher in the $\J$-order. Since $\Refn$
  has finite height, we must eventually not be able to properly decompose the
  elements we have found; by \thref{cor:reflexiveindecomposable} we have then
  found a decomposition of $A$ as a product of matrices in $T \cup E$.
\end{proof}

Given a matrix $A \in \Refn$, it is helpful to be able to determine whether $A$
is properly decomposable. The following lemmas suggest a method for doing so.

\begin{lemma}
  \thlabel{lem:greedymaximal}
  Given matrices $A, B \in \Bn$:
  \begin{enumerate}
    \item
      the greedy left multiplier $C$ of $A$ w.r.t $B$ is maximal w.r.t
      containment in the set $\set{X \in \Bn}{XA \leq B}$, and\\
    \item 
      the product $CA$ is maximal w.r.t containment amongst products $XA$
      contained in $B$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  Let $D \in \set{X \in \Bn}{XA = B}$, and suppose that row $i$ of $D$ contains
  a $1$ in position $j$. Then row $j$ of $A$ is contained in row $i$ of $B$, and
  hence $C$ has a $1$ in position $j$ of row $i$. Therefore $D \leq X$. The
  second part follows directly from this.
\end{proof}

\begin{lemma}
  \thlabel{lem:decomposeintersection}
  A trim matrix $A \in \Refn$ can be decomposed as $A = BC$, $B, C \in
  \Refn\setminus\{I, A\}$, if and only if $A = B'C'$ where $C'$ is the matrix
  whose $i$th row $C_i$ is the intersection 
  \[ C_i = \cap_{K_i} A_i \]
  where $K_i$ is the positions of the $1$s in the $i$th column of $B$, $B'$ is
  the greedy left multiplier, and $B', C' \in \Refn \setminus\{A\}$.
\end{lemma}
\begin{proof}
  ($\Rightarrow$)
  Suppose that $A = BC$ for $B, C \in \Refn \setminus\{I, A\}$, and let $B', C',
  K_i$ be defined as above. Fix $i$, and consider the $i^{\text{th}}$ row $C_i'$
  of $C'$. By the definition of $K_i$, for each $j \in K_i$, we have $C_i \leq
  A_j$; hence $C_i \leq C'_i \leq A_j$. This implies that $A = BC'$, since $A =
  BC \leq BC' \leq A$. By \thref{lem:greedymaximal}, $A = B'C'$, and $B' \in
  \Refn$ since $B \leq B'$. Since $C_i \leq C'_i$ for all $i$, $C'$ is also in
  $\Refn$. It remains to show that neither $B', C' \not\in \{I, A\}$. Note
  that since $B \leq B'$ (\thref{lem:greedymaximal}) and $C \leq C'$, $B', C'$
  are not the identity matrix. Since $A$ is trim, if $B'$ or $C'$ were equal
  to $A$ the product $B'C'$ would have more ones than $A$ does.\\
  ($\Leftarrow$) Immediate.
\end{proof}
Hence, in order to determine whether a trim matrix $A$ is decomposable it
suffices to:
\begin{enumerate}
  \item generate all matrices $C$ with rows intersections of rows of $A$, and
    for each $C$
  \item check whether the product $BC$ with the greedy left multiplier is equal
    to $A$, and $B, C \not\in \{I, A\}$.
\end{enumerate}
If no such matrices $B, C$ are found, then $A$ is indecomposable. This method is
clearly superior to checking all products of matrices in $\Refn$, but still may
require significant time.\\

In order to reduce the time spent checking matrices using
\thref{lem:decomposeintersection}, we would like to only check a smaller set of
canonical representatives. Unfortunately, the following two matrices illustrate
that two reflexive matrices can have the same canonical form under row and
column permutations in $\Bn$, while only one of them is decomposable in $\Refn$. 
\begin{ex}
  Let
\begin{align*}
  A = \begin{pmatrix}
    1 & 0 & 0 & 0 & 1 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 0 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}\text{, }&
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
Then $A, B \in \Ref{5}$, and $B$ may be obtained by exchanging columns $3$ and
$5$ of $A$. However, $A$ is indecomposable whilst
\begin{align*}
  B = \begin{pmatrix}
    1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 1 & 1 & 0 \\
    1 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1 
  \end{pmatrix}
  \begin{pmatrix}
    1 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 1 & 0 \\
    0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 & 1 \\
    0 & 1 & 1 & 0 & 1 
  \end{pmatrix}.&\\
\end{align*}
\end{ex} 

However, the following lemma shows that a more restricted form of
canonicalisation can be applied in this case:

\begin{lemma}
  \thlabel{lem:reflexivecanonical}
  Let $A, B \in \Refn$ be such that $A = P^{-1} B P$ for some permutation matrix
  $P \in S_n$ (i.e. $A$ is obtained by permuting the rows and columns of $B$ by
  the same permutation). Then $A$ is decomposable in $\Refn$ if and only if $B$
  is decomposable in $\Refn$.
\end{lemma}
\begin{proof}
  Suppose that $B = XY$ for $X, Y \in \Refn\setminus \{I, A\}$. Then $P^{-1}XP,
  P^{-1}YP \in \Refn\setminus\{I, A\}$ and $P^{-1}XPP^{-1}YP = A$. The proof of
  the other direction is dual, since $PAP^{-1} = B$.
\end{proof}

We then have the following algorithm for finding a minimal generating set for
$\Refn$:
\begin{itemize}
  \item
    Enumerate the trim reflexive boolean matrices using a backtrack search,
    storing canonical representatives under a row and column permutation in a
    set $S$
  \item 
    Filter out the properly decomposable matrices in $S$ using
    \thref{lem:decomposeintersection}, leaving a set $T$ of trim matrices that
    are not properly decomposable
  \item
    The minimal generating set of $\Refn$ is then $T \cup E$.
\end{itemize}
Using this algorithm, we can calculate the sizes of minimal generating sets up
to $n = 7$; these are contained in Figure~\ref{fig:reflexiverank}.

\begin{figure}
  \centering
  \begin{tabular}{l|r|r}
    $n$ & $\mathbf{d}(\Refn)$ &   \\
    \hline
    1 & 1          & - \\ 
    2 & 2          & - \\ 
    3 & 8          & - \\ 
    4 & 38         & - \\
    5 & 1415       & \cmark \\
    6 & 482\ 430   & \cmark \\ 
    7 & ?          & \cmark \\
    7 & ?          & ? \\
  \end{tabular}
  \caption{The minimum size $d(\Refn)$ of a generating set for the monoid
    consisting of all reflexive $n \times n$ Boolean matrices matrices where:
    ``-'' indicates a value that can be computed by hand or brute force;
    ``\cmark'' indicates that the value was first found here; ``?'' indicates
    that the value is unknown.}
  \label{fig:reflexiverank}
\end{figure}

\section{Hall Matrices}
The submonoid of $\Bn$ consisting of those boolean matrices containing a
permutation matrix is particularly interesting. It is often called the
\emph{Hall monoid} since matrices containing a permutation matrix correspond to
instances of the Hall marriage problem that have a solution, and are thus
referred to as \emph{Hall matrices}. We will denote the Hall monoid by
$\Halln$. 

In order to prove our main result on the Hall monoid, we will need the following
classical result, restated in our context.

\begin{thm}[Hall's Marriage Theorem]
  Let $A in \Bn$. Then $A$ is a Hall matrix if and only if every union of $k$
  rows contains at least $k$ ones, for $1 \leq k \leq n$.
\end{thm}
We shall say that a subset $X$ of the rows of a matrix \emph{satisfies the Hall
  condition} if the union of the rows in $X$ contains at least $|X|$ ones, and
that a matrix satifies the Hall condition if every subset of the rows satisfies
the Hall condition.

It will be useful in this section to define $e_i$ to be the boolean vector of
length $n$ with a single $1$ in position $i$.

The Hall monoid is similar in certain ways to $\Refn$. In particular
the $\J$-relation is easily described through the following lemmas.

\begin{lemma}
  \thlabel{lem:HallContainment}
  For any $A, B \in \Halln$, the product $AB$ contains at least as many ones as
  $A$ or $B$ does.
\end{lemma}
\begin{proof}
  Since $A \in \Halln$, $A$ contains a permutation matrix; hence $AB$ contains a
  row-permuted copy of $B$. Similarly, $AB$ contains a column-permuted copy of
  $A$.
\end{proof}

\begin{lemma}
  \thlabel{lem:HallJRelation}
  Two matrices $A, B \in \Halln$ are $\J$-related in $\Halln$ if and only if $A
  = PBQ$ for two permutation matrices $P, Q \in S_n$.
\end{lemma}
\begin{proof}
  The forward direction is clear. For the reverse, suppose that $A = SBT$ and $B
  = UAV$ for matrices $S, T, U, V \in \Halln$. Then $BT$ contains a
  column-permuted copy of $B$, and hence $A$ contains a row- and column-permuted
  copy of $B$. Since, similarly, $B$ contains a row- and column-permuted copy of
  $A$, it follows that $A$ is a row- and column-permutation of $B$.
\end{proof}

Unlike $\Refn$, $\Halln$ has a particularly nice minimal generating set.
\begin{lemma}
  Every minimal generating set for $\Halln$ is obtained by removing a rank $n-1$
  matrix from a minimal generating set for $\Bn$. That is, every minimal
  generating set for $\Halln$ consists of a set of representatives $P$ of the
  prime $J$-classes of $\Bn$ together with two generators for the group of units
  $S_n$ and an elementary matrix.
\end{lemma}
\begin{proof}
  The fact that $P \subset \Halln$ is a consequence of the discussion after
  \cite[Definition 2.4]{Caen1981aa}. Let $G \subset \Halln$ be obtained as in
  the statement. To establish that $G$ is a generating set, we will show that
  any Hall matrix that lies below the matrices in $G$ in the $\J$-order may be
  written as a product of two higher non-permutation Hall matrices, and
  therefore by an infinite ascent argument may be factorized into matrices in
  $G$.
  
  Note that $G$ consists of matrices from the maximal $\J$-class and all
  one-below-maximal $\J$-classes. By \thref{lem:PermutingReducedMatrices}, every
  matrix in the $\J$-classes of matrices in $G$ is generated by $G$.

  Let $A$ be a Hall matrix that lies below $G$ in the $\J$-order. We may assume
  without loss of generality that $A$ contains the identity permutation, since
  $\langle G \rangle$ contains $S_n$. We will decompose $A$ as a product of
  non-permutation Hall matrices that lie above $A$ in the $\J$-order. 

  First, suppose that $A$ is not trim, i.e.\ some row $i$ of $A$ is contained in
  row $j$. Let $B$ be the matrix obtained by setting entry $i$ of row $j$ to be
  equal to $0$, and $C$ be the greedy left multiplier of $B$ with respect to
  $A$. Then $B$ and $C$ both contain the identity permutation, and hence are
  Hall matrices. Since row $i$ of $B$ is contained in row $j$ of $A$, entry $(j,
  i)$ of $C$ is $1$ and hence $C$ is not a permutation matrix.  Since $A$ was
  not an elementary matrix, and $B$ was obtained by removing a single $1$ from
  $A$, $B$ is not a permutation matrix. Finally, $A = CB$.

  We now assume that $A$ is trim. Since $A$ lies below $G$ in the $\J$-order, it
  has non-maximal row space. Let $B$ be a maximal non-permutation matrix in
  $\Bn$ which contains the row space of $A$. Then $B$ is prime or elementary,
  and hence is similar to some matrix in $G$. By multiplying by permutation
  matrices $U$ and $V$, we may assume that $UBV$ contains the identity
  permutation. Now $A = CB$ where $C$ is the greedy multiplier. Since $A$ is
  trim, we must also have that $C$ is trim. However, there is no reason that $C$
  must be a Hall matrix.
  
  Suppose that $C$ is a Hall matrix. Then, since $B$ is not similar to $A$, $C$
  is not a permutation matrix.  Since $B$ is not a permutation matrix, $C$ is
  not similar to $A$. By \thref{lem:HallJRelation}, $B$ and $C$ are both
  non-permutation matrices which are greater than $A$ in the $\J$-order.

  Now, if $C$ is not a Hall matrix, then it does not satisfy the Hall condition
  and hence there is some minimal subset of rows $W \subseteq \{1, \ldots, n \}$
  that do not satisfy the Hall condition. By multiplying by permutation matrices
  $X$ and $Y$, and working with the matrix $XCY$, we may assume that $W = \{1,
    \ldots, r \}$ and that the union of rows $1$ up to $r$ contains a $1$ in
  positions $1$ up to $s$, $s < r$. We now construct two new matrices $S, T \in
  \Halln$ such that $A = ST$. 
  Let $x, y, u, v$ be the permutations of $\{1, \ldots, n \}$ associated with
  the matrices $X, Y, U, V$. For $1 \leq i \leq s$, define row $i$ of $S$ to
  be row $i$ of $XCY$ and row $i$ of $T$ to be row $i$ of $UBV$. For $s + 1 \leq
  i \leq r$, define row $i$ of $S$ to be row $i$ of $XCY$ plus $e_i$, and define
  row $i$ of $T$ to be $e_i$. For $r + 1 \leq i \leq n$, define row $i$ of $S$
  to be $e_i$, and row $i$ of $T$ to be row $i$ of $A$. 
  
  
  Oh dear, this doesn't work.
 

  We note now
  that if $A$ is similar to a direct sum of a Hall matrix in $\Hall{m}$, $m <
  n$, and an $(n-m)$ dimension identity matrix, then $A$ is decomposable into 

\end{proof}

\section{Transformation Hall Matrices}
The previous two sections can both be viewed in the context of ``matrices which
are forced to contain permutations''; for reflexive boolean matrices this
permutation must be the identity. We now relax this requirement to consider the
monoid $\MTn$ of matrices which contain a transformation, i.e. have a $1$ in
every row. Such a matrix will be called a TC matrix, standing for
``transformation containing''.

\begin{lemma}
  All minimal generating sets for $\MTn$ are obtained by replacing the rank $n -
  1$ matrix in a minimal generating set for $\Bn$ by a matrix similar to
  \begin{align*}
    F' = \begin{pmatrix}
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 1 & 0 & 0 & \cdots & 0 \\
      0 & 0 & 1 & 0 & \cdots & 0 \\
      0 & 0 & 0 & 1 & \cdots & 0 \\
        &   &   \dots & \dots & \\
      0 & 0 & 0 & 0 & \cdots & 1
    \end{pmatrix}
  \end{align*}
\end{lemma}
\begin{proof}
  Since all prime matrices have full rank, such a set $G$ is contained in
  $\MTn$. To see that it is a generating set, consider a matrix $A$ which is not
  $\J$-related to any matrix in $G$. We wish to write $A$ as a product of
  matrices which lie strictly above $A$ in the $\J$-order. 
  
  Suppose that $A$ is not row-trim, and row $i$ is contained in row $j$. Then
  subtracting row $i$ from row $j$, we obtain a new matrix $A'$. If row $j$ is
  now empty, we then insert any row that is not in the row space of $A$ as row
  $j$. Now $A$ is the product $F''A'$ of $A'$ with some matrix similar to $F'$. By
  replacing $A$ with $A'$, and repeating if necessary, we may assume that $A$ is
  row-trim; a dual procedure allows us to assume that $A$ is column-trim. 
  
  Let $A_0 = A$. Then we write $A_0 = B_0C_0$ where $B_0, C_0 \in \Bn$, $B_0$ has a
  maximal row-space amongst non-permutation matrices, and $C_0$ is the greedy left
  multiplier. Since $B_0$ is Hall, it lies in $\MTn$; it is also $\J$-related to
  some matrix in $G$ and hence lies above $A_0$. Since $A_0$ is trim, $C_0$ must also
  be trim, and similarly since $A_0$ contains no zero row neither does $C_0$.
  However, $B_0$ is not a permutation matrix, and therefore $A_0 = C_0B_0$ contains more
  $1$s than $C_0$ does. Now either $C_0$ also lies strictly above $A_0$, in which case
  we are done, or we can repeat the process with $A_1 = C_0$. Since we
  cannot continue producing matrices with fewer and fewer ones forever,
  eventually we must decompose one of the $A_i$s as desired; then the product $A
  = C_i B_i B_{i - 1} \ldots B_1$ consists of matrices strictly above $A$ in the
  $\J$-order, which all lie in $\MTn$. Hence by Lemma~TODO, $G$ generates
  $\MTn$.
  Now, since every generating set for $\Bn$ must contain a representative of
  each prime $\J$-class and an elementary matrix, so too must every generating
  set for $\MTn$. Now $F'$ is not Hall, while all prime and elementary matrices
  are Hall, so $F'$ is not generated by prime and elementary matrices. Hence,
  any such generating set $G$ is minimal. TODO: clean up this last paragraph.
\end{proof}

\printbibliography
\end{document} 
